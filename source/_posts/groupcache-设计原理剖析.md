---
title: groupcache 设计原理剖析
date: 2018-10-29 17:54:55
categories:
- 分布式系统
- 分布式缓存
tags:
- 分布式系统
- 分布式缓存
- LRU缓存
- 一致性哈希
- 缓存过滤机制
- 缓存击穿
- 热点数据扩散
---

[`groupcache`](https://github.com/golang/groupcache)是一个用`go`实现的分布式k/v缓存及缓存填充库，它的作者也是[`memcached`](https://github.com/memcached/memcached)的作者，它已在Google多个生产环境中使用。它非常小巧精致，比较适用于分布式缓存的学习。它本身只是一个代码包（大约2000行代码，不需要配置服务器，在不同的请求处理场合，它可以充当客户端或者服务器的角色。它支持一致性哈希，即通过一致性哈希来对查询请求进行路由。对于缓存的具体策略，`groupcache`采用的是`LRU`，使用了一个`List`和一个`Map`来实现，非常简单。下面先简述本地缓存的基本模型和常见问题，然后剖析`groupcache`的设计原理。

<!-- More -->

单机缓存或者本地缓存是简单的，通过在内存中维护一个cache，当收到查询时，先查询cache是否已缓存查询结果，如果命中则直接返回，否则必须到存储系统执行查询，然后将结果先缓存到cache，然后返回结果。当然，这是本地缓存的基本模型，一般而言，缓存系统都面临着诸如**缓存穿透**、**缓存雪崩**及**缓存击穿**等问题。

- 缓存穿透指的是查询一定不存在的数据，此时从数据源查询不到结果，因此也无法对结果进行缓存，这直接导致此类型的查询请求每次都会落到数据源层，不仅使得缓存失效，当请求数量过多时也会浪费资源。
- 缓存雪崩指的是大量的缓存的过期时间被设置为相同或近似，使得缓存失效时，所有的查询请求全部落地到数据源层，同样，此时数据源层存在服务不可用的可能性。
- 缓存击穿则指的是对于那些热点数据，在缓存失效时，高并发的查询请求也会导致后端数据源层崩溃。

对于`groupcache`的设计，文章从一致性哈希、缓存命名空间、热数据扩散以及缓存过滤几个方面进行阐述。

## 一致性哈希

一致性哈希最初是在论文[《Consistent Hashing and Random Trees: Distributed Caching Protocols for Relieving Hot Spots on the World Wide Web》](https://www.akamai.com/us/en/multimedia/documents/technical-publication/consistent-hashing-and-random-trees-distributed-caching-protocols-for-relieving-hot-spots-on-the-world-wide-web-technical-publication.pdf)中提出，目标是致力于解决因特网中的热点(`Hot spot`)问题，并真正应用于`p2p`环境，它弥补简单的哈希算法的不足。一般可以从四个方面来衡量哈希算法的适用性。
- **平衡性**。平衡性即哈希的结果能够尽可能的分散到所有节点或缓冲，以保证缓冲空间被最大程度使用。
- **单调性**。单调性即如果当前缓存系统已经存在被映射的缓冲内容，当有新的节点加入到系统时，哈希算法应该能够尽可能保证原有已分配的的缓冲内容只能被映射到原有的对应节点或者新的节点，而不能被映射到旧的节点集合的其它节点。
- **分散性**。分布式环境中，不同终端所见的节点范围有可能不同（因为可能只能看见部分节点），这会导致不同终端的哈希结果不一致，最终，相同的内容被映射到了不同的节点。而分散性则专门用于描述此种情况发生的严重程度。好的哈希算法应该尽量避免发生这种情况，即降低分散性。
- **负载**。本质上与分散性阐述的是同一问题。但它从节点出发，即某一特定的节点应该尽可能被相同的缓冲内容所映射到，换言之，避免（不同终端）将相同的内容映射到不同的节点。

所谓一致性哈希，简而言之，即将节点与缓冲内容分别映射到一个巨大的环形空间中，最终内容的缓存节点为在顺时针方向上最靠近它的节点。可以发现，系统中节点的添加与删除，一致性哈希算法仍能基本满足以上四个特性。另外一个关键问题是，当集群中节点数量较少时，节点分布不均匀（即节点所负责的内容范围相差较大）会直接导致内容（数据）倾斜，因此一般会引入虚拟节点，即将节点映射为虚拟节点。如此，整个缓存映射过程便拆分为两个阶段：对于特定缓冲内容，先找到其映射的虚拟节点，然后再由虚拟节点映射到物理节点。

一致性哈希在分布式缓存中充当查询路由角色，因为不同节点负责特定的`key`集合。因此，如果此时当查询没能在本节点缓存中命中时，则需通过一致性哈希路由特定节点(`peer`)，然后借助`http`发送数据查询请求，请求的协议格式为: `GET http://peer/key`。因此，所有节点必须监听其它节点的数据查询请求，同时具备相应的请求处理模块。

## 缓存命名空间

即便是在单个节点上，也可以创建若干个不同名称的缓存命名空间，以使得不同命名空间的缓存相互独立。如此，可以在原本针对`key`进行分片的基础上，丰富缓存功能。因此，节点间的数据查询请求协议格式变更为：`GET http://peer/groupname/key`。

## 热点数据扩散

分布式缓存系统，不同的节点会负责特定的`key`集合的查询请求。但因为并非所有的`key`的访问量是均匀的，因此，存在这种情况：某些`key`属于热点数据而被大量访问，这可能导致包含该`key`的节点无法及时处理甚至瘫痪。考虑到这一点，`groupcache`增加了热点数据自动扩展的功能。即针对每一个节点，除了会缓存本节点存在且大量被访问的`key`之外（缓存这些`key`的对象被称之为`maincache`），也会缓存那些不属于本节点，但同样被大量访问（发生大量地`miss cache`）的`key`，而缓存这些`key`的对象被称这为`hotcache`，如此便能缓解热点数据的查询请求集中某一个节点的问题。

## 缓存过滤机制

`groupcache`的`singleflight`模块实现了缓存过滤机制。即在大量相同的请求并发访问时，若缓存未能命中，则会触发大量的`Load`过程。即所有的查询请求全部会落到数据源（如`DB`）或从其它节点加载数据，因此考虑到节点可靠性，此时`DB`存在因压力过大而导致服务不可用的情况，同时也浪费资源。`groupcache`设计所提供的解决方案是：尽管存在并发的查询，但能保证只有一个请求能够真正的转发到`DB`执行查询，而其余的请求都会阻塞等待，直至第一个请求的查询结果返回，同时，其它请求会使用第一个请求的查询结果，最后再返回给客户端。`singleflight`通过`go`的`sync.WaitGroup`实现同一时间相同查询请求的合并。

最后，虽然官方声称`groupcache`在很多场景下已经成为`memcached`的替代版，但其本身存在固有的"局限性"。
- `groupcache`采用的是`LRU`缓存机制，使用`List`和`Map`实现，不支持过期机制（不支持设置过期时间），也没有明确的回收机制（只是简单地将队尾的数据移除），但能够控制缓存总大小在用户设置的阈值之下。
- `groupcache`不支持`set`、`update`以及`delete`，即对于客户端而言，只能执行`get`操作。
- `groupcache`针对`key`不支持多个版本的值。

总而言之，`groupcache`是一个值得学习的开源分布式缓存系统，通过阅读源码，一方面可以了解分布式缓存相关的设计原则，也能学习编程相关的设计经验。