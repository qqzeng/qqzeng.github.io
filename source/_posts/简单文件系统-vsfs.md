---
title: 简单文件系统 vsfs
date: 2020-01-05 17:02:08
categories:
- 单机存储
tags:
- 单机存储
- 文件系统
---

目前 unix/linux 所采用的文件系统类型，如`ext2`和`ext3`，甚至`ext4`都已经实现得较为完善成熟，其实现细节也比较复杂。但事实上，它们的实现也是经过一步步对已有文件系统的不足进行改进和扩展得来。本文内容指在简要阐述如何设计一个非常简单的文件系统`Very Simple File System (vsfs)`，它需要重点考虑的因素，以及一些设计准则。通过这个文件系统原型，抓住文件系统设计的核心和那些不可避免的`trade-offs`哲学，对于理解那些更加先进和复杂的文件系统是有好处的。

<!-- More-->

本文主要包括两部分内容，在阐述`vsfs`前先简要指出作为文件系统的载体，硬盘的几个关键点。然后再概要阐述`vsfs`的设计。需要注意的是，本文并不会详细阐述设计的细节，本文的定位是一篇总结和启发式的文章，它来源于自己阅读  operating systems three easy pieces 的总结和想法。因此，强烈建议大家阅读原文。

# 关于硬盘一些关键点

文件系统的目的在于有效地统一组织和管理硬盘上的数据，并提供一个一致的、简便的接口给上层应用。但需注意，虽然文件系统作为操作系统软件的一部分，即具备超级管理权限，能够执行一些特权指令(`privileged instruction`)用来操控硬盘驱动器，但大部分情况下它并不知道硬盘存储数据的细节，比如文件具体是存储在哪块盘片上，占据了哪些磁道和扇区，或者当前磁头的具体位置。这也说明了，很多文件系统的优化对于操作系统或者文件系统而言，就无能为力。相反，文件系统只能把硬盘抽象成一个大的数组，可以通过某个单位大小进行寻址/索引（典型的，如4kb），虽然优秀的文件系统会对这个大数组进一步抽象来提高组织管理的效率。

硬盘扇区大小为 512b，因此整个硬盘可以看作是一个以 512b 为寻址单位的数组，但这并不意味着文件系统也只能同样以 512b 寻址，多扇区的操作也是允许的，但显然，硬盘只能保证 512b 的寻址操作具备原子性。

另外，需要时刻记住的是，硬盘的顺序读写的速度远大于随机读写，大约有2个数量级的差异。换言之，如果能将访问硬盘的随机读写操作转化为连续或顺序的读写操作，则可显著提升硬盘访问效率。这比较容易解释，如果从整个硬盘访问的过程来分析，通常其访问时间包含三个部分：旋转时延(`Rotational Delay`)、寻道时间(`Seek Time`)以及传输时延(`Transfer Time`)。我们可以做一个简单的估算，一般硬盘的`RPM`，即每分钟转数为 15000 或 7200，因此，平均旋转时延大约为 2ms 或 4ms（注意只有一半）；而寻道时间通常由硬盘制造商给出，大约几 ms，比如 4ms；最后传输时延和所传输的数据块大小以及数据块传输速率相关，关于数据块传输速率，一般都有 100MB/s 的级别，比如 125MB/s，因此对于随机读，假定每次读的大小为 4kb（换言之，每读 4kb 的数据块就要累加一次旋转时延和寻道时间），那么其传输时延约为 31 微秒，因此，对于随机读，其（4kb 的大小块）总耗时约为 6ms，由此，随机读传输速率约为 0.67MB/s。而对于顺序读，假定传输数据块大小为 100MB，那么其传输时延为 800ms，其（100MB 的大小块）总耗时约为 806ms，因此顺序读传输速率约为  124MB/s。可以观察到，当每次随机读的块大小为 4kb，而顺序读的块大小为 100MB 这个前提条件下，顺序读的效率为随机读的效率的 100 多倍。不难理解造成这个差异的原因，随机读的主要时间消耗都在旋转时延和寻道时间上，每一次读取都有开销，而真正花费在数据块传输的时间却几乎可以忽略不计（微秒级别）。相反，对于顺序读，其主要的时间消耗主要集中在数据块传输，因此顺序读的带宽 124MB/s 很接近硬盘的理论带宽大小 125MB/s(`peek bandwidth`)。

关于磁盘的调度策略。所谓的磁盘调度策略在这里指的是当应用程序发出了多个 IO 请求时，磁盘调度器如何决定这些请求的执行顺序。最直接的调度策略是最短寻道时间优先(`SSTF: Shortest Seek Time First`)，因为磁盘调度器可以通过当前磁头的位置，以及IO 请求的详细内容估算 IO 请求的具体耗费时间，然后按照从小到大排序进行调度。它的问题也很明显，可能会引发请求`starvation`，即那些先发出的请求迟迟得不到执行。另外，一般情况下，实际上是由处理器来先对应用程序发出的请求进行调度，且考虑到处理器只知道整个磁盘的抽象逻辑表示，无法利用当前磁头的位置来找出最短寻道时间的请求，因此此种策略有局限性。另外就是电梯调度算法(`Elevator`)及其变种。这种调度策略比较简单，也较有效，能够最大程度接近最短寻道时间所实现的效果，但它只考虑了寻道时间，没有考虑旋转延时。因此，现代的 IO 调度策略准确而言是由磁盘调度器以及处理器调度合作实现完成，处理器只能做粗粒度的请求调度，因为它不知道具体的磁盘目前状态（如磁头位置）及磁盘布局细节（如柱面组划分）。且磁盘调度器还会做一些调度优化，比如对一些相邻块的请求进行合并。

# vsfs

关于学习文件系统。一个文件系统的精髓或者学习一个文件可以从两个方面来把握：一是实现文件系统所涉及的数据结构。换言之，其底层采用的是怎样的数据结构以有效地组织管理用户数据(`user data`)和元数据(`metadata`)。不同的文件系统可以采用不同的数据结构来实现，但它们的目标是一致的，即有效地管理和组织数据；其次，梳理文件系统的典型的方法执行流程和原理。比如对于`open()`系统调用是如何通过操作这些数据结构来实现的？此过程涉及到对哪些数据结构的读和写的操作？这些操作执行的效率如何？对这两个方面的深入了解，能够让我们了解一个文件系统的数据模型和基本工作原理，以方便之后更好的使用它，甚至改进和扩展它。

## 基本数据结构

首先了解一个典型的文件系统，为了存储用户数据，包含了哪些基本的数据结构，以及它们是如何被有有效组织的。

### 磁盘组织布局

一个最简单的文件系统的布局是容易得到的。整个磁盘，准确而言是整个分区（因为不同分区可以挂载不同的文件系统，各分区独立）可划分成用户数据区(`data`)和元数据区(`inodes`)，数据区即存储实际数据块的磁盘区域，而元数据区则用来索引数据块和记录数据块元信息的磁盘区域（准确而言，索引的方式一般是通过指针，可以是多级指针；而元信息则包括时间类，文件权限类，以及文件大小等属性类）。为了重复使用`inodes`和`data`区域，需要使用一块区域来记录它们是否已被占用，常见是采用位图来完成，位图占用空间小，检索也方便，即使用`i-bmap`和`d-bmap`来分别跟踪`inodes`和`data`所包含区域的数据块的使用情况。最后对于一个文件系统而言，需要有一个关键的全局已知区域来存放文件系统级别的信息，即是超级块`superblock`，它存储的信息包括整个文件系统`data`和`inodes`所包含的数据块的数目以及它们各自的索引起始位置，另外也会存储一个`magic number`来检测文件系统类型。`superblock`至关重要，一旦损坏，则整个文件系统变为不可用，因为一些会多副本存储。另外，在整个文件系统正常工作前，需要先将`superblock`加载到内存，换言之，在系统挂载文件系统时，其首先将读取`superblock`的内容并初始化全局信息，然后才将文件系统的其它部分附加到系统文件系统层级树。

### 一个实例

下面以一个实例来直观描述文件系统对硬盘抽象后的详细布局。下图是一个典型的简化后的磁盘布局，假设磁盘的数据块大小为 4kb，则从文件系统的角度而言，整个磁盘就是一个以 4kb 为寻址单位且总大小为 256kb（共64个数据块） 的数组。数组的后 56 个数据块作为`data`区域，`inodes`区域靠近`data`区域，占据 5 个数据块大小，共 20kb，假设一个`inode`的大小为  256b，那么一个块可以包含 16 个 `inode`，因此，整个`inodes`区域(`inode table`)包含了 80 个`inode`，这对于我们的实例是足够的（我们只有 64 个`data block`）。在`indoes`区域前的是`i-bmap`和`d-bmap`区域，各占 1 个数据块的大小。最后数组的第一个数据块被设置成`superblock`。

<img src="https://res.cloudinary.com/turalyon/image/upload/v1578413457/blog/31-vsfs/vsfs-disk-structure-layout-outline_z8cwso.png" alt="vsfs 磁盘布局" style="zoom:67%;" />

每个`inode`都有唯一编号，即`inode number`。且在`vsfs`中，通过`inode number`可以直接得出对应的`inode`所在磁盘位置。下图中，`inodes`从 12kb 位置开始直至 32kb 处，占据 5 个数据块空间。因此，若读取`inode number`为 32 的`inode`，则可通过`blk=(inumber * sizeof(inode_t))/blockSize` 得到起始的 `block`编号（相对于`inodes`区域的`block`编号），但考虑到物理磁盘通过扇区寻址，因此进一步计算，`sector=((blk*blockSize)+inodeStartAddr)/sectorSize`以得出最后的全局扇区编号。

<img src="https://res.cloudinary.com/turalyon/image/upload/v1578413459/blog/31-vsfs/vsfs-disk-structure-layout_us9zno.png" alt="vsfs inode 磁盘布局" style="zoom:67%;" />

### 关于 inode

关于`inode`的设计。即如何通过`inode`定位到对应的`data blocks`。最简单的方式即存储一个直接指针(`direct pointers`)，即对应的磁盘地址。但这种方式存在明显的局限性，考虑一个非常大的文件，其大小超过一个`inode`块所能索引总的数据块大小（约 4kb/256b * 4kb）。解决办法也很直接，使用多级指针，在这个实例中，若仅多考虑一个间接指针`indirect pointer`，且间级指针所指向的数据块中所包含的地址大小为 4b，且再加上一级指针所能索引的数据块的大小，即若一个`inode`包含 12 （典型的值）个`direct pointer`和 1 个`indirect pointer`，那么此`inode`所能索引的最大文件大小为 (12+4kb/4b) * 4kb = 4144kb。当然，在很多情况下，仍不能满足需求，则可考虑三级指针(`double indirect pointer`)，简单估算，可以索引的数据块的最大大小为 (12+4kb/4b+(4kb/4b * 4kb/4b))  * 4kb，可以看到这个大小已经非常大了。事实上，很多文件系统（包括`ext2`和`ext3`）都使用多级指针。另外，实际上在绝大部分使用场景中，一级指针已经完全够用，因为小文件在文件系统占主导地位（如 2kb），因此，为了更好地适应此种情形，一个`inode`包含典型的 12 个直接指针，能够直接索引 48kb 的文件大小，这已经可以满足大部分情况下的需求了。但为了应对极少部分的大文件存储，可以添加一个二级甚至三级指针。

事实上，`inode`可以使用任何其它能够有效管理组织数据块元数据信息的数据结构来实现，另一种常见的是基于`extents`的实现方式，一个`extent`表示一个磁盘地址和一个表示数据块数目的整数，以此来索引一个文件。明显，基于`extents`的表示方式需要大量连续磁盘空间，且如果文件过大，也可能需要多个`extent`来表示，但相比基于`inode`的索引方式，基于`extents`的方式其元数据信息所占空间小，相对紧凑，因此访问效率可能更高。

另一种用于实现`inode`的方式是使用链表(`linked-based`)，在这种情况下，我们只需要一个指针指向文件所包含的第一个数据块。但此种方式的缺点很明显，访问文件指定部分时，相当于要遍历整个链表。因此，对于`FAT`文件系统而言，虽然它也采用类似的方式实现，但它使用一个内存表存储着所有链表节点的信息，内存表通过数据块的地址来索引，以获得下一个数据块的地址信息，通过此种方式高效地实现数据块的随机索引。

### 目录组织

关于目录。对于内核而言，目录也是一种特殊的文件（`directory`类型），因此，它也是通过`inode`来索引其所包含的`data blocks`。只不过不同于普通的文件存储的是用户数据，目录包含的是`(entry name, inode number)`的一个列表（可能还包含其它信息，比如`entry`名的长度），当然，目录也可以包含目录。类似地，也有通过`B-tree`来组织目录所包含的内容的实现方式。

## 典型方法执行流程

在了解一个典型的文件系统所使用的基本数据结构后，即清楚了用户数据在磁盘是如何被组织和管理后。那么，我们还需要了解，当我们操作存储在磁盘上的文件时，具体是如何映射到对这些数据结构的相关操作的。典型的操作流程包括文件的读取和写入。

### 文件读取

以一个简单的实例阐述。若文件系统读取一个大小为 12kb(3个数据块)的文件`/foo/bar`。读取过程所涉及的相应数据结构的操作类型及顺序如下图。几个关键点L：`/`目录所对应的`inode`的编号必须是全局的，因为一般的文件或目录的`inode`编号是通过在其父目录中检索得到，而考虑到`/`处在最顶级的层级，因此，其`inode`编号必须是全局的。另外，访问一个文件的某个数据块时，需要更新文件所对应的`inode`中存储的元数据信息（访问时间）。最后注意到，目标文件所处的层级越深，其访问也越耗时，因为理论上它需要一层层递归下去，而且在递归过程中，若某一目录所包含的项非常多，则会严重降低指定目录项的检索效率。但为了提高文件访问的效率，文件系统一般会采用缓存那些频繁访问的数据块。

<img src="https://res.cloudinary.com/turalyon/image/upload/v1578413458/blog/31-vsfs/vsfs-access-read_wvmans.png" alt="vsfs 文件读取流程" style="zoom:50%;" />

### 文件写入

同样以一个简单的实例阐述。文件的写入流程和文件读取的流程存在相似部分。显然，文件首先需要被打开，因此定位文件的过程是类似的。写入文件可能涉及到新数据块分配，当然，也有可能是已有数据块被覆盖。如果考虑写入额外内容，则需要更新`d-bmap`和`inode`。具体而言，每次对文件写入新数据块，需要对`d-bmap`读取和写入各一次，对`inode`读取和写入各一次，以及对新数据块的写入操作。另外，若创建文件，则流程更为复杂，因为它涉及到文件所在目录的相关操作，比如在目录所关联的数据块中分配对应的`entry`记录。具体而言，对`d-bmap`读取和写入各一次，对文件所对应`inode`的写入，对文件所在目录所关联的数据块的写入，以及对文件所在的目录所对应的`inode`的读取和写入各一次，即总共包含了 5 次IO。而且可能还需要对创建后的文件写入新数据块。同文件读取类似，文件写入所需要的磁盘操作甚至更多，因此，大部分情况下，文件系统也会对文件的写入进行缓冲，以执行批量写入，批量写入也有助于磁盘调度器的调度优化。

<img src="https://res.cloudinary.com/turalyon/image/upload/v1578413457/blog/31-vsfs/vsfs-access-write_z5v5ql.png" alt="vsfs 文件创建流程" style="zoom:50%;" />

简单小结。本文先指出关于磁盘本身的一些重要点，这是考虑到这些关键点与文件系统的设计，甚至上层应用程序对文件系统的使用密切相关。另外，从两个方面简单介绍了简单文件系统(`vsfs`)，其一是`vsfs`为了有效组织和管理磁盘上的数据，所采用的重要数据结构，其次结合这些数据结构，简单介绍文件读取和创建两个典型操作流程中对相应的数据结构的操作类型和顺序。理解这两点有助于对一个文件系统的原理的整体把握。本文的定位是一篇总结和启发性的文章（文章中的插图全部出自参考资料中的[1]），希望通过对一个极其简单的文件系统的了解，能够有助于学习那些更加先进复杂的文件系统。







参考资料
[1].  Arpaci-Dusseau R H, Arpaci-Dusseau A C. Operating systems: Three easy pieces[M]. Arpaci-Dusseau Books LLC, 2018.