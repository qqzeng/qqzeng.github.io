---
title: 分布式互斥算法解析与实现
date: 2018-11-09 16:16:42
categories:
- 分布式系统
- 互斥算法
tags:
- 分布式系统
- 互斥算法
- 资源共享
- lamport clock
- 逻辑时钟
---

资源共享非常普遍，在单机系统中，进程间对共享资源的互斥访问可以通过互斥锁、信号量以及进程间通信等机制来实现。而在分布式系统中，也不可避免多个节点共享某一资源或同时执行某一函数，比如全局配置文件，因此分布式互斥算法必须保证任何时刻只允许一个进程访问资源或执行临界区(`critical section`)代码，即互斥算法的安全性，有些场景也有公平性要求。另外，好的互斥算法应该能尽可能降低消息带宽(`message overhead`)，减少进程（节点）等待时间，即时延(`latency`)，无系统瓶颈(`bottleneck`)，也能容忍消息乱序。

<!-- More-->

分布式互斥算法分为集中式算法(`centralized algorithm`)和分布式算法(`distributed algorithm`)，而分布式算法又包括了基于令牌的算法(`token based algorithm`)以及基于请求的算法(`permission based algorithm`)。无论基于何种原理实现，一般而言，理想的分布式互斥算法需要保证以下目标：
- **安全性**，即任何时刻只能有一个进程访问共享资源，即持有互斥锁。
- **公平性**，有些场景需要尽量保证访问共享资源的公平性，这表明：系统不能出现死锁，任何进程持有锁的时间是有限的，任何等待的进程最终都能获取锁，以及等待获取锁的进程的等待时间是有限的。
- **低带宽**，即尽量减少消息传输的数目。
- **低延迟**，即进程进入临界区之前的等待的时间。
- 动态性，即允许进程在任何时刻加入到访问共享资源的进程集合中，或者从其中退出。
- 容忍进程失败，即允许访问共享资源的进程集合中的进程因失败而退出，而保证整个系统不受影响。
- 容忍消息丢失，即在消息不能按时到达、乱序甚至丢失的情况下，整个系统依然正常工作。

在本文我们讨论前四个要求，假设**进程数目是确定的，没有进程会失败，消息也不会丢失**。下面我们通过简要阐述算法原理以及实现关键点来依次介绍`Centralized Mutual Server`算法、`Ricart Agrawala`算法、`Lamport Distributed Mutual Exclusion`算法以及`Token Ring`算法。

## Centralized Mutual Server

顾名思义，`Centralized Muutal Server`为集中式的互斥算法。整个系统内部包括两种消息：请求(`reqeust`)消息、授权(`grant`)消息以及释放(`release`)消息。核心数据结构为一个请求消息队列。算法核心为：它选取一个进程(`centralized server`)作为协调者，负责对名进程的请求进行即时或推迟(`defer`)授权。它内部维护一个互斥锁锁请求队列，当收到请求消息时，如果队列为空，则直接授权，否则将其加入到队列中。当收到释放消息时，如果列队不为空，则从队列中取出一个请求并授权响应。算法公平性依赖于队列实现，如使用`FIFO`则能够保证各个进程的锁请求消息能够被公平地授权。消息带宽为3(`1 request, 1 grant, 1 release`)，即在某一进程从准备进入临界区到退出临界区所传输消息的数量。很明显，集中式互斥算法的缺点是协调者的瓶颈。

集中式互斥算法最容易实现。在网络通信层，可以采用基于`TCP`的`client-server`通信模型。关于协调者的实现，你可能需要关注当前是否已经授权了锁请求。同时，如果有必要，注意单进程内部锁的使用。

## Ricart Agrawala

`Ricart & Agrawala`算法是在1981年被提出的一个基于请求的分布式互斥算法。它基于`lamport clock`，即依赖于全局有序的逻辑时钟。整个系统内部包括两种消息：请求(`reqeust,i,ts`)消息与回复(`reply,j`)消息。核心数据结构包括缓存其它进程回复消息的队列(`replyQueue`)以及缓存推迟回复进程请求消息队列(`deferQueue`)。算法核心为：当进程`i`准备进入临界区时，必须发送一个带（逻辑）时间戳的请求消息给其它所有进程，当其收到了其它所有进程的对此请求的回复（响应）时，则进入临界区。但如果某一进程`j`在收到进程`i`的请求之前，发出了一个更早的请求消息，则它会将此进程(`i`)的请求消息放入到延迟队列(`deferQueue`)，并且先执行完临界区的代码，当准备退出临界区时，才发送请求响应给进程(`i`)。算法的公平性容易保证。而消息带宽为`{request: n-1, reply: n-1} => 2(n-1)`，其中`n`为进程数。

`Ricart Agrawala`算法的相比集中式算法在实现上更为复杂。同样在通信层，则不能构建`one server, muliti-client`模型，而采用`peer to peer`模型，因为所有进程都是对等的，即同时充当`server`与`client`，而且作为一种简化实现，所有进程在启动后，应该互相建立连接。除此之外，你需要实现（模拟）[lamport clock 算法](https://qqzeng.top/2018/11/05/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E6%97%B6%E9%97%B4%E3%80%81%E6%97%B6%E9%92%9F%E4%B8%8E%E4%BA%8B%E4%BB%B6%E9%A1%BA%E5%BA%8F/)，否则互斥算法的正确性不能得到保证，注意对于某些消息（如`reply`）的发送事件，虽然可以更新消息时间戳，但其实不影响算法正确性。

## Lamport Distributed Mutual Exclusion

`Lmpoart Distributed Mutual Exclusion`算法于1978年由 Lamport 在关于`lamport clock`理论论文中提出，其作为`lamport clock`的实际应用，因此，显然其依赖于`lamport clock`。事实上，此算法不仅可以作为分布式互斥算法，其内部的请求优先级队列也能作为分布式节点副本一致性的实现参考模型。但原论文提出的互斥算法基于消息按顺序到达的假设，解释如下：

> 比如，进程i在时间片1发送锁请求a，但因为网络原因被极端延时了。而且在其它进程收到进程i发送的请求消息a之前，进程j在时间片5发送了请求b，而请求b恰好被顺利传输，很快被其他进程接收，并且其他进程（包括进程i）立刻发送了对请求消息b的回复消息，同时回复消息也立刻被进程j接收，但此时进程j仍未收到进程i的请求消息a，所以进程j以为自己成功获取到锁（收到了其它所有进程对请求消息b的回复）。而事实上，进程i的请求消息a要比进程j的请求消息b更早发送，因此应该是进程i先获取锁。其根本原因在于，进程i在收到其他节点请求消息（进程j的请求消息b）时，没有进行额外检查，理论上它需要判定自己是否在更早前发出过请求消息，而不只是直接对请求消息回复，即使最后其在请求消息队列里移除的消息是它自己的请求消息（因为自己是请求消息是最早的）。但这造成了整个系统的不正确性。

因此，改变`Lmpoart Distributed Mutual Exclusion`算法在接收请求消息后发送回复消息的条件，消除了消息按序到达的假设，但同时也使得变更后的算法更为复杂。

系统内部包括三种消息：请求(`reqeust,i,ts`)消息、回复(`reply,j`)消息以及释放(`release`)消息。核心数据结构包括缓存其它进程回复消息的队列(`replyQueue`)、缓存推迟回复进程请求消息队列(`deferQueue`)以及一个以时间戳为依据的请求消息优先级队列(`requestPriorityQueue`)。算法变更的核心为：进程`i`在收到进程`j`的请求消息`(request, j, t)`时，（条件1）先判断自己是否发送过更早的请求消息，（条件2）并且未收到进程`j`针对此请求消息的回复消息。如果二者之中任一个未被满足，则对进程`i`的请求消息发送回复，否则将其加入到`deferQueue`。原因如下：条件1是明显的；关于条件2，如果进程`j`已经收到了进程`i`的消息回复，说明进程`i`先前发出的请求消息肯定已经被进程`j`接收（换言之，进程`i`若发送过请求消息，则此请求消息必定已经缓存到了进程`j`的`requestPriorityQueue`），因此消除了消息延迟（乱序）的影响。另一方面，当进程`i`收到请求回复消息时，它会先将其加入到`replyQueue`，并判断发送此回复消息的进程是否被加入到了其`deferQueue`中，如果已经加入到了，则将其移除，然后对此进程发送回复消息（因为进程`i`确认它已经收到被移除进程的回复消息）。其它的算法逻辑同论文中描述一致。事实上，消除消息按序到达的关键为`deferQueue`。算法的公平性容易保证。而消息带宽为`{request: n-1, reply: n-1, release: n-1} => 3(n-1)`，其中`n`为进程数。

`Lmpoart Distributed Mutual Exclusion`算法的相比`Ricart Agrawala`算法在实现上更为复杂。通信层采用`peer to peer`模型。

## Token Ring

`Token Ring`是基于令牌的互斥算法。是一种简单的互斥算法模型，局限性也较大。系统内部只有一种消息：传递 token 的(`OK`)消息。算法核心为：将所有进程在逻辑上组成一个环，并将 token 在环上依次传递，获取到 token 的进程则具备进行临界区的条件，未收到 token 的进程则必须等待。在进程启动时，必须先将 token 传递给某一进程，若此接收进程需要锁，则进入临界区，执行完临界区代码后，再将 token 传递给相邻的下一个进程。否则直接将 token 传递给相邻下一个进程。算法的公平性同样易保证。消息带宽为`n-1`，其中`n`为进程数。

`Token Ring`算法较易实现，同样采用`peer to peer`通信模型。注意进程启动时，初始的 token 持有者。

## 关于测试

在实现上述四种算法时(`go`语言)，采用`TCP`协议（可靠的）。测试的流程包含两个独立的阶段：
**Phase a**. 每个进程独立的重复以下操作若干次。
1. 执行本地操作。采用 sleep [100, 300]ms 来模拟。
2. 开始进入临界区(`critical section`)。执行获取互斥锁逻辑。
3. 执行临界区代码。对一个共享变量进行累加，在 [100, 200]ms超时时间内，每隔100ms，对共享变量随机增加 [1,10]。将累加过程写入文件，同时将累加的中间值记录到全局数组。
4. 退出临界区。执行释放互斥锁逻辑。

**Phase b**. 每个进程独立的重复以下操作若干次。
1. 进程号为偶数的进程 sleep [100, 300]ms，然后重复 Phase a 操作流程。进程号奇数的进程直接重复 Phase b 流程。

对上述四个分布式互斥算法的测试结果的验证侧重于两个方面：
- **算法正确性**。通过检查 Phase a&b 中全局数组的记录情况来确保共享资源的互斥访问。另外，核查 Phase a&b 中进程访问共享资源的访问日志文件。
- **带宽与延时**。统计每个进程的消息读写数目，及获取互斥锁的延时，并计算平均延时。

[参考代码在这里](https://github.com/qqzeng/distributed-mutual-exclusion)。






参考文献：

[1] Ricart G, Agrawala A K. An Algorithm for Mutual Exclusion in Computer Networks[R]. MARYLAND UNIV COLLEGE PARK DEPT OF COMPUTER SCIENCE, 1980.
[2] Lamport L. Time, clocks, and the ordering of events in a distributed system[J]. Communications of the ACM, 1978, 21(7): 558-565.
[3].[CMU Distributed System Lecture.](https://www.cs.cmu.edu/~dga/15-440/S14/)

