<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[etcd-raft 集群配置变更源码简析]]></title>
    <url>%2F2019%2F01%2F15%2Fetcd-raft-%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE%E5%8F%98%E6%9B%B4%E6%BA%90%E7%A0%81%E7%AE%80%E6%9E%90%2F</url>
    <content type="text"><![CDATA[上一篇文章阐述了etcd-raft snopshot相关逻辑，并从整体上把握etcd-raft snapshot的设计规范。本文的主题是集群配置变更的理论及实际的相关流程，即etcd-raft如何处理集群配置变更，且在配置变更前后必须保证集群任何时刻只存在一个leader。在raft论文中提出每次只能处理一个节点的变更请求，若一次性处理多个节点变更请求（如添加多个节点），可能会造成某一时刻集群中存在两个leader，但这是raft协议规范所不允许的。而etcd-raft的实现同样只允许每次处理一个配置变更请求。大概地，etcd-raft首先将配置变更请求同普通请求日志进行类似处理，即复制到quorum节点，然后提交配置变更请求。一旦quorum节点完配置变更日志的追加操作后，便触发leader节点所维护的集群拓扑信息变更（此时原集群拓扑所包含的节点才知道新的集群拓扑结构），而其它节点在收到leader的消息后，也会更新其维护的集群拓扑。 集群配置信息变更在结合代码阐述集群配置信息变更的流程之前，先简单了解论文中所阐述的集群配置变更理论。为什么一次集群配置信息变更（此处以增加新节点示例）只能增加一个节点？这包含两个部分：其一解释若一次增加两个节点会使得集群在某一时刻存在两个leader的情况。其二，阐述若一次只允许增加一个节点，则不会出现某一时刻存在两个两个leader的情况。 如图（论文原图）所示，集群配置变更前集群中节点数量为 3（包括s1、s2及s3），且假设最最初的leader为s3。假设集群配置变更时允许 2 个节点同时加入到集群中，那么原来的 3 个节点在知道新的集群拓扑结构前（即集群配置变更的请求日志被提交之前），它们认为集群中只包含 3 个节点。而当新加入的节点（s4及s5）提出加入请求时，leader节点开始对节点加入请求日志进行同步复制，假设在s1及s2提交日志之前，s3、s4于它们之前收到日志并成功回复，那么leader此时收到了 quorum个回复（s1、s4及s5），因此可以提交节点请求加入的日志，换言之，此时节点s1、s4及s5认为集群中存在 5 个节点，而s2和s3仍然认为集群中只包含 3 个节点（因为它们还未提交配置变更请求）。此时假设某种网络原因，s1与s3（leader节点）失联，则s1重新发起选举，并成功收到s2的回复（s2可以给s1投票的），因此s1成功选举为leader（因为它它认为自己收到了quorum=3/2+1=2节点的投票）。而s3此时也同样发起选举，它可以获得s3、s4及s5的选票，因此它也能成功当选为leader（它认为自己收到了quorum=5/2+1=3节点的投票）。此时，集群中存在两个leader，是不安全且不允许的（显然，两个leader会导致对于同一索引处的日志不同，违反一致性）。 那为什么每次只入一个节点就能保证安全性呢（即任何时刻都只能有一个leader存在）？同样，假设我们最初的集群中包含三个节点（s1、s2及s3），且最初的leader为s1，但此时只有一个节点加入（假设为s4）。那么我们从三个方面来讨论为什么能保证任意时刻只存在一个leader： 配置变更请求日志提交前。即此时原集群的节点（s1、s2及s3）都只知道原始集群拓扑结构信息，不知道新加入的节点信息（其quorum=3/2+1=2）。但新加入的节点认为集群中存在 4 个节点（因此其quorum=4/2+1=3）。因此，在s1、s2或s3当中任意一个或多个发起选举时，它们最多只能产生 1 个leader（与原始集群的选举一致，因为它们的集群拓扑视角均未变化）。而s4发起选举时，它不能得到s1、s2或s3任何一张选票（因为很明显它的日志比它们的要旧）。 配置变更请求日志提交中。即此时配置变更请求的日志已经被leader提交了，但并不是所有的节点都提交了。比如，s1及s2成功提交了日志，则此时若s4发起选举，它不能获取quorum=3/1+1=3张选票，因为它的日志要比s1和s2的要更旧，即只能获取s3的选票（不能成功当选 ），若s3发起选举的结果也类似（注意，其此刻不知道s4的存在，因此其quorum=2）。总而言之，已提交了日志的节点能够获取quorum张选票，而未提交日志的节点因为日志不够新因此不能获得quorum张选票。 配置变更请求日志提交后。这种情况比较简单，当配置变更请求已经提交了，集群中任意一个节点当选的条件必须是获得quorum张选票，且任意两个quorum存在交集，但一个节点只能投出一张选票（在一个term内），因此不可能存在两个节点同时当选为leader。 至此，关于论文中的理论已经阐述完毕。而etcd-raft也只允许一次只能存在一个配置变更的请求。下面来简单了解etcd-raft是如何处理配置变更请求。 关键流程我们同样从raftexample着手，当客户端发起配置变更请求（这里以加入一个新节点作为示例）时，etcd-raft是如何处理的。上文提过，这主要包含两个过程：其一，配置变更请求日志的同步过程（同普通的日志请求复制流程类似）。其二，在日志提交之后，节点正式更新集群拓扑信息，直至此时，原集群中的节点才知道新节点的存在。主要涉及的代码的目录为：/etcd/contribe/raftexample及/etcd/raft。 在阐述配置变更相关流程逻辑前，我们简要帖出核心数据结构，比较简单： 1234567891011121314151617type ConfChange struct &#123; // ID 为节点变更的消息id ID uint64 `protobuf:"varint,1,opt,name=ID" json:"ID"` // 配置信息变更的类型，目前包含四种 Type ConfChangeType `protobuf:"varint,2,opt,name=Type,enum=raftpb.ConfChangeType" json:"Type"` // 配置信息变更所涉及到的节点的 ID NodeID uint64 `protobuf:"varint,3,opt,name=NodeID" json:"NodeID"` Context []byte `protobuf:"bytes,4,opt,name=Context" json:"Context,omitempty"`&#125; // /etc/raft/raftpb/raft.pb.gotype ConfChangeType int32const ( ConfChangeAddNode ConfChangeType = 0 ConfChangeRemoveNode ConfChangeType = 1 ConfChangeUpdateNode ConfChangeType = 2 ConfChangeAddLearnerNode ConfChangeType = 3) // /etc/raft/raftpb/raft.pb.go 我们知道，关于raftexample示例，它可以通过两种方式加入集群，其一是集群节点信息初始化，即在集群启动时便知道存在哪些节点，这不属于我们本文讨论的范围。其二是集群正常运行过程中，一个节点要加入集群，它可以通过向客户端发出一个 HTTP POST 请求以加入集群： 12curl -L http://127.0.0.1:12380/4 -XPOST -d http://127.0.0.1:42379 raftexample --id 4 --cluster http://127.0.0.1:12379,http://127.0.0.1:22379,http://127.0.0.1:32379,http://127.0.0.1:42379 --port 42380 --join 在应用的 HTTP 处理器模块接收到请求后，会构建一个配置变更对象，通过confChangeC管道将其传递给raftNode模块，由raftNode进一步调用node实例的ProposeConfChange()函数。相关代码如下： 123456789101112131415161718192021222324252627282930313233343536373839func (h *httpKVAPI) ServeHTTP(w http.ResponseWriter, r *http.Request) &#123; key := r.RequestURI switch &#123; case r.Method == "PUT": // ... case r.Method == "GET": // ... case r.Method == "POST": url, err := ioutil.ReadAll(r.Body) // ... // 解析参数 nodeId, err := strconv.ParseUint(key[1:], 0, 64) if err != nil &#123; log.Printf("Failed to convert ID for conf change (%v)\n", err) http.Error(w, "Failed on POST", http.StatusBadRequest) return &#125; // 构建 ConfChang 对象 cc := raftpb.ConfChange&#123; Type: raftpb.ConfChangeAddNode, NodeID: nodeId, Context: url, &#125; // 将对象放入管道，通知 raftNode h.confChangeC &lt;- cc w.WriteHeader(http.StatusNoContent) case r.Method == "DELETE": nodeId, err := strconv.ParseUint(key[1:], 0, 64) // ... cc := raftpb.ConfChange&#123; Type: raftpb.ConfChangeRemoveNode, NodeID: nodeId, &#125; h.confChangeC &lt;- cc // As above, optimistic that raft will apply the conf change w.WriteHeader(http.StatusNoContent) // ... &#125;&#125; // /etcd/contribe/raftexample/httpapi.go 1234567891011121314151617181920212223func (rc *raftNode) serveChannels() &#123; go func() &#123; confChangeCount := uint64(0) for rc.proposeC != nil &amp;&amp; rc.confChangeC != nil &#123; select &#123; case prop, ok := &lt;-rc.proposeC: // ... // 收到客户端的配置变更请求 case cc, ok := &lt;-rc.confChangeC: if !ok &#123; rc.confChangeC = nil &#125; else &#123; confChangeCount++ cc.ID = confChangeCount // 调用底层协议核心来处理配置变更请求（实际上即追加配置变更日志） rc.node.ProposeConfChange(context.TODO(), cc) &#125; &#125; &#125; // client closed channel; shutdown raft if not already close(rc.stopc) &#125;()&#125; // /etcd/contribe/raftexample/raft.go 在底层协议收到此调用请求后，会构建一个MsgProp类型的日志消息（这同普通的日志请求的类型是一致的），但消息中的Entry类型为EntryConfChange。通过一系列的函数调用，会将此请求消息放入proc管道，而在node的run()函数中会将消息从管理中取出，然后调用底层协议的核心处理实例raft的Step()函数，进而在最后调用其stepLeader()函数。部分代码如下（完整的函数调用栈为：ProposeConfChange() -&gt; Step() -&gt; step() -&gt; stepWithWaitOption() -&gt; r.Step() -&gt; r.stepLeader()）： 1234567func (n *node) ProposeConfChange(ctx context.Context, cc pb.ConfChange) error &#123; data, err := cc.Marshal() if err != nil &#123; return err &#125; return n.Step(ctx, pb.Message&#123;Type: pb.MsgProp, Entries: []pb.Entry&#123;&#123;Type: pb.EntryConfChange, Data: data&#125;&#125;&#125;)&#125; // /etcd/raft/node.go 123456789101112131415161718192021222324252627282930313233343536373839404142func stepLeader(r *raft, m pb.Message) error &#123; switch m.Type &#123; case pb.MsgBeat: r.bcastHeartbeat() return nil case pb.MsgCheckQuorum: // ... case pb.MsgProp: // 配置变更请求消息也走这里，因此其处理流程同普通的日志请求是类似的 if len(m.Entries) == 0 &#123; r.logger.Panicf("%x stepped empty MsgProp", r.id) &#125; if _, ok := r.prs[r.id]; !ok &#123; return ErrProposalDropped &#125; if r.leadTransferee != None &#123; r.logger.Debugf("%x [term %d] transfer leadership to %x is in progress; dropping proposal", r.id, r.Term, r.leadTransferee) return ErrProposalDropped &#125; for i, e := range m.Entries &#123; if e.Type == pb.EntryConfChange &#123; // 若为配置变更请求消息，先判断其 pendingConfIndex（它限制了一次只能进行一个节点的变更） // 并且保证其不能超过 appliedIndex，因为只有一个变更请求被 pending，因此其肯定还未提交，因此正常情况下必须小于 appliedIndex if r.pendingConfIndex &gt; r.raftLog.applied &#123; r.logger.Infof("propose conf %s ignored since pending unapplied configuration [index %d, applied %d]", e.String(), r.pendingConfIndex, r.raftLog.applied) m.Entries[i] = pb.Entry&#123;Type: pb.EntryNormal&#125; &#125; else &#123; // 否则，若符合条件，则更新 pendingConfIndex 为对应的索引 r.pendingConfIndex = r.raftLog.lastIndex() + uint64(i) + 1 &#125; &#125; &#125; // 追加配置变更消息到节点的 unstable if !r.appendEntry(m.Entries...) &#123; return ErrProposalDropped &#125; // 广播配置变更消息到 follower 节点 r.bcastAppend() return nil &#125; &#125;&#125; // /etcd/raft/raft.go 关于bcastAppend()之后的逻辑，这里不再重复阐述，其同正常的日志消息的逻辑是一致的。因此，当上层应用调用网络传输组件将配置变更消息转发到集群其它节点时，其它节点同样会完成配置变更日志追加操作（同普通的日志请求消息追加的流程一致），而且leader节点处理响应同样与同步普通日志的响应的逻辑一致，这里也不再重复阐述。 最后，我们来了解当配置变更请求已经被同步到quorum节点后，准备提交的相关逻辑。这包括两个部分：其一是上层应用程序准备应用配置变更请求日志到状态机，然后会触发底层协议正式更新集群拓扑结构信息。 步骤一的相关代码如下（完整调用栈为：serverChannels() -&gt; publishEntries()）： 12345678910111213141516171819202122232425262728293031323334353637383940414243// whether all entries could be published.func (rc *raftNode) publishEntries(ents []raftpb.Entry) bool &#123; for i := range ents &#123; switch ents[i].Type &#123; // 准备应用普通的日志 case raftpb.EntryNormal: // ... // 若为配置变更请求日志 case raftpb.EntryConfChange: var cc raftpb.ConfChange // 1. 反序列化 cc.Unmarshal(ents[i].Data) // 2. 调用 node 的 ApplyConfChange 正式更新对应节点所维护的集群拓扑结构信息 // 即更新 progress 结构信息，这可能包括 learners 信息 // 并且会返回集群的配置信息，即各节点的具体角色 rc.confState = *rc.node.ApplyConfChange(cc) switch cc.Type &#123; // 3. 调用网络传输组件变更对应的代表节点网络传输实例的信息 case raftpb.ConfChangeAddNode: if len(cc.Context) &gt; 0 &#123; rc.transport.AddPeer(types.ID(cc.NodeID), []string&#123;string(cc.Context)&#125;) &#125; case raftpb.ConfChangeRemoveNode: if cc.NodeID == uint64(rc.id) &#123; log.Println("I've been removed from the cluster! Shutting down.") return false &#125; rc.transport.RemovePeer(types.ID(cc.NodeID)) &#125; &#125; // 4. 更新当前已应用的日志索引 rc.appliedIndex = ents[i].Index // special nil commit to signal replay has finished if ents[i].Index == rc.lastIndex &#123; select &#123; case rc.commitC &lt;- nil: case &lt;-rc.stopc: return false &#125; &#125; &#125; return true&#125; // /etcd/contrib/raftexample/raft.go 而底层协议会执行具体的更新集群拓扑（包括更换已有节点的角色）的操作。相关代码如下： 1234567891011121314func (n *node) ApplyConfChange(cc pb.ConfChange) *pb.ConfState &#123; var cs pb.ConfState select &#123; // 将配置变更请求实例放入 confc 管道，n.run() 函数会循环从 confc 管道中取 case n.confc &lt;- cc: case &lt;-n.done: &#125; select &#123; // 从 confstatec 管道中取出集群配置信息实例，返回给上层应用 raftNode case cs = &lt;-n.confstatec: case &lt;-n.done: &#125; return &amp;cs&#125; // /etcd/raft/node.go 12345678910111213141516171819202122232425262728293031323334353637383940func (r *raft) addNode(id uint64) &#123; r.addNodeOrLearnerNode(id, false)&#125; // etcd/raft/raft.gofunc (r *raft) addLearner(id uint64) &#123; r.addNodeOrLearnerNode(id, true)&#125; // etcd/raft/raft.gofunc (r *raft) addNodeOrLearnerNode(id uint64, isLearner bool) &#123; // 1. 获取此新加入节点的 progress 实例 pr := r.getProgress(id) // 2. 若为空，则表示为新加入的节点，设置其 progress 对象信息 if pr == nil &#123; r.setProgress(id, 0, r.raftLog.lastIndex()+1, isLearner) &#125; else &#123; // 3. 否则节点已存在，可能是更新节点的具体的角色 if isLearner &amp;&amp; !pr.IsLearner &#123; // can only change Learner to Voter r.logger.Infof("%x ignored addLearner: do not support changing %x from raft peer to learner.", r.id, id) return &#125; if isLearner == pr.IsLearner &#123; return &#125; // change Learner to Voter, use origin Learner progress // 3.1 考虑从 Learner 切换到 Voter 的角色（Voter 角色的节点保存在 prs 数组） delete(r.learnerPrs, id) pr.IsLearner = false r.prs[id] = pr &#125; // 4. 如果当前节点即为新加入的节点，则设置是否是 Learner if r.id == id &#123; r.isLearner = isLearner &#125; // When a node is first added, we should mark it as recently active. // Otherwise, CheckQuorum may cause us to step down if it is invoked // before the added node has a chance to communicate with us. // 5. 当节点第一次被加入时，需要标记节点最近为 活跃，否则在节点正式与 leader 通信前，可能会导致 leader 节点下台 pr = r.getProgress(id) pr.RecentActive = true&#125; // etcd/raft/raft.go 123456789101112131415161718// 从集群中移除指定节点func (r *raft) removeNode(id uint64) &#123; // 1. 从当前节点维护的其它节点的 progress 对象数组中移除欲删除节点的信息 r.delProgress(id) // do not try to commit or abort transferring if there is no nodes in the cluster. if len(r.prs) == 0 &amp;&amp; len(r.learnerPrs) == 0 &#123; return &#125; // 2. 节点删除操作，更新了 quorum 的大小，因此需要检查是否有 pending 的日志项已经达到提交的条件了 if r.maybeCommit() &#123; // 2.1 若确实提交了日志项，则将此消息进行广播 r.bcastAppend() &#125; // 3. 如果当前被移除的节点是即将当选为 Leader 的节点则中断此 Leader 交接过程 if r.state == StateLeader &amp;&amp; r.leadTransferee == id &#123; r.abortLeaderTransfer() &#125;&#125; // /etcd/raft/raft.go 至此，集群配置信息的变更的相关流程源码已经简单分析完毕。 简单小结，本文主要从两个方面阐述集群配置变更：首先结合论文从理论角度阐述为什么一次集群配置变更只能涉及到单个节点，从正反两个方面进行简单讨论证明。其次，结合etcd-raft中集群配置信息变更的代码具体叙述其中的流程，流程的第一阶段大部分已略过，这同普通日志的提交、追加、同步及响应过程类似，流程的第二阶段为节点执行集群拓扑配置信息的更新过程，直至此时，原集群中的节点，才能感知到新加入节点的存在，因此会更新其quorum。 参考文献 [1]. Ongaro D, Ousterhout J K. In search of an understandable consensus algorithm[C]//USENIX Annual Technical Conference. 2014: 305-319.[2]. https://github.com/etcd-io/etcd]]></content>
      <categories>
        <category>分布式系统</category>
        <category>分布式协调服务</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>分布式协调服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[etcd-raft snapshot实现源码简析]]></title>
    <url>%2F2019%2F01%2F14%2Fetcd-raft-snapshot%E5%AE%9E%E7%8E%B0%E6%BA%90%E7%A0%81%E7%AE%80%E6%9E%90%2F</url>
    <content type="text"><![CDATA[上一篇文章阐述了etcd-raft存储模块相关逻辑源码，准确而言是与日志存储相关，主要是围绕raftLog、unstable以及Storage/MemoryStorage展开，涉及流程较多，且结合流程逻辑阐述得比较详细。本文主题是snapshot，快照也属于存储的范畴，因此本文内容与上一篇文章存在重叠。不同的是，本文是围绕snapshot展开相关逻辑的分析。具体而言，首先简要介绍snapshot数据结构及重要接口实现，然后重点分析snapshot的全局逻辑（大部分源码已在上篇文章中分析），这主要包括如下四个子问题：其一，leader节点何时执行snapshot同步复制，其二，（应用程序）何时触发snapshot操作及，其三，（应用程序）如何应用snapshot数据，最后，follower节点何时以及如何应用snapshot数据事实上，第一、四两点是从底层协议的角度阐述与snapshot的相关操作，而第二、三点是从应用程序的角度来阐述snapshot相关操作（这其实涵盖了所有节点的操作）。但总的原则不变，目的是从整体上把握snapshot的逻辑，希望读者不要混淆。 需要注意，etcd-raft中关于存储的组件unstable、Storage以及WAL都包含快照，其中前二者的日志项包括快照存储在内存中，WAL将日志项以及快照数据存储在磁盘上。所谓快照实际上表示的是某一时刻系统的状态数据，那么在此时刻之前所保留的日志可以清除，因此它明显具有压缩日志项、节约磁盘空间的作用（在unstable及Storage中仍旧存储在内存）。但WAL与前二者不同，实际上它存储的snapshot数据是指存储它的元数据信息（原因是进行日志重放时，只要从快照元数据记录的日志索引开始即可，在【etcd-raft WAL日志管理源码简析】章节详述），并且每次构建快照数据，它不会覆盖已有的快照数据，而unstable及Storage在更新快照时则会进行替换。另外，etcd-raft还提供一个Snapshotter组件来构建Snapshot数据，它也属于快照数据，而且是增量更新并保存并持久化到磁盘的快照数据目录下的。下面介绍的Snapshot数据结构指的便是此Snapshot类型数据。因为它们相互关联，但作用不同。因此希望读者不要将这几种类型的snapshot混淆，仔细理解每一处的含义。 数据结构Snapshot的数据结构及其相关接口的实现较为简单，大致了解下即可，其中数据结构相关代码的主要目录为/etcd/etcdserver/api/snap/。 SnapshotSnapshot的数据结构如下所示： 123456789101112131415161718type Snapshot struct &#123; Data []byte `protobuf:"bytes,1,opt,name=data" json:"data,omitempty"` Metadata SnapshotMetadata `protobuf:"bytes,2,opt,name=metadata" json:"metadata"`&#125; // raft.pb.gotype SnapshotMetadata struct &#123; ConfState ConfState `protobuf:"bytes,1,opt,name=conf_state,json=confState" json:"conf_state"` // 系统构建快照时，最后一条日志项的索引值 Index uint64 `protobuf:"varint,2,opt,name=index" json:"index"` Term uint64 `protobuf:"varint,3,opt,name=term" json:"term"`&#125; // raft.pb.gotype ConfState struct &#123; // 表示集群中的节点的信息， Nodes 表示 leader及follower的id数组， // 而 Learners 表示集群中 learner 的 id 数组 Nodes []uint64 `protobuf:"varint,1,rep,name=nodes" json:"nodes,omitempty"` Learners []uint64 `protobuf:"varint,2,rep,name=learners" json:"learners,omitempty"`&#125; // raft.pb.go Snapshot的数据结构比较简单。我们下面简单了解其几个关键接口实现，首先是创建快照（文件）： 1234567891011121314151617181920212223242526272829303132// 构建快照文件，应用程序使用此接口来创建持久化的快照文件func (s *Snapshotter) SaveSnap(snapshot raftpb.Snapshot) error &#123; if raft.IsEmptySnap(snapshot) &#123; return nil &#125; return s.save(&amp;snapshot)&#125; // snapshotter.gofunc (s *Snapshotter) save(snapshot *raftpb.Snapshot) error &#123; start := time.Now() // 1. snapshot 文件命令规则：Term-Index.snap fname := fmt.Sprintf("%016x-%016x%s", snapshot.Metadata.Term, snapshot.Metadata.Index, snapSuffix) // 2. 序列化快照结构体数据 b := pbutil.MustMarshal(snapshot) // 3. 生成 crc 检验数据 crc := crc32.Update(0, crcTable, b) // 4. 生成快照 pb 结构数据 snap := snappb.Snapshot&#123;Crc: crc, Data: b&#125; // 5. 序列化 d, err := snap.Marshal() if err != nil &#123; return err &#125; snapMarshallingSec.Observe(time.Since(start).Seconds()) // 6. 构建快照文件路径 spath := filepath.Join(s.dir, fname) fsyncStart := time.Now() // 7. 快照文件存盘 err = pioutil.WriteAndSyncFile(spath, d, 0666) // ... return nil&#125; // snapshotter.go 再简单也解加载快照文件的过程： 12345678910111213141516// 加载快照文件，应用程序使用此接口来加载已存盘的快照文件func (s *Snapshotter) Load() (*raftpb.Snapshot, error) &#123; // 1. 获取快照文件目录下的所有快照谁的，并排序 names, err := s.snapNames() // ... // 2. 遍历快照文件集合，并加载每一个快照文件到内存，形成*raftpb.Snapshot实例 // load 的过程也比较简单，为创建的逆过程，包括反序列化及校验 crc var snap *raftpb.Snapshot for _, name := range names &#123; if snap, err = loadSnap(s.lg, s.dir, name); err == nil &#123; break &#125; &#125; // ... return snap, nil&#125; // snapshotter.go 快照数据结构比较简单，而且其相关接口的实现也比较简单，不多阐述。 关键流程上文提到，snapshot是系统某时刻状态的数据，在etcd-raft中会在多个地方存储snapshot数据，这包括unstable、Storage/MemoryStorage、WAL以及snap日志文件。正是因为涉及到多个存储的结构，因此整个关于snapshot的逻辑也稍显啰嗦。此部分代码的主要目录为：/etcd/raft/、/etcd/contrib/raftexample/。 snapshot 相关逻辑总结大概地，关于unstable日志存储，它与底层协议库直接交互，当leader节点发现follower节点进度过慢时（这也包括节点新加入的情形），会尝试发送MsgSnap，以加快节点状态同步（关于leader如何知道follower节点的日志过旧的原因是leader为每个follower维护了其目前的日志进度视图，这通过progress.go实现）。更准确来说，leader节点在发现本节点的日志过长时（MemoryStorage的实现规则是将长度大于 10000 ），会将更早的日志compact掉以节约内存（这在应用每次收到raft协议核心的Ready通知时，都会检查是否可以触发构建快照）。因此，若leader在给follower节点同步日志时，其可能发现对应的（需要从哪一项日志开始同步）日志项不存在，那么它会认为对应的日志已经被compact掉，因此尝试使用同步快照来代替（即发送MsgSnap消息）。换言之，unstable中的snapshot是来自于leader节点的同步（若follower节点允许直接执行快照同步，会将unstable中的快照直接进行替换）。 而关于Storage日志存储中的快照的来源，则可能来自两处，其一是节点自身主动构建snapshot，即应用程序发现达到快照构建条件时，便触发快照创建，所以这部分快照所对应的数据已存在于节点的应用状态机中，因此也不需要被重放，其主要目的是进行日志压缩。其二是leader节点通过MsgSnap将快照同步到follower节点的unstable中，然后follower的会生成Ready结构并传递给上层应用（里面封装了unstable的snapshot数据），因此最终由follower节点的应用将unstable中的snapshot应用到节点的Storage中。此处的快照的作用使用同步快照数据来代替同步日志项数据，因此减少了网络及 IO 开销，并加速了节点状态的同步。 对比unstable和Storage中快照数据的来源可知，unstable中的快照数据也必须交给上层应用，由上层应用进行WAL持久化、保存snap日志并应用到Storage中。而Storage中的快照数据的另外一个来源则由节点应用层自身直接创建，当然，此时也要作WAL持久化并且记录snap日志。由此可见，unstable与Storage中的日志存储的内容差别较大。另外需要强调的是，WAL日志中的快照部分存储snapshot元信息。而snap的数据存储方法由使用etcd-raft的应用实现，这取决于应用存储的数据类型（在etcd-raft中使用的是Snapshot数据结构来存储）。 综上，基本涵盖了整个关于snapshot流程的逻辑。下面结合代码更详细地阐述各个逻辑，本文将它分为四个方面进行叙述：其一，leader节点何时执行snapshot同步复制，其二，（应用程序）何时触发snapshot操作及，其三，（应用程序）如何应用snapshot数据，最后，follower节点何时以及如何应用snapshot数据。（这四点其实可以串联在一起叙述，但本文还是将它们分开叙述，希望读者能够理清并串联好整个逻辑） leader 节点执行 snapshot 同步复制上文提到当leader节点发现follower节点日志过旧时会使用同步snapshot复制来代替普通的日志同步（即发送MsgSnap而非MsgApp消息），这leadaer节点之所以能够发现follower节点的日志进度过慢的原因是，它使用为此follower节点保存的当前已同步日志索引来获取其unstable（也包括Storage）中的日志项（集合）时，发现不能成功获取对应的日志项，由此说明对应的日志项已经被compact掉了，即已经创建了快照。（关于如何创建快照，在下小节详述），因此，leader节点会向follower节点发送MsgSnap消息。相关代码及部分关键注释如下（下面只展示了关键函数的代码，整个流程为：stepLeader() -&gt; bcastAppend() -&gt; sendAppend() -&gt; maybeSendAppend()）： 123456789101112131415161718192021222324252627282930313233343536373839404142434445func (r *raft) maybeSendAppend(to uint64, sendIfEmpty bool) bool &#123; // 1. 获取 id 为 to 的 follower 的日志同步进度视图（具体查看 progress.go） pr := r.getProgress(to) // 2. 若对应 follower 节点未停止接收消息（停止的原因可能是在执行一个耗时操作，如应用快照数据） if pr.IsPaused() &#123; return false &#125; // 3. 构建消息实例 m := pb.Message&#123;&#125; m.To = to // 4. 通过 Next(为节点维护的下一个需要同步的日志索引)查找对应的 term 及 ents // 注意：1. maxMsgSize 是作为控制最大的传输日志项数量 // 2. 其在查找对应的 term 及 ents 时，也会查找 Storage 中的日志项集合 term, errt := r.raftLog.term(pr.Next - 1) ents, erre := r.raftLog.entries(pr.Next, r.maxMsgSize) if len(ents) == 0 &amp;&amp; !sendIfEmpty &#123; return false &#125; // 5. 如果查找失败，则考虑发送 MsgSnap 消息 if errt != nil || erre != nil &#123; // send snapshot if we failed to get term or entries // 此处记录对应节点最近是活跃 if !pr.RecentActive &#123; r.logger.Debugf("ignore sending snapshot to %x since it is not recently active", to) return false &#125; m.Type = pb.MsgSnap // 5.1 通过 raftLog 获取 snapshot 数据，若 unstable 中没有，则从 Storage 中获取 snapshot, err := r.raftLog.snapshot() // ... m.Snapshot = snapshot sindex, sterm := snapshot.Metadata.Index, snapshot.Metadata.Term r.logger.Debugf("%x [firstindex: %d, commit: %d] sent snapshot[index: %d, term: %d] to %x [%s]", r.id, r.raftLog.firstIndex(), r.raftLog.committed, sindex, sterm, to, pr) // 5.2 更新对应节点的 progress 实例对象 pr.becomeSnapshot(sindex) r.logger.Debugf("%x paused sending replication messages to %x [%s]", r.id, to, pr) &#125; else &#123; // 6. 否则进行日志同步，即发送正常的 MsgApp 消息 m.Type = pb.MsgApp // ... &#125; // 此处会将此消息打包到 raft.msgs 中，进一步会由 node 将其打包到 Ready 结构中，并转发给上层应用程序， // 由应用程序调用启用网络传输的组件，将消息发送出去（在上一篇文章中已经详述） r.send(m) return true&#125; // /etcd/raft/raft.go 何时触发 snapshot 操作事实上，触发snapshot操作是由上层应用程序完成的（并非底层raft协议核心库的功能）。触发构建快照的规则是：Storage中的日志条目的数量大于 10000，一旦达到此条件，则会将日志项索引不在过去 10000 条索引范围内的日志执行compact操作，并创建对应的快照数据，记录到WAL日志文件，以及snap快照文件中。相关代码及部分关键注释如下（下面只展示了关键函数的代码，整个流程为：startRaft() -&gt; serveChannels() -&gt; maybeTriggerSnapshot()）： 12345678910111213141516171819202122232425262728293031323334353637// 针对 memoryStorage 触发快照操作（如果满足条件）（注意这是对 memoryStorage 中保存的日志信息作快照）func (rc *raftNode) maybeTriggerSnapshot() &#123; // 0. 判断是否达到创建快照（compact）的条件 if rc.appliedIndex-rc.snapshotIndex &lt;= rc.snapCount &#123; return &#125; log.Printf("start snapshot [applied index: %d | last snapshot index: %d]", rc.appliedIndex, rc.snapshotIndex) // 1. 加载状态机中当前的状态数据（此方法由应用程序提供，在 kvstore 中） data, err := rc.getSnapshot() if err != nil &#123; log.Panic(err) &#125; // 2. 利用上述快照数据、以及 appliedIndex 等为 memoryStorage 实例创建快照（它会覆盖/更新 memoryStorage 已有的快照信息） snap, err := rc.raftStorage.CreateSnapshot(rc.appliedIndex, &amp;rc.confState, data) if err != nil &#123; panic(err) &#125; // 3. 保存快照到 WAL 日志（快照的索引/元数据信息） // 以及到 snap 日志文件中（它包含所有信息，一般而言，此 snap 结构由应用程序决定，etcd-raft 的实现包含了元数据及实际数据） if err := rc.saveSnap(snap); err != nil &#123; panic(err) &#125; // 4. 如果满足日志被 compact 的条件（防止内存中的日志项过多），则对内存中的日志项集合作 compact 操作 // compact 操作会丢弃 memoryStorage 日志项集中 compactIndex 之前的日志 compactIndex := uint64(1) if rc.appliedIndex &gt; snapshotCatchUpEntriesN &#123; compactIndex = rc.appliedIndex - snapshotCatchUpEntriesN &#125; if err := rc.raftStorage.Compact(compactIndex); err != nil &#123; panic(err) &#125; log.Printf("compacted log at index %d", compactIndex) // 5. 更新应用程序的快照位置(进度)信息 rc.snapshotIndex = rc.appliedIndex&#125; // /etcd/contrib/raftexample/raft.go 如何应用 snapshot 数据本小节所涉及的如何应用snapshot数据亦是针对应用程序而言（因为follower节点的unstable也会由协议库来应用leader节点发送的快照数据）。大概地，应用程序应用快照数据包含两个方面：其一，在节点刚启动时（宕机后重启）会进行日志重放，因此在重放过程中，若快照数据不为空（由snap存盘的快照数据，包括元信息及实际数据），则加载快照数据，并将其应用到Storage的快照中，而且会重放快照数据后的WAL日志项数据，并将其追加到Storage的日志项集。如此以来，节点便能重构其状态数据。其相关代码如下（实际完整调用为：startRaft() -&gt; serveChannels()）： 12345678910111213141516171819202122232425262728293031323334func (rc *raftNode) replayWAL() *wal.WAL &#123; log.Printf("replaying WAL of member %d", rc.id) // 1. 从 snap 快照文件中加载 快照数据（包含元信息及实际数据） snapshot := rc.loadSnapshot() // 2. 从指定日志索引位置打开 WAL 日志，以准备读取快照之后的日志项 w := rc.openWAL(snapshot) // 3. 读取指定索引位置后的所有日志 _, st, ents, err := w.ReadAll() if err != nil &#123; log.Fatalf("raftexample: failed to read WAL (%v)", err) &#125; // 4. 应用程序创建一个 MemoryStorage 实例 rc.raftStorage = raft.NewMemoryStorage() // 5. 若快照数据不为空，则将快照数据应用到 memoryStorage 中，替换掉已有的 snapshot 实例 if snapshot != nil &#123; rc.raftStorage.ApplySnapshot(*snapshot) &#125; // 6. 设置 HardState 到 memoryStorage 实例 rc.raftStorage.SetHardState(st) // append to storage so raft starts at the right place in log // 7. 将 WAL 重放的日志项集追加到 memoryStorage 实例（显然，此日志项不包含已经快照的日志项） rc.raftStorage.Append(ents) // send nil once lastIndex is published so client knows commit channel is current if len(ents) &gt; 0 &#123; // 8. 如果在快照后，仍存在日志项记录，则设置 lastIndex rc.lastIndex = ents[len(ents)-1].Index &#125; else &#123; // 9. 通知 kvstore，日志重放已经完毕，因此 kvstore 状态机也会从 snap 快照文件中加载数据 // 参见下面的代码片段 rc.commitC &lt;- nil &#125; return w&#125; // /etcd/raftexample/raft.go 12345678910111213141516171819202122232425262728293031323334353637383940func (s *kvstore) readCommits(commitC &lt;-chan *string, errorC &lt;-chan error) &#123; // raftNode 会将日志项 或 nil 放入 commitC 管道 for data := range commitC &#123; if data == nil &#123; // done replaying log; new data incoming // OR signaled to load snapshot // 从 snap 快照文件中加载数据，这包括两种情形： // 一是重启时重放日志， // 二是当 leader 向 follower 同步 snapshot 数据时，节点会将其应用到 unstable 及 Storage 中，同样会保存到 WAL 及 snap 文件 // 因此让状态机重新加载 snap 快照数据 snapshot, err := s.snapshotter.Load() // ... if err := s.recoverFromSnapshot(snapshot.Data); err != nil &#123; log.Panic(err) &#125; continue &#125; // 有新的数据已经被提交，因此将其应用到状态机中 var dataKv kv dec := gob.NewDecoder(bytes.NewBufferString(*data)) if err := dec.Decode(&amp;dataKv); err != nil &#123; log.Fatalf("raftexample: could not decode message (%v)", err) &#125; s.mu.Lock() s.kvStore[dataKv.Key] = dataKv.Val s.mu.Unlock() &#125;// ...&#125; // /etcd/raftexample/kvstore.gofunc (s *kvstore) recoverFromSnapshot(snapshot []byte) error &#123; var store map[string]string if err := json.Unmarshal(snapshot, &amp;store); err != nil &#123; return err &#125; s.mu.Lock() s.kvStore = store s.mu.Unlock() return nil&#125; // /etcd/raftexample/kvstore.go 其二，当leader节点同步快照数据给follower节点时，协议库会将快照数据应用到unstable（如果合法的话），然后，将Ready实例返回给应用程序，应用程序会检测到Ready结构中包含快照数据，因此，会将快照数据应用到Storage中。其相关代码如下（实际完整调用为：startRaft() -&gt; serveChannels()）： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051func (rc *raftNode) serveChannels() &#123; // 节点刚启动时，通过加载 snap 快照 &amp;&amp; 重放 WAL 日志，以将其应用到 memoryStorage 中 // 因此可以从 memoryStorage 中取出相关数据 snap, err := rc.raftStorage.Snapshot() rc.confState = snap.Metadata.ConfState rc.snapshotIndex = snap.Metadata.Index rc.appliedIndex = snap.Metadata.Index // ... go func() &#123; // ... // 应用程序状态机更新的事件循环，即循环等待底层协议库的 Ready 通知 for &#123; select &#123; case &lt;-ticker.C: rc.node.Tick() // 1. 收到底层协议库的 Ready 通知，关于 Ready 的结构已经在介绍 raftexample 文章中简要介绍 case rd := &lt;-rc.node.Ready(): // 2. 先将 Ready 中需要被持久化的数据保存到 WAL 日志文件（在消息转发前） rc.wal.Save(rd.HardState, rd.Entries) // 3. 如果 Ready 中的需要被持久化的快照不为空 // 此部分快照数据的来源是 leader 节点通过 MsgSnap 消息同步给 follower 节点 if !raft.IsEmptySnap(rd.Snapshot) &#123; // 3.1 保存快照到 WAL 日志（快照的索引/元数据信息）以及到 // snap 日志文件中（由应用程序来实现 snap 的数据结构，etcd-raft 的实现包含了快照的元信息及实际数据） // snap 日志文件会作为 状态机 (kvstore) 加载快照数据的来源（重启时加载，以及快照更新时重新加载） rc.saveSnap(rd.Snapshot) // 3.2 将快照应用到 memoryStorage 实例，替换掉其 snapshot 实例 rc.raftStorage.ApplySnapshot(rd.Snapshot) // 3.3 更新应用程序保存的快照信息 // 这包括更新 snapshotIndex、appliedIndex以及confState // 另外，还会通知 kvstore 重新加载 snap 文件的快照数据 rc.publishSnapshot(rd.Snapshot) &#125; // 4. 追加 Ready 结构中需要被持久化的信息（在消息转发前） rc.raftStorage.Append(rd.Entries) // 5. 转发 Ready 结构中的消息 rc.transport.Send(rd.Messages) // 6. 将日志应用到状态机（如果存在已经提交，即准备应用的日志项） // 会更新 appliedIndex if ok := rc.publishEntries(rc.entriesToApply(rd.CommittedEntries)); !ok &#123; rc.stop() return &#125; // 7. 触发快照操作（如果满足条件） rc.maybeTriggerSnapshot() // 8. 通知底层 raft 协议库实例 node，即告知当前 Ready 已经处理完毕，可以准备下一个 rc.node.Advance() // ... &#125; &#125;&#125; // /etcd/contrib/raftexample/raft.go follower 节点何时以及如何应用 snapshot 数据 最后，我们来简单了解follower节点收到leader节点的MsgSnap消息时，如何应用snapshot数据。其大致的逻辑为：当follower节点收到MsgSnap消息时，会判断此快照是否合法，若合法，则将共应用到unstable，并且更新相关的记录索引（如offset等），返回快照应用成功的消息。否则，返回快照已应用的消息（事实上回复消息没有明显区分应用失败还是成功，实际上是以lastIndex及commited来区分，这足以使得leader节点获悉follower节点日志进度）。同时follower节点还会更新集群的拓扑结构信息。再提醒一次，其最后调用的send()函数使得节点的上层应用程序将snapshot应用到Storage，并且作WAL日志以及snap快照。其相关代码为（实际完整调用为：stepFollower() -&gt; handleSnapshot() -&gt; restore()）： 12345678910111213141516func (r *raft) handleSnapshot(m pb.Message) &#123; sindex, sterm := m.Snapshot.Metadata.Index, m.Snapshot.Metadata.Term // 1. 若应用成功，则发送当前 raftLog 中（包括 unstable 及 Storage）的最后一项日志（之前的日志已作为快照数据存储） if r.restore(m.Snapshot) &#123; r.logger.Infof("%x [commit: %d] restored snapshot [index: %d, term: %d]", r.id, r.raftLog.committed, sindex, sterm) // 1.1 此 send 函数会将消息最终放入 Ready 结构中，node 会将 Ready 实例进行打包，以发送给节点上层应用程序 // 上层应用程序收到 Ready 通知后，检查到此消息中包含 snapshot 数据，则应用到 Storage，并作 WAL日志以及 snap 快照记录 r.send(pb.Message&#123;To: m.From, Type: pb.MsgAppResp, Index: r.raftLog.lastIndex()&#125;) &#125; else &#123; // 1.2 否则说明此快照数据已应用，则发送目前已提交的日志项的索引给 leader r.logger.Infof("%x [commit: %d] ignored snapshot [index: %d, term: %d]", r.id, r.raftLog.committed, sindex, sterm) r.send(pb.Message&#123;To: m.From, Type: pb.MsgAppResp, Index: r.raftLog.committed&#125;) &#125;&#125; // /etcd/raft/raft.go 12345678910111213141516171819202122232425262728293031323334353637func (r *raft) restore(s pb.Snapshot) bool &#123; // 1. 若快照消息中的快照索引小于已提交的日志项的日志索引，则不能应用此快照（之前已应用） if s.Metadata.Index &lt;= r.raftLog.committed &#123; return false &#125; // 2. 否则，若此索引与任期匹配 if r.raftLog.matchTerm(s.Metadata.Index, s.Metadata.Term) &#123; r.logger.Infof("%x [commit: %d, lastindex: %d, lastterm: %d] fast-forwarded commit to snapshot [index: %d, term: %d]", r.id, r.raftLog.committed, r.raftLog.lastIndex(), r.raftLog.lastTerm(), s.Metadata.Index, s.Metadata.Term) // 2.1 则更新 raftLog 中的 commited 字段，因为 committed 之前的日志代表已经提交 r.raftLog.commitTo(s.Metadata.Index) return false &#125; // The normal peer can't become learner. // 3. 这里是更新当前节点的集群的拓扑结构信息，即集群中包含哪些节点，它们各自的角色是什么 if !r.isLearner &#123; for _, id := range s.Metadata.ConfState.Learners &#123; if id == r.id &#123; r.logger.Errorf("%x can't become learner when restores snapshot [index: %d, term: %d]", r.id, s.Metadata.Index, s.Metadata.Term) return false &#125; &#125; &#125; r.logger.Infof("%x [commit: %d, lastindex: %d, lastterm: %d] starts to restore snapshot [index: %d, term: %d]", r.id, r.raftLog.committed, r.raftLog.lastIndex(), r.raftLog.lastTerm(), s.Metadata.Index, s.Metadata.Term) // 4. 更新 raftLog 的 commited 为快照消息中的索引，以及更换 unstable 中的 snapshot 实例为快照消息中的快照实例 // 并更新 unstable 的 offset 为 快照消息索引+1，更新 ents 字段为空 r.raftLog.restore(s) // 5. 以下同样是重构节点的拓扑信息 r.prs = make(map[uint64]*Progress) r.learnerPrs = make(map[uint64]*Progress) r.restoreNode(s.Metadata.ConfState.Nodes, false) r.restoreNode(s.Metadata.ConfState.Learners, true) return true&#125; // /etcd/raft/raft.go 至此，关于snapshot的逻辑已经阐述完毕。 简单小结，本文先是简单介绍了Snapshot的数据结构及接口实现（该Snapshot为重启的快照数据加载来源，并配合WAL日志重放记录，以重构节点宕机前的状态），然后围绕unstable及Storage总结了关于snapshot的流程逻辑，以在总体上把握snapshot的核心设计流程。最后，结合代码分析从四个方面梳理snapshot的相关流程，目的是加深读者对整个系统中如何使用snapshot的印象，并且需要理解为何如此设计。 参考文献 [1]. https://github.com/etcd-io/etcd[2]. etcd-raft snapshot实现分析]]></content>
      <categories>
        <category>分布式系统</category>
        <category>分布式系统协调服务</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>snapshot管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[etcd-raft 存储模块源码简析]]></title>
    <url>%2F2019%2F01%2F12%2Fetcd-raft-%E5%AD%98%E5%82%A8%E6%A8%A1%E5%9D%97%E6%BA%90%E7%A0%81%E7%AE%80%E6%9E%90%2F</url>
    <content type="text"><![CDATA[上一篇文章简单分析了etcd-raft WAL日志管理模块相关的源码。文章集中在WAL库提供的相关接口的阐述，而未将其与raft协议核心库关联起来，即尚未阐述raft协议核心库如何使用WAL日志库，并且上一篇文章虽然是以应用程序使用WAL库为切入点分析，但并没有阐述清楚WAL、Storage以及unstable三者的关联，鉴于三者提供日志存储的功能。本文的重点是分析etcd-raft 存储模块，它包括Storage及其实现memoryStorage（etcd为应用程序提供的一个Storage实现的范例）、unstable以及raftLog三个核心数据结构。另外，阐述Storage同应用程序的交互的细节以及raft协议库与raftLog的交互相关的逻辑，后者包括raftLog重要接口的实现，以及raft协议库的一个典型的简单的日志追加流程（即从leader追加日志，然后广播给follower节点，然后follower节点同样进行日志项的追加，最后leader节点处理follower节点的响应各个环节中日志追加的具体逻辑）。 （需要提醒的是，整篇文章较长，因此读者可以选择部分小节进行针对性参考，每个小节的最开始都有概括该小节的内容，各小节的分析是独立进行的。）同样我们先重点了解几个数据结构，主要包括raftLog、unstable以及Storage &amp; MemoryStorage，读者可以深入源码文件仔细查看相关字段及逻辑（主要涉及的目录/etcd/raft/，也有示例应用的部分代码/etcd/contrib/raftexample）。通过了解相关数据结构，就能大概推测出其相关功能。 数据结构raftLograftLog为raft协议核心处理日志复制提供接口，raft协议库对日志的操作都基于raftLog实施。换言之，协议核心库不会直接同Storage及WAL直接交互。raftLog的数据结构如下： 12345678910111213141516type raftLog struct &#123; // 包含从上一次快照以来的所有已被持久化的日志项集合 storage Storage // 包含所有未被持久化（一旦宕机便丢失）的日志项集合及快照 // 它们会被持久化到 storage unstable unstable // 已被持久化的最高的日志项的索引编号 committed uint64 // 已经被应用程序应用到状态机的最高手日志项索引编号 // 必须保证： applied &lt;= committed applied uint64 logger Logger // 调用 nextEnts 时，返回的日志项集合的最大的大小 // nextEnts 函数返回应用程序已经可以应用到状态机的日志项集合 maxNextEntsSize uint64&#125; // log.go 关于storage及unstable两个数据我们暂时不知道其具体作用，比如它们是如何被raftLog使用的，它们的区别是什么？我们先继续了解这两个数据结构的内容。 unstableunstable顾名思义，表示非持久化的存储。其数据结构如下： 1234567891011121314// unstable.entries[i] 存储的日志的索引为 i+unstable.offset// 另外，unstable.offset 可能会小于 storage.entries 中的最大的索引// 此时，当继续向 storage 同步日志时，需要先截断其大于 unstable.offset 的部分type unstable struct &#123; // the incoming unstable snapshot, if any. // unstable 包含的快照数据 snapshot *pb.Snapshot // 所有未被写入 storage 的日志 entries []pb.Entry // entries 日志集合中起始的日志项编号 offset uint64 logger Logger&#125; // log_unstable.go Storage &amp; MemoryStorageStorage表示etcd-raft提供的持久化存储的接口。应用程序负责实现此接口，以将日志信息落盘。并且，若在操作过程此持久化存储时出现错误，则应用程序应该停止对相应的 raft 实例的操作，并需要执行清理或恢复的操作。其数据结构如下： 12345678910111213141516171819202122232425// Storage 接口需由应用程序来实现，以从存储中以出日志信息// 如果在操作过程中出现错误，则应用程序应该停止对相应的 raft 实例的操作，并需要执行清理或恢复的操作type Storage interface &#123; // 返回 HardState 及 ConfState 数据 InitialState() (pb.HardState, pb.ConfState, error) // 返回 [lo, hi) 范围的日志项集合 Entries(lo, hi, maxSize uint64) ([]pb.Entry, error) // 返回指定日志项索引的 term Term(i uint64) (uint64, error) // 返回日志项中最后一条日志的索引编号 LastIndex() (uint64, error) // 返回日志项中最后第一条日志的索引编号，注意在其被创建时，日志项集合会被填充一项 dummy entry FirstIndex() (uint64, error) // 返回最近一次的快照数据，如果快照不可用，则返回出错 Snapshot() (pb.Snapshot, error)&#125; // storage.go// MemoryStorage 实现了 Storage 接口，注意 MemoryStorage 也是基于内存的type MemoryStorage struct &#123; sync.Mutex hardState pb.HardState snapshot pb.Snapshot // ents[i] 存储的日志项的编号为 i+snapshot.Metadata.Index，即要把快照考虑在内 ents []pb.Entry&#125; // storage.go 关键流程从上述数据结构中发现raftLog封装了storage及unstable。而且大概看一下raftLog中各个接口，发现主要不是同unstable进行交互（也有利用storage的数据）。所以，我们决定从两个方面来明晰主几个数据结构的作用。包括应用程序与Storage交互，以及raft协议核心同raftLog(unstable/storage)交互。希望通过从具体功能实现切入来摸索梳理相关逻辑，并结合数据结构，以达到由外至里尽可能把握其设计原理的效果。 应用程序与 Storage 交互为了让读者有更好的理解，本文仍旧从raftexample中的startRaft()开始追溯与上述三个数据结构相关的逻辑，以明晰它们三者的作用。我们从两个方面来阐述交互的大致逻辑，包括应用程序启动（此时raft实例也会被初始化）以及上层应用收到底层raft协议核心的通知(Ready)时所执行的相关操作。 应用初始化首先来看第一个：在startRaft()函数中，我们先深入日志重放代码rc.wal = rc.replayWAL()： 123456789101112131415161718192021222324252627282930313233// 重放 WAL 日志到 raft 实例func (rc *raftNode) replayWAL() *wal.WAL &#123; log.Printf("replaying WAL of member %d", rc.id) // 1. 从持久化存储中加载 快照数据 snapshot := rc.loadSnapshot() // 2. 从指定日志索引位置打开 WAL 日志，以准备读取日志 w := rc.openWAL(snapshot) // 3. 读取指定索引位置后的所有日志 _, st, ents, err := w.ReadAll() if err != nil &#123; log.Fatalf("raftexample: failed to read WAL (%v)", err) &#125; // 4. 应用程序创建一个 MemoryStorage 实例 rc.raftStorage = raft.NewMemoryStorage() // 5. 若快照数据不为空，则将快照数据应用到 memoryStorage 中 if snapshot != nil &#123; rc.raftStorage.ApplySnapshot(*snapshot) &#125; // 6. 设置 HardState 到 memoryStorage 实例 rc.raftStorage.SetHardState(st) // append to storage so raft starts at the right place in log // 7. 将日志项追加到 memoryStorage 实例，注意，此日志项不包含已经快照的日志项 rc.raftStorage.Append(ents) // send nil once lastIndex is published so client knows commit channel is current if len(ents) &gt; 0 &#123; // 8. 如果在快照后，仍存在日志项记录，则设置 lastIndex rc.lastIndex = ents[len(ents)-1].Index &#125; else &#123; // 9. 通知 kvstore，日志重放已经完毕 rc.commitC &lt;- nil &#125; return w&#125; // raft.go 我们重点关注与memoryStorage相关的逻辑。步骤 4 创建了一个memoryStorage实例，创建逻辑也比较简单： 1234567// NewMemoryStorage creates an empty MemoryStorage.func NewMemoryStorage() *MemoryStorage &#123; return &amp;MemoryStorage&#123; // When starting from scratch populate the list with a dummy entry at term zero. ents: make([]pb.Entry, 1), &#125;&#125; // storage.go 而步骤 5 将快照数据应用到了memoryStorage实例，其逻辑也较为简单： 12345678910111213141516// ApplySnapshot overwrites the contents of this Storage object with// those of the given snapshot.func (ms *MemoryStorage) ApplySnapshot(snap pb.Snapshot) error &#123; ms.Lock() defer ms.Unlock() //handle check for old snapshot being applied msIndex := ms.snapshot.Metadata.Index snapIndex := snap.Metadata.Index if msIndex &gt;= snapIndex &#123; return ErrSnapOutOfDate &#125; ms.snapshot = snap ms.ents = []pb.Entry&#123;&#123;Term: snap.Metadata.Term, Index: snap.Metadata.Index&#125;&#125; return nil&#125; // storage.go 从代码可以看出，其只是将快照直接进行替换，并将快照的当前索引及任期存入日志项集合。而步骤 6 较为简单，在此略过。简单了解一下步骤 7，它往memoryStorage的日志项集合中追加日志项集合，其代码如下： 12345678910111213141516171819202122232425262728293031323334// 新追加的日志项必须是连续的，且 entries[0].Index &gt; ms.entries[0].Indexfunc (ms *MemoryStorage) Append(entries []pb.Entry) error &#123; if len(entries) == 0 &#123; return nil &#125; ms.Lock() defer ms.Unlock() first := ms.firstIndex() last := entries[0].Index + uint64(len(entries)) - 1 // shortcut if there is no new entry. if last &lt; first &#123; return nil &#125; // truncate compacted entries // 若已有的 ms.ents 被 compact 了，则新追加的日志项集有可能为被 compact 掉中的一部分 // 因此，需要将那一部进行移除，以免重复追加 if first &gt; entries[0].Index &#123; entries = entries[first-entries[0].Index:] &#125; // 判断新追加日志与已有日志是否有重叠，若是，则需要覆盖已有日志，否则直接追加到已有日志后面 offset := entries[0].Index - ms.ents[0].Index switch &#123; case uint64(len(ms.ents)) &gt; offset: ms.ents = append([]pb.Entry&#123;&#125;, ms.ents[:offset]...) ms.ents = append(ms.ents, entries...) case uint64(len(ms.ents)) == offset: ms.ents = append(ms.ents, entries...) default: raftLogger.Panicf("missing log entry [last: %d, append at: %d]", ms.lastIndex(), entries[0].Index) &#125; return nil&#125; // storage.go 日志追加流程基本符合逻辑，但需要注意如果已有日志项集合被compact，且追加的日志与已有日志重叠的情况。关于日志项被compact的相关逻辑，后面会叙述。现在作一个小结，上述逻辑发生在应用启动初始化时机，换言之，这包括两种情况，其一是整个集群刚启动，应用程序所在的节点没有任何持久化的快照记录；其二是此节点宕机，并且错过了部分日志的追加与快照操作，因此，应用程序需要恢复此节点对应的raft实例的memoryStorge信息以及增加快照数据（节点新加入时，也大致符合这种情况）。换言之，在有节点落后、刚重启、新加入的情况下，给这些节点的数据多数来自已落盘部分（持久化的快照及WAL日志）。 处理 raft 协议库 Ready 消息接下来，继续了解第二处交互逻辑：在serverChannels()函数中，应用等待接收底层raft协议库的通知： 123456789101112131415161718192021222324252627282930313233343536// 应用程序状态机更新的事件循环，即循环等待底层协议库的 Ready 通知for &#123; select &#123; case &lt;-ticker.C: rc.node.Tick() // store raft entries to wal, then publish over commit channel // 1. 收到底层协议库的 Ready 通知，关于 Ready 结构已经在介绍 raftexample 文章中简要介绍 case rd := &lt;-rc.node.Ready(): // 2. 先将 Ready 中需要被持久化的数据保存到 WAL 日志文件（在消息转发前） rc.wal.Save(rd.HardState, rd.Entries) // 3. 如果 Ready 中的需要被持久化的快照不为空 if !raft.IsEmptySnap(rd.Snapshot) &#123; // 3.1 保存快照到 WAL 日志（快照索引/元数据信息）以及到 snap (后面文章会介绍)中 rc.saveSnap(rd.Snapshot) // 3.2 将快照应用到 memoryStorage 实例 rc.raftStorage.ApplySnapshot(rd.Snapshot) // 3.3 更新应用程序保存的快照信息 rc.publishSnapshot(rd.Snapshot) &#125; // 4. 追加 Ready 结构中需要被持久化的信息（在消息转发前） rc.raftStorage.Append(rd.Entries) // 5. 转发 Ready 结构中的消息 rc.transport.Send(rd.Messages) // 6. 将日志应用到状态机（如果存在已经提交，即准备应用的日志项） if ok := rc.publishEntries(rc.entriesToApply(rd.CommittedEntries)); !ok &#123; rc.stop() return &#125; // 7. 触发快照操作（如果满足条件） rc.maybeTriggerSnapshot() // 8. 通知底层 raft 协议库实例 node，即告知当前 Ready 已经处理完毕，可以准备下一个 rc.node.Advance() // ... &#125;&#125; // raft.go 同样，重点关注与memoryStorage相关的逻辑（其余的逻辑在【etcd raftexample 源码简析】中已阐述）。在步骤 3 中，当Ready结构中的快照不为空时，需要保存快照至一系列地方。其中步骤 3.1 的调用代码如下： 1234567891011121314151617func (rc *raftNode) saveSnap(snap raftpb.Snapshot) error &#123; // must save the snapshot index to the WAL before saving the // snapshot to maintain the invariant that we only Open the // wal at previously-saved snapshot indexes. walSnap := walpb.Snapshot&#123; // 1. 构建快照索引（在【WAL 日志管理源码解析】文章有阐述）信息 Index: snap.Metadata.Index, Term: snap.Metadata.Term, &#125; // 2. 保存快照索引信息到 WAL 日志 if err := rc.wal.SaveSnapshot(walSnap); err != nil &#123; return err &#125; // 3. 保存快照完整数据到 snap（后面文章阐述） if err := rc.snapshotter.SaveSnap(snap); err != nil &#123; return err &#125; // 4. 更新 WAL 日志文件锁范围 return rc.wal.ReleaseLockTo(snap.Metadata.Index)&#125; // raft.go 而步骤 3.2 在上文已阐述过，即将快照替换到memoryStorage关联的快照实例。而最后 3.3 的相关代码如下： 1234567891011121314151617// 更新应用程序保存的快照位置信息，并且通知上层应用(kvstore)可以重新加载快照func (rc *raftNode) publishSnapshot(snapshotToSave raftpb.Snapshot) &#123; if raft.IsEmptySnap(snapshotToSave) &#123; return &#125; log.Printf("publishing snapshot at index %d", rc.snapshotIndex) defer log.Printf("finished publishing snapshot at index %d", rc.snapshotIndex) // 1. 检验快照数据 if snapshotToSave.Metadata.Index &lt;= rc.appliedIndex &#123; log.Fatalf("snapshot index [%d] should &gt; progress.appliedIndex [%d]", snapshotToSave.Metadata.Index, rc.appliedIndex) &#125; // 2. 通知上层应用(kvstore)可以重新加载快照 rc.commitC &lt;- nil // trigger kvstore to load snapshot // 3. 更新应用程序(raftNode)保存的快照位置信息，以及当前已应用到状态机的日志的索引信息 rc.confState = snapshotToSave.Metadata.ConfState rc.snapshotIndex = snapshotToSave.Metadata.Index rc.appliedIndex = snapshotToSave.Metadata.Index&#125; // raft.go 小结步骤 3 逻辑（包括 3.1-3.3）：若底层协议传来的Ready结构中包含的快照不为空，则首先将快照保存到WAL日志（索引信息），并保存完整快照信息到snap，然后将快照替换掉内存(memoryStorage)关联的快照实例，最后更新应用保存的快照位置信息及当前已应用日志位置信息，并触发应用（状态机）重新加载快照。 同样，步骤 4 已在上文阐述过。 123456789101112131415161718192021222324252627282930313233343536// 针对 memoryStorage 触发快照操作（如果满足条件）//（注意这是对 memoryStorage 中保存的日志信息作快照）func (rc *raftNode) maybeTriggerSnapshot() &#123; if rc.appliedIndex-rc.snapshotIndex &lt;= rc.snapCount &#123; return &#125; log.Printf("start snapshot [applied index: %d | last snapshot index: %d]", rc.appliedIndex, rc.snapshotIndex) // 1. 加载状态机中当前的信息（此方法由应用程序提供，在 kvstore 中） data, err := rc.getSnapshot() if err != nil &#123; log.Panic(err) &#125; // 2. 利用上述快照数据、以及 appliedIndex 等为 memoryStorage 实例创建快照（它会覆盖/更新 memoryStorage 已有的快照信息） snap, err := rc.raftStorage.CreateSnapshot(rc.appliedIndex, &amp;rc.confState, data) if err != nil &#123; panic(err) &#125; // 3. 保存快照到 WAL 日志（快照的索引/元数据信息）以及到 snap（后面文章会介绍）中 if err := rc.saveSnap(snap); err != nil &#123; panic(err) &#125;// 4. 若满足日志被 compact 的条件（防止内存中日志项过多），则对内存中日志项集合作 compact 操作 // compact 操作会丢弃 memoryStorage 日志项中 compactIndex 之前的日志 compactIndex := uint64(1) if rc.appliedIndex &gt; snapshotCatchUpEntriesN &#123; compactIndex = rc.appliedIndex - snapshotCatchUpEntriesN &#125; if err := rc.raftStorage.Compact(compactIndex); err != nil &#123; panic(err) &#125; log.Printf("compacted log at index %d", compactIndex) // 5. 更新应用程序的快照位置信息 rc.snapshotIndex = rc.appliedIndex&#125; // raft.go 上述代码逻辑比较简单，简单而言，它会从状态机中加载快照，然后覆盖raft实例关联的memoryStorage中的快照实例，而且，还会保存快照信息（上文已阐述），最后检查memoryStorage是否可以执行compact操作。其中memoryStorage的compact操作的逻辑也比较简单，即丢弃compactIndex之前的日志（注意：并不是丢弃 appliedIndex之前的日志，也不是丢弃snapshotIndex之前的日志）： 1234567891011121314151617181920// compact 操作会丢弃 compactIndex 之前的日志，// 应用程序应该检查 compactIndex 应该在 appliedIndex 之前，因为，只允许 compact 掉已经 applyfunc (ms *MemoryStorage) Compact(compactIndex uint64) error &#123; ms.Lock() defer ms.Unlock() offset := ms.ents[0].Index if compactIndex &lt;= offset &#123; return ErrCompacted &#125; if compactIndex &gt; ms.lastIndex() &#123; raftLogger.Panicf("compact %d is out of bound lastindex(%d)", compactIndex, ms.lastIndex()) &#125; i := compactIndex - offset ents := make([]pb.Entry, 1, 1+uint64(len(ms.ents))-i) ents[0].Index = ms.ents[i].Index ents[0].Term = ms.ents[i].Term ents = append(ents, ms.ents[i+1:]...) ms.ents = ents return nil&#125; // storage.go 至此，关于应用程序与memoryStorage/Storage的简单交互过程已经阐述完毕。作个简单小结：通过上述的分析，我们仔细关联各个流程，可以发现WAL中的日志项是已落盘的，而Storage则是etcd-raft提供的被应用程序访问已落盘数据的接口，memoryStorage实现了这个接口(Storage)（而且，从它的各个操作逻辑来看，它只是简单地将WAL已落盘的数据进行了拷贝，当然还有一个compact过程，如果满足条件的话），个人感觉似乎有一点多余（从网上查找资料发现，一般而言，Storage的实现应该是WAL与cache算法的组合，那显然，在这里的memoryStorage并没有实现某种cache算法）。另外值得注意的是，在etcd-raft的实现中，协议核心并不与memoryStorage直接交互，都是应用程序与memoryStorage交互。 raft 协议库与 raftLog 交互这部分内容包括两个部分：其一是先继续了解raftLog内部一些重要接口的实现，以更进一步理解直接与raft协议库交互的raftLog的实现原理。其二挑选一个简单的raft协议库的逻辑——日志追加操作以查看协议库使用raftLog的细节。 raftLog 接口实现逻辑首先了解raftLog相关接口的实现细则。在上文已经初步了解过raftLog的数据结构。其构造函数如下： 123456789101112131415161718192021222324252627func newLog(storage Storage, logger Logger) *raftLog &#123; return newLogWithSize(storage, logger, noLimit)&#125;// newLogWithSize returns a log using the given storage and max// message size.func newLogWithSize(storage Storage, logger Logger, maxNextEntsSize uint64) *raftLog &#123; if storage == nil &#123; // storage 不能为空！ log.Panic("storage must not be nil") &#125; // 利用应用传入的 storage 及 logger 以及 maxNextEntsSize（如果有的话）构建 raftLog 实例 log := &amp;raftLog&#123; storage: storage, logger: logger, maxNextEntsSize: maxNextEntsSize, &#125; firstIndex, err := storage.FirstIndex() lastIndex, err := storage.LastIndex() // 将 unstable 的 offset 初始化为 storage 的 lastIndex+1 log.unstable.offset = lastIndex + 1 log.unstable.logger = logger // Initialize our committed and applied pointers to the time of the last compaction. // 将 raftLog 的 commited 及 applied 初始化为 firstIndex-1，即 storage 中第一项日志的索引号， // 因为第一项日志为已经被提交的（也是已经被快照的），可以仔细察看 storage 的 ApplySnapshot 逻辑 log.committed = firstIndex - 1 log.applied = firstIndex - 1 return log&#125; // log.go 此构造函数在初始化raft结构时会被调用（具体可以查看代码）。从上述构造函数逻辑来看，unstable似乎是从storage最后一条日志后开始存储，换言之，从raft协议库的角度，unstable存储更新的日志。。我们可以从下面的几个函数来进一步证实这一点： 12345678910111213141516171819202122func (l *raftLog) snapshot() (pb.Snapshot, error) &#123; if l.unstable.snapshot != nil &#123; return *l.unstable.snapshot, nil &#125; return l.storage.Snapshot()&#125; // log.gofunc (l *raftLog) firstIndex() uint64 &#123; if i, ok := l.unstable.maybeFirstIndex(); ok &#123; return i &#125; index, err := l.storage.FirstIndex() return index&#125; // log.gofunc (l *raftLog) lastIndex() uint64 &#123; if i, ok := l.unstable.maybeLastIndex(); ok &#123; return i &#125; i, err := l.storage.LastIndex() return i&#125; // log.go 当raftLog都是先将unstable关联的数据返回给raft核心库。我们后面会来仔细了解这些函数如何被调用。我们继续了解两个较为重要的接口： 12345678910111213141516171819202122232425262728293031323334353637// 日志追加，返回(0, false)若日志项不能被追加，否则返回 (最后一条日志索引, true)func (l *raftLog) maybeAppend(index, logTerm, committed uint64, ents ...pb.Entry) (lastnewi uint64, ok bool) &#123; if l.matchTerm(index, logTerm) &#123; // 1. 检验 index 与 term 是否匹配 lastnewi = index + uint64(len(ents)) // 2. 最后一条日志索引 ci := l.findConflict(ents) // 3. 检查此次追加的日志项是否与已有的存在冲突（论文中有详述冲突情况） switch &#123; case ci == 0: // 3.1 没有冲突，则直接提交（如果可以提交的话） case ci &lt;= l.committed: // 3.2 冲突的索引不能比已经提交的索引还要小！ l.logger.Panicf("entry %d conflict with committed entry [committed(%d)]", ci, l.committed) default: // 3.3 否则，与已有日志（未提交的）有冲突 //（也有可能没有冲突，详情在 findConflict 函数中说明），并追加日志，最后提交 offset := index + 1 l.append(ents[ci-offset:]...) &#125; l.commitTo(min(committed, lastnewi)) return lastnewi, true &#125; return 0, false&#125; // log.go// 即检查追加的日志项集合与已有的日志项（包括已提交与未提交）是否存在冲突，返回第一次冲突的日志索引（如果有的话）// 另外，需要注意的是，要追加的日志必须要连续// 如果没有冲突，并且已有的日志包含了要追加的所有日志项，则返回 0// 如果没有冲突，并且要追加的日志包含有新日志项，则返回第一次新的日志项// 日志项冲突判定的条件是: 相同的 index 不同的 termfunc (l *raftLog) findConflict(ents []pb.Entry) uint64 &#123; for _, ne := range ents &#123; if !l.matchTerm(ne.Index, ne.Term) &#123; if ne.Index &lt;= l.lastIndex() &#123; l.logger.Infof("found conflict at index %d [existing term: %d, conflicting term: %d]", ne.Index, l.zeroTermOnErrCompacted(l.term(ne.Index)), ne.Term) &#125; return ne.Index &#125; &#125; return 0&#125; raft 协议库追加日志接下来，我们把重点放在/etcd/raft.log文件中，并梳理日志追加的整体逻辑（关于文件中的数据结构以及一些细节我们暂且忽略，重点关注其逻辑流程）。为了让读者更容易理解整个过程的来龙去脉，我们仍然从应用程序提交日志开始切入，以将整个流程梳理一遍（同时，下文所展示的代码大部分只包含关键的逻辑）。下面的逻辑分析会大致依据实际逻辑顺利展开，即从应用程序提交日志开始，到leader节点在本地追加日志（若是follower节点收到请求消息，则一般是转发给leader节点），然后到leader节点广播日志给follower节点，最后到follower节点的日志追加，以及leader如何处理follower节点日志追加的响应消息。 leader 节点追加日志我们从应用程序向raft协议库提交日志请求开始，当然，在应用启动初始化时，其实也涉及到raft协议库的初始化启动，如下代码所示： 1234567891011121314151617181920212223242526272829func (rc *raftNode) startRaft() &#123; // ... rpeers := make([]raft.Peer, len(rc.peers)) for i := range rpeers &#123; rpeers[i] = raft.Peer&#123;ID: uint64(i + 1)&#125; &#125; c := &amp;raft.Config&#123; ID: uint64(rc.id), ElectionTick: 10, HeartbeatTick: 1, Storage: rc.raftStorage, MaxSizePerMsg: 1024 * 1024, MaxInflightMsgs: 256, MaxUncommittedEntriesSize: 1 &lt;&lt; 30, &#125; if oldwal &#123; rc.node = raft.RestartNode(c) &#125; else &#123; startPeers := rpeers if rc.join &#123; startPeers = nil &#125; // 启动底层 raft 协议核心库，并将 Config 及集群中节点信息传入 rc.node = raft.StartNode(c, startPeers) &#125; // ... go rc.serveRaft() go rc.serveChannels()&#125; // /etcd/contrib/raftexample/raft.go 在raft.StartNode()函数中，创建node，它表示底层raft协议的实例，构建了raft实例（封装协议实现的核心逻辑），并且调用了n.run()以等待上层应用程序向node提交请求，关键代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091func StartNode(c *Config, peers []Peer) Node &#123; r := newRaft(c) // ... n := newNode() // ... go n.run(r) return &amp;n&#125; // node.gofunc (n *node) run(r *raft) &#123; // ... for &#123; if advancec != nil &#123; readyc = nil &#125; else &#123; rd = newReady(r, prevSoftSt, prevHardSt) if rd.containsUpdates() &#123; readyc = n.readyc &#125; else &#123; readyc = nil &#125; &#125; // ... select &#123; case pm := &lt;-propc: m := pm.m m.From = r.id err := r.Step(m) // 调用 Step 函数来进行处理 if pm.result != nil &#123; pm.result &lt;- err close(pm.result) &#125; case m := &lt;-n.recvc: // 此处的逻辑会在 follower 节点接收 leader 节点广播的消息时调用 // 具体地，会在下文的 【follower 节点追加日志】 小节涉及到 // filter out response message from unknown From. if pr := r.getProgress(m.From); pr != nil || !IsResponseMsg(m.Type) &#123; r.Step(m) &#125; // ... case readyc &lt;- rd: if rd.SoftState != nil &#123; prevSoftSt = rd.SoftState &#125; if len(rd.Entries) &gt; 0 &#123; prevLastUnstablei = rd.Entries[len(rd.Entries)-1].Index prevLastUnstablet = rd.Entries[len(rd.Entries)-1].Term havePrevLastUnstablei = true &#125; if !IsEmptyHardState(rd.HardState) &#123; prevHardSt = rd.HardState &#125; if !IsEmptySnap(rd.Snapshot) &#123; prevSnapi = rd.Snapshot.Metadata.Index &#125; if index := rd.appliedCursor(); index != 0 &#123; applyingToI = index &#125; r.msgs = nil r.readStates = nil r.reduceUncommittedSize(rd.CommittedEntries) advancec = n.advancec case &lt;-advancec: // ... // ... &#125; &#125;&#125; // node.gofunc newReady(r *raft, prevSoftSt *SoftState, prevHardSt pb.HardState) Ready &#123; rd := Ready&#123; Entries: r.raftLog.unstableEntries(), CommittedEntries: r.raftLog.nextEnts(), Messages: r.msgs, // Step 函数将消息进行广播实际上会发送到此 msg 结构中 &#125; if softSt := r.softState(); !softSt.equal(prevSoftSt) &#123; rd.SoftState = softSt &#125; if hardSt := r.hardState(); !isHardStateEqual(hardSt, prevHardSt) &#123; rd.HardState = hardSt &#125; if r.raftLog.unstable.snapshot != nil &#123; rd.Snapshot = *r.raftLog.unstable.snapshot &#125; if len(r.readStates) != 0 &#123; rd.ReadStates = r.readStates &#125; rd.MustSync = MustSync(r.hardState(), prevHardSt, len(rd.Entries)) return rd&#125; // node.go 从上面展示的三个函数，可以发现程序会开一个go routine通过channel来处理所有现应用程序（当然也有内部的一些逻辑）的交互。当node从propc管道中收到应用程序提交的请求后，它会将此请求交给Step函数处理，Step函数在经过一系列检查之后（比如检查term），会调用step函数（这里只考虑正常的MsgProp消息），step函数对于不同的角色的节点其实现不同，典型的，对于leader节点，其实现为stepLeader。另外，在循环中，程序会将打包好Ready结构通过readc的管道发送给应用程序，然后等待从advancec管道中接收应用程序的返回消息。下面，我们从stepLeader函数开始来一步步梳理leader的日志追加逻辑： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667func stepLeader(r *raft, m pb.Message) error &#123; // These message types do not require any progress for m.From. switch m.Type &#123; case pb.MsgBeat: // ... return nil case pb.MsgProp: // ... // 1. 追加日志 if !r.appendEntry(m.Entries...) &#123; return ErrProposalDropped &#125; // 2. 广播日志追加 r.bcastAppend() return nil case pb.MsgReadIndex: // ... return nil &#125; // ... return nil&#125; // /etcd/raft/raft.gofunc (r *raft) appendEntry(es ...pb.Entry) (accepted bool) &#123; // ... // use latest "last" index after truncate/append li = r.raftLog.append(es...) r.getProgress(r.id).maybeUpdate(li) // Regardless of maybeCommit's return, our caller will call bcastAppend. r.maybeCommit() return true&#125; // /etcd/raft/raft.gofunc (l *raftLog) append(ents ...pb.Entry) uint64 &#123; // ... l.unstable.truncateAndAppend(ents) return l.lastIndex()&#125; // log.gofunc (u *unstable) truncateAndAppend(ents []pb.Entry) &#123; after := ents[0].Index switch &#123; // 若需要追加的日志项集合中的第一条日志恰好是已有的日志的最后一条日志的后一条日志，则直接追加 case after == u.offset+uint64(len(u.entries)): // after is the next index in the u.entries // directly append u.entries = append(u.entries, ents...) // 若需要追加的日志项集合中的第一条日志，要比 unstable 中的 offset 还要小 //（即比 unstable 中日志项集合的开始日志的索引要小） // 则需要把重新设置 offset 索引，并且将 unstable 的日志项集合中的日志覆盖 case after &lt;= u.offset: u.logger.Infof("replace the unstable entries from index %d", after) // The log is being truncated to before our current offset // portion, so set the offset and replace the entries u.offset = after u.entries = ents default: // 否则，分段次进行日志追加 //（包含两种情况，u.offset &lt; after &lt; u.offset+len(u.entries) 或者 after &gt; u.offset+len(u.entries)） // 此种情况也可能涉及到 unstable 中已有日志的截断（前一种情况） // truncate to after and copy to u.entries // then append u.logger.Infof("truncate the unstable entries before index %d", after) u.entries = append([]pb.Entry&#123;&#125;, u.slice(u.offset, after)...) u.entries = append(u.entries, ents...) &#125;&#125; // log_unstable.go 在stepLeader函数中，首先调用 了appendEntry()函数，它会将日志项集合追加到raftLog中（实际上是调用了r.raftLog.append(es...)追加到unstable日志项集合），并且提交本地的日志项（如果满足条件的话）。 leader 节点向 follower 节点广播日志并且，在stepLeader()上会继续调用r.bcastAppend()函数向集群中其它节点广播日志，具体代码如下所示： 123456789101112func (r *raft) bcastAppend() &#123; r.forEachProgress(func(id uint64, _ *Progress) &#123; if id == r.id &#123; return &#125; r.sendAppend(id) &#125;)&#125; // /etcd/raft/raft.gofunc (r *raft) sendAppend(to uint64) &#123; r.maybeSendAppend(to, true)&#125; // /etcd/raft/raft.go 而sendAppend()函数又会调用maybeSendAppend()函数来向特定的节点发送日志同步命令。代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647func (r *raft) maybeSendAppend(to uint64, sendIfEmpty bool) bool &#123; pr := r.getProgress(to) // ... m := pb.Message&#123;&#125; m.To = to term, errt := r.raftLog.term(pr.Next - 1) ents, erre := r.raftLog.entries(pr.Next, r.maxMsgSize) if len(ents) == 0 &amp;&amp; !sendIfEmpty &#123; return false &#125; // sendIfEmpty 可以用作控制空消息是否可以被发送（消息过多时，肯定不建议发送） // 如果获取 term 或者 ents 失败，则发送 snap 消息 if errt != nil || erre != nil &#123; // 此处主要是构建 snap 消息的相关操作 // ... m.Type = pb.MsgSnap snapshot, err := r.raftLog.snapshot() // ... m.Snapshot = snapshot sindex, sterm := snapshot.Metadata.Index, snapshot.Metadata.Term // ... pr.becomeSnapshot(sindex) r.logger.Debugf("%x paused sending replication messages to %x [%s]", r.id, to, pr) &#125; else &#123; // 先设置消息的相关属性 m.Type = pb.MsgApp m.Index = pr.Next - 1 m.LogTerm = term m.Entries = ents m.Commit = r.raftLog.committed // 此处针对节点不同的状态（定义在 progress.go 文件中），来控制一次性给节点发送的消息数量，是批量发送，还是一次只发一条，还是要先暂停探测一下 if n := len(m.Entries); n != 0 &#123; switch pr.State &#123; // optimistically increase the next when in ProgressStateReplicate case ProgressStateReplicate: last := m.Entries[n-1].Index pr.optimisticUpdate(last) pr.ins.add(last) case ProgressStateProbe: pr.pause() default: r.logger.Panicf("%x is sending append in unhandled state %s", r.id, pr.State) &#125; &#125; &#125; // send 函数会将消息保存到 raft.msgs 字段，最后用于构建 Ready 实例结构，以发送给应用程序， // 事实上，此步骤才是真正执行消息发送的步骤（raft 协议库向应用程序发送消息，然后应用程序来控制并执行具体的日志消息网络传输的操作） r.send(m) return true&#125; // /etcd/raft/raft.go 简单而言，上述函数的逻辑为：首先根据该节点上一次已同步的日志位置pr.Next-1，从raftLog中获取该位置之后的日志项，并且日志同步的数量会受到maxMsgSize控制。并且若果无法从raftLog获取到想要的日志项，此时需要只能发送snap（即MsgSnap消息），因为对应日志项可能由于已经被commit而丢弃了。另外，真正的发送消息的操作其实是向r.msgs字段中追加实际需要发送的消息，后面会由node将其打包入Ready结构中，转而发送给应用程序，由应用程序执行真正消息的网络传输操作。 至此，leader节点广播日志项给follower相关流程已经分析完毕。 follower 节点追加日志在分析具体的follower节点追加leader节点给它发送的消息中的日志之前，我们把这个过程阐述得更完整一些。当应用程序调用transport网络传输组件将MsgApp类型的消息由传至follower节点时，更准确而言，transport组件的接收器在接收到消息后，会调用其Raft组件的Process()方法（此部分逻辑不再展示相关代码，在上上篇文章【etcd-raft 网络传输源码简析】中包含了此部分逻辑）。而应用程序会实现此Process()接口，在raftexample示例程序中，其实现逻辑也较为简单： 123func (rc *raftNode) Process(ctx context.Context, m raftpb.Message) error &#123; return rc.node.Step(ctx, m) // 直接调用底层协议核心结构 node 的 Step 函数来处理消息&#125; // /etcd/contrib/raftexample/raft.go 调用Step()函数后，类似于leader节点，会进入到node实例的Step()函数中，它会调用node的一系列函数，包括step()、stepWithWaitOption()函数，然后将消息传入recvc通道，然后在node节点的主循环函数run()中，会一直监视着各通道，因此会从recvc通道中取出消息，最后调用raft.Step()，接下来经过一系列的检查，会调用step()函数即，同样，这里是follower节点，因此最后会调用stepFollower()函数（后面这一个阶段的函数调用栈同leader节点接收到应用程序的请求的流程是一样的）。下面简要贴出在recv通道放入消息之前流程的相关代码： 123456789101112131415161718192021222324252627282930func (n *node) Step(ctx context.Context, m pb.Message) error &#123; // ignore unexpected local messages receiving over network if IsLocalMsg(m.Type) &#123; // TODO: return an error? return nil &#125; return n.step(ctx, m)&#125; // node.gofunc (n *node) step(ctx context.Context, m pb.Message) error &#123; return n.stepWithWaitOption(ctx, m, false)&#125; // node.gofunc (n *node) stepWait(ctx context.Context, m pb.Message) error &#123; return n.stepWithWaitOption(ctx, m, true)&#125; // node.go// Step advances the state machine using msgs. The ctx.Err() will be returned,// if any.func (n *node) stepWithWaitOption(ctx context.Context, m pb.Message, wait bool) error &#123; if m.Type != pb.MsgProp &#123; select &#123; case n.recvc &lt;- m: return nil case &lt;-ctx.Done(): return ctx.Err() case &lt;-n.done: return ErrStopped &#125; &#125; // ... return nil&#125; // node.go 下面来重点看一下stepFolower()函数的逻辑，具体是接收到MsgApp类型的消息的处理逻辑。 1234567891011121314151617181920212223242526272829303132333435func stepFollower(r *raft, m pb.Message) error &#123; switch m.Type &#123; case pb.MsgProp: // 如果应用程序将请求直接发到了 follower 节点，则可能会将消息转发给 leader if r.lead == None &#123; r.logger.Infof("%x no leader at term %d; dropping proposal", r.id, r.Term) return ErrProposalDropped &#125; else if r.disableProposalForwarding &#123; r.logger.Infof("%x not forwarding to leader %x at term %d; dropping proposal", r.id, r.lead, r.Term) return ErrProposalDropped &#125; m.To = r.lead r.send(m) // 转发给 leader case pb.MsgApp: // 接收到 leader 发送的日志同步消息 r.electionElapsed = 0 r.lead = m.From r.handleAppendEntries(m) // 追加日志操作 case pb.MsgHeartbeat: r.electionElapsed = 0 r.lead = m.From r.handleHeartbeat(m) case pb.MsgSnap:// 接收到 leader 发送的 snap 同步消息 r.electionElapsed = 0 r.lead = m.From r.handleSnapshot(m) // 处理快照同步的操作 case pb.MsgTransferLeader: // ... case pb.MsgTimeoutNow: // ... case pb.MsgReadIndex: // ... case pb.MsgReadIndexResp: // .. &#125; return nil&#125; // /etcd/raft/raft.go 上面的逻辑很清晰。我们紧接着查看handleAppendEntries()函数： 123456789101112131415161718192021func (r *raft) handleAppendEntries(m pb.Message) &#123; // 消息中的索引不能小于节点已经提交的消息的索引，否则不追加消息，以已提交的索引作为参数直接回复 if m.Index &lt; r.raftLog.committed &#123; // 此处的 send 函数同 前面 leader 节点在广播日志最终调用的 send 函数为同一个函数 // 即将此消息放到 raft.msgs 结构中，此结构最后会作为 node 打包 Ready 结构的参数 // 最后发送给应用程序，然后由应用程序通过网络转发给对应的节点（此处为 leader） r.send(pb.Message&#123;To: m.From, Type: pb.MsgAppResp, Index: r.raftLog.committed&#125;) return &#125; // 调用 maybeAppend 函数进行日志追加，若追加成功，则以追加后的日志项集合作为参数回复 if mlastIndex, ok := r.raftLog.maybeAppend(m.Index, m.LogTerm, m.Commit, m.Entries...); ok &#123; r.send(pb.Message&#123;To: m.From, Type: pb.MsgAppResp, Index: mlastIndex&#125;) &#125; else &#123; // 否则表示日志追加失败，则是日志索引不匹配造成 //（详情可查看 maybeAppedn函数，简而言之，最后会通过调用 append、truncateAndAppend函数以将消息追加到 raftLog 的 unstable 结构中。 // 此函数在之前的 raftLog 接口实现分析中有涉及，因此不再阐述）， // 则设置冲突的提示，以及本节点的最后的日志项索引作为参数进行回复 r.logger.Debugf("%x [logterm: %d, index: %d] rejected msgApp [logterm: %d, index: %d] from %x", r.id, r.raftLog.zeroTermOnErrCompacted(r.raftLog.term(m.Index)), m.Index, m.LogTerm, m.Index, m.From) r.send(pb.Message&#123;To: m.From, Type: pb.MsgAppResp, Index: m.Index, Reject: true, RejectHint: r.raftLog.lastIndex()&#125;) &#125;&#125; // /etcd/raft/raft.go 作个简单小结，从上面分析的逻辑可以发现，同leader类似，follower节点的数据最终也是被写入了日志模块raftLog的unstable结构中，同样，follower节点的回复消息也是加入到raft.msgs结构中，最后会成为Ready的成员，以传递给应用程序，由应用程序进行实际的网络转发操作。 leader 节点处理 follower 节点日志追加响应最后，同样，当follower将回复消息发送之后，再由网络传输组件transport调用node.Process()函数以处理此消息（此逻辑已在上面的【folower节点追加日志】小节中最开始阐述）。因此，最后同样会进入leader的stepLeader()函数，而且会进入消息类型为MsgAppResp分支处理逻辑中，关键代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263func stepLeader(r *raft, m pb.Message) error &#123; // ... switch m.Type &#123; case pb.MsgAppResp: pr.RecentActive = true if m.Reject &#123; // 若 follower回复拒绝消息 r.logger.Debugf("%x received msgApp rejection(lastindex: %d) from %x for index %d", r.id, m.RejectHint, m.From, m.Index) // 则需要减小消息的索引，即往前挑选消息（raft 论文中关于日志冲突已经详细介绍）， // 即 if pr.maybeDecrTo(m.Index, m.RejectHint) &#123; r.logger.Debugf("%x decreased progress of %x to [%s]", r.id, m.From, pr) if pr.State == ProgressStateReplicate &#123; pr.becomeProbe() &#125; // 再次将消息发送给 follower r.sendAppend(m.From) &#125; &#125; else &#123; // 否则 follower 回复成功追加日志 oldPaused := pr.IsPaused() // 此处为更新 leader 维护的对各 follower 节点的进度详情（具体在 progress.go中描述） // 比较简单，因此为了节约篇幅，此处不展开叙述。 // 事实上，这也是 etcd-raft 针对 原始的 raft 论文作的一些优化。 if pr.maybeUpdate(m.Index) &#123; switch &#123; case pr.State == ProgressStateProbe: pr.becomeReplicate() case pr.State == ProgressStateSnapshot &amp;&amp; pr.needSnapshotAbort(): r.logger.Debugf("%x snapshot aborted, resumed sending replication messages to %x [%s]", r.id, m.From, pr) pr.becomeProbe() pr.becomeReplicate() case pr.State == ProgressStateReplicate: pr.ins.freeTo(m.Index) &#125; // 检查是否需要提交，若的确可以提交，则同样将此消息进行广播 if r.maybeCommit() &#123; r.bcastAppend() &#125; else if oldPaused &#123; r.sendAppend(m.From) &#125; // We've updated flow control information above, which may // allow us to send multiple (size-limited) in-flight messages // at once (such as when transitioning from probe to // replicate, or when freeTo() covers multiple messages). If // we have more entries to send, send as many messages as we // can (without sending empty messages for the commit index) for r.maybeSendAppend(m.From, false) &#123; &#125; // Transfer leadership is in progress. if m.From == r.leadTransferee &amp;&amp; pr.Match == r.raftLog.lastIndex() &#123; r.logger.Infof("%x sent MsgTimeoutNow to %x after received MsgAppResp", r.id, m.From) r.sendTimeoutNow(m.From) &#125; &#125; &#125; case pb.MsgHeartbeatResp: // ... case pb.MsgSnapStatus: // ... case pb.MsgTransferLeader: // ... &#125; return nil&#125; // /etcd/raft/raft.go 至此，leader节点处理follower节点对日志追加消息的回复也已经分析完毕。 因此，整个完整的流程也已经结束。我们也对unstabel以及raftLog的流程，即raft协议库与raftLog的交互作一个简单小结：可以发现，unstable或者说raftLog只是协议存储管理日志的组件，没有其它作用，即它没有用作诸如节点宕机后重启、新节点加入过程的日志来源。unstable是未落盘的日志项集合，即可能会丢失，因此unstable日志最终会持久化到storage中，即持久化到snap以及WAL日志。 最后，需要提醒读者的是，文章比较长，若读者没有时间，也可以挑选部分小节进行参考（各小节是独立分析阐述的）。最重要的是，读者自己能够进入到源码文件进行查看，那比本文所贴出的代码逻辑会更容易理解，读者也会获取得更多。 参考文献 [1]. https://github.com/etcd-io/etcd/tree/master/raft]]></content>
      <categories>
        <category>分布式系统</category>
        <category>分布式协调服务</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>分布式协调服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[etcd-raft WAL日志管理源码简析]]></title>
    <url>%2F2019%2F01%2F11%2Fetcd-raft-WAL%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86%E6%BA%90%E7%A0%81%E7%AE%80%E6%9E%90%2F</url>
    <content type="text"><![CDATA[上一篇文章简单分析了etcd-raft 网络传输组件相关的源码。本文会简要分析etcd-raft WAL日志管理部分的源码。WAL(Write-Ahead Logging)即为预写式日志，即在真正执行写操作之前先写日志，这在数据库系统和分布式系统领域很常见。它是为了保证数据的可靠写。日志对于利用一致性协议构建高可用的分布式系统而言至关重要，在etcd raft中，日志也会在各节点之间同步。并且etcd提供了一个WAL的日志库，它暴露日志管理相关的接口以方便应用程序具体操作日志的逻辑。本文从应用调用 WAL库执行日志追加逻辑切入，重点分析etcd提供的WAL日志库的相关接口实现逻辑细则，包括WAL日志的设计、日志创建追加等。 数据结构同之前的文章类似，希望读者能够主动查看源码（主要涉及目录/etcd/wal），文章作为参考。按惯例，先来观察与WAL相关的重要数据结构的设计。从最核心的数据结构切入WAL： 12345678910111213141516171819202122232425262728293031// WAL 是持久化存在的逻辑表示。并且要么处于读模式要么处于追加模式。// 新创建的 WAL 处于追加模式，可用于记录追加。// 刚打开的 WAL 处于读模式，可用于记录读取。// 当读完之前所有的 WAL 记录后，WAL 才可用于记录追加。type WAL struct &#123; lg *zap.Logger // 日志存储目录 dir string // the living directory of the underlay files // dirFile is a fd for the wal directory for syncing on Rename // 文件描述符，用于 WAL 目录同步重命名操作 dirFile *os.File // 元数据，在创建日志文件时，在写在文件头位置 metadata []byte // metadata recorded at the head of each WAL state raftpb.HardState // hardstate recorded at the head of WAL start walpb.Snapshot // snapshot to start reading decoder *decoder // decoder to decode records readClose func() error // closer for decode reader mu sync.Mutex // WAL 中保存的最后一条日志的索引 enti uint64 // index of the last entry saved to the wal encoder *encoder // encoder to encode records // LockedFile 封装了 os.File 的结构，具备文件锁定功能 locks []*fileutil.LockedFile // the locked files the WAL holds (the name is increasing) fp *filePipeline&#125; // wal.go 简单的字段在代码中作了注释。下面了解下几个重点的结构： state: HardState{Term,Vote,Commit}类型，它表示节点在回复消息时，必须先进行持久化保持的状态。 start: walpb.Snapshot{Index, Term}类型，即表示WAL日志中的快照，当读WAL日志时需从此索引后一个开始，如应用在重放日志逻辑中，需要打开WAL日志，则其只需要对Snapshot索引后的日志作重放。 decoder: decoder封装了Reader，并且使用crc来校验读取的记录，一个文件对应一个decoder。 encoder: encoder封装了PageWriter，同样使用crc来检验写入记录，encoder实例同样对应一个文件。 fp: filePipeline类型，它管理文件创建时的磁盘空间分配操作逻辑。若文件以写模式打开，它会开启一个单独的go routine为文件创建预分配空间，以提高文件创建的效率。此逻辑封装在file_pipeline.go。 我们不妨简单看看encoder的结构（比decoder结构稍复杂），它包含了一个执行具体写操作的PageWriter，以及一个crc字段，另外，还包含两个预分配的缓冲区，其中buf(1MB)用于写入实际数据，而uint64buf(8B)用于写入长度相关字段。其代码如下： 123456789101112131415161718type encoder struct &#123; mu sync.Mutex bw *ioutil.PageWriter crc hash.Hash32 buf []byte // 用于写入实际记录数据 uint64buf []byte // 用于写入长度相关字段&#125; // encoder.gofunc newEncoder(w io.Writer, prevCrc uint32, pageOffset int) *encoder &#123; return &amp;encoder&#123; bw: ioutil.NewPageWriter(w, walPageBytes, pageOffset), crc: crc.New(prevCrc, crcTable), // 1MB buffer buf: make([]byte, 1024*1024), uint64buf: make([]byte, 8), &#125;&#125; // encoder.go 另外，存储在WAL日志的记录包括两种，一种以Record形式保存，它是一种普通的记录格式，另一种以Snapshot形式保存，它专门用于快照记录的存储，但快照类型的记录最终还是作为Record类型记录存储： 123456789101112type Record struct &#123; Type int64 `protobuf:"varint,1,opt,name=type" json:"type"` Crc uint32 `protobuf:"varint,2,opt,name=crc" json:"crc"` Data []byte `protobuf:"bytes,3,opt,name=data" json:"data,omitempty"` XXX_unrecognized []byte `json:"-"`&#125; // record.pb.gotype Snapshot struct &#123; Index uint64 `protobuf:"varint,1,opt,name=index" json:"index"` Term uint64 `protobuf:"varint,2,opt,name=term" json:"term"` XXX_unrecognized []byte `json:"-"`&#125; // record.pb.go 对于普通记录Record类型结构（即WAL日志类型），它的Type字段表示日志类型，包括如下几种日志类型： 12345678910111213141516const ( // 元数据类型日志项，被写在每个日志文件的头部，具体内容可以任意，包括空值 metadataType int64 = iota + 1 // 实际的数据，即日志存储中的关键数据 entryType // 表示保存的为 HardState 类型的数据 stateType // 前一个 WAL 日志记录数据的 crc 值 crcType // 表示快照类型的日志记录，它表示当前 Snapshot 位于哪个日志记录，保存的是索引(Term,Index)数据 snapshotType // warnSyncDuration is the amount of time allotted to an fsync before // logging a warning warnSyncDuration = time.Second) // wal.go 而它的crc字段表示校验和数据，需要注意的是它并非直接保存的是当前日志记录的校验数据，而保存的是当前文件该日志项之前的所有日志项的校验和，这似乎是采用类似一种rolling crc，以保证WAL日志的连续性，因为写日志的时候可能会涉及到cut操作，它会将日志内容存储到不止一个文件。data字段会根据不同的类型来具体确定，若为stateType，则存储HardState类型的数据，若为entryType，则存储Entry类型的数据，若为snapshotType，则存储Snapshot类型的数据（只是索引数据），若为metadataType，则似乎可以由应用决定（目前来看在raftNode结构中，使用了此类型的日志，但传过来的数据为空），若为crcType，则存储Crc类型(unit32)的数据。 最后的padding字段，则是为了保持日志项数据 8 字节对其的策略，而进行填充的内容。这个我们可以从任一一处编码Record记录的代码中观察得知，如从wal.go中w.encoder.encode(...)代码往下追溯具体的encode()的逻辑，在encode()函数中会调用encodeFrameSize(len(data))，其函数具体的代码如下： 1234567891011func encodeFrameSize(dataBytes int) (lenField uint64, padBytes int) &#123; lenField = uint64(dataBytes) // force 8 byte alignment so length never gets a torn write padBytes = (8 - (dataBytes % 8)) % 8 // 先得出 padding 的 bytes 的大小，一定小于 8 if padBytes != 0 &#123; lenField |= uint64(0x80|padBytes) &lt;&lt; 56 // 将 0x80 与 padBytes 进行或操作，得到 4 个二进制位的内容，然后再左移 56 位。最后得到的记录的存储二进制结构为： // &#123;|-(1位标记位)| |---(3位表示 Padding bytes Size)|&#125;&#123;...(56位于表示实际的 Record bytes Size)&#125; &#125; return lenField, padBytes&#125; // encoder.go 至此相关的重要的数据结构项已经查看完毕，主要是围绕WAL结构展开。文章为了节约篇幅并没有将所有的数据项结构的代码帖出，读者可以自己深入源码查看，较为简单。 关键流程在此部分分析中，简要分析阐述WAL库提供的各个接口实现的逻辑，主要包括WAL创建、WAL初始化（打开）、WAL日志项读取及WAL追加日志项等流程。另外，关于raft协议核心库如何操作日志的逻辑暂不涉及。 WAL 创建在raftexample示例代码中，应用在启动时，对WAL日志执行重放操作（raft.go，在startRaft()中的rc.replayWAL()），而在重放日志函数的逻辑中，它先加载snapshot数据，然后，将其作为参数传递给rc.openWAL(snapshot)函数，以对打开文件，如果文件不存在，则会先创建日志文件。关键代码如下所示： 123456789101112131415161718192021222324252627282930313233// replayWAL replays WAL entries into the raft instance.func (rc *raftNode) replayWAL() *wal.WAL &#123; log.Printf("replaying WAL of member %d", rc.id) snapshot := rc.loadSnapshot() // 加载 snapshot 数据 w := rc.openWAL(snapshot) // 打开 WAL 日志文件，以读取 snaptshot 位置后的日志 _, st, ents, err := w.ReadAll() // 读取 WAL 日志文件，相关逻辑后面详述 // ... return w&#125; // raft.go// openWAL returns a WAL ready for reading.func (rc *raftNode) openWAL(snapshot *raftpb.Snapshot) *wal.WAL &#123; if !wal.Exist(rc.waldir) &#123; if err := os.Mkdir(rc.waldir, 0750); err != nil &#123; log.Fatalf("raftexample: cannot create dir for wal (%v)", err) &#125; // 1. 创建日志文件，注意在这里 metaData 参数为 nil w, err := wal.Create(zap.NewExample(), rc.waldir, nil) w.Close() &#125; // 2. 创建 snapshotType 类型的日志项，以用于记录当前快照的索引情况(Term, Index) walsnap := walpb.Snapshot&#123;&#125; if snapshot != nil &#123; walsnap.Index, walsnap.Term = snapshot.Metadata.Index, snapshot.Metadata.Term &#125; log.Printf("loading WAL at term %d and index %d", walsnap.Term, walsnap.Index) // 3. 打开从 snapshot 位置打开日志，其相关的逻辑在后面详述 w, err := wal.Open(zap.NewExample(), rc.waldir, walsnap) if err != nil &#123; log.Fatalf("raftexample: error loading wal (%v)", err) &#125; return w&#125; // raft.go 阐明了应用WAL日志库的入口后，我们先来查看WAL创建函数相关的逻辑。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172// Create creates a WAL ready for appending records. The given metadata is// recorded at the head of each WAL file, and can be retrieved with ReadAll.// 创建一个 WAL 文件用于日志记录追加。元数据存放在文件头部，可以通过 ReadAll 检索到func Create(lg *zap.Logger, dirpath string, metadata []byte) (*WAL, error) &#123; if Exist(dirpath) &#123; return nil, os.ErrExist &#125; // keep temporary wal directory so WAL initialization appears atomic // 1. 先创建一个临时文件，然后对此文件进行重命名，以使得文件被原子创建 tmpdirpath := filepath.Clean(dirpath) + ".tmp" if fileutil.Exist(tmpdirpath) &#123; if err := os.RemoveAll(tmpdirpath); err != nil &#123; return nil, err &#125; &#125; if err := fileutil.CreateDirAll(tmpdirpath); err != nil &#123; return nil, err &#125; // 2. 构造文件名，即构建 dir/filename, 其中 filename 伤脑筋 walName函数来获取，文件名构建规则为：seq-index.wal p := filepath.Join(tmpdirpath, walName(0, 0)) // 3. WAL 对文件的操作都是通过 LockFile 来执行的 f, err := fileutil.LockFile(p, os.O_WRONLY|os.O_CREATE, fileutil.PrivateFileMode) if err != nil &#123; return nil, err &#125; // 4. 定位到文件末尾 if _, err = f.Seek(0, io.SeekEnd); err != nil &#123; return nil, err &#125; // 5. 预分配文件，默认 SegmentSizeBytes 大小为 64MB if err = fileutil.Preallocate(f.File, SegmentSizeBytes, true); err != nil &#123; return nil, err &#125; // 6. 初始化 WAL 数据结构 w := &amp;WAL&#123; lg: lg, dir: dirpath, metadata: metadata, &#125; // 7. 针对此文件构建 WAL 结构的 encoder 字段，并且将 preCrc 字段赋值为0 w.encoder, err = newFileEncoder(f.File, 0) // 8. 将此（具备锁定性质的）文件添加到 WAL 结构的 locks 数组字段 w.locks = append(w.locks, f) // 9. 保存类型为 crcType 的 crc 记录项，具体的 crc 数据为 preCrc=0 if err = w.saveCrc(0); err != nil &#123; return nil, err &#125; // 10. 利用 encoder 编码类型为 metadataType 的 metaData 记录项 if err = w.encoder.encode(&amp;walpb.Record&#123;Type: metadataType, Data: metadata&#125;); err != nil &#123; return nil, err &#125; // 11. 保存类型为 snapshotType 的空的 Snapshot 记录 if err = w.SaveSnapshot(walpb.Snapshot&#123;&#125;); err != nil &#123; return nil, err &#125; // 12. 重命名操作，之前以.tmp结尾的文件，初始化完成之后进行重命名，类似原子操作 if w, err = w.renameWAL(tmpdirpath); err != nil &#123; return nil, err &#125; // directory was renamed; sync parent dir to persist rename pdir, perr := fileutil.OpenDir(filepath.Dir(w.dir)) // 13. 将上述涉及到对文件的操作进行同步处理 if perr = fileutil.Fsync(pdir); perr != nil &#123; return nil, perr &#125; if perr = pdir.Close(); err != nil &#123; return nil, perr &#125; return w, nil&#125; // wal.go 上述代码片段中的注释对整个创建过程进行了详细阐述，这是总结一下，它主要涉及到几个操作： 创建WAL目录，用于存储WAL日志文件及索引，同时使用临时文件及重命名的方式来原子操作。 对日志文件的创建，会预分配空间，以提高创建的效率。 在日志文件创建时，会初始化 WAL结构实例，同时写入crcType、metadataType记录项，并且保存一个空的snapshotType记录项。对于各种类型记录项，上文中数据结构小节已经详细阐述。 我们来看下它是如何保存snapshotType类型的Snapshot数据的，相关逻辑在函数SaveSnapShot(Snapshot): 123456789101112131415161718// 持久化 walpb.Snapshot 数据func (w *WAL) SaveSnapshot(e walpb.Snapshot) error &#123; b := pbutil.MustMarshal(&amp;e) // 1. 先执行序列化操作 w.mu.Lock() defer w.mu.Unlock() // 2. 构建 snaptshotType 类型的记录结构，并以序列化的数据作为参数 rec := &amp;walpb.Record&#123;Type: snapshotType, Data: b&#125; // 3. 利用 encoder 编码写入 if err := w.encoder.encode(rec); err != nil &#123; return err &#125; // update enti only when snapshot is ahead of last index // 4. w.enti 表示的是 WAL 中最后一条日志的索引，因此只有当其小于快照的索引时，才进行替换 if w.enti &lt; e.Index &#123; w.enti = e.Index &#125; return w.sync()&#125; // wal.go 我们不妨深入encoder.encode()函数中查看一下编码的细节： 12345678910111213141516171819202122232425262728293031323334353637383940// 编码一条数据记录项func (e *encoder) encode(rec *walpb.Record) error &#123; e.mu.Lock() defer e.mu.Unlock() // 1. 生成校验和数据 e.crc.Write(rec.Data) rec.Crc = e.crc.Sum32() var ( data []byte err error n int ) // 2. 如果记录的大小超过预分配的 1MB 的 buffer（与文件的预分配可能类似），则重新分配空间 if rec.Size() &gt; len(e.buf) &#123; data, err = rec.Marshal() if err != nil &#123; return err &#125; &#125; else &#123; // 否则直接使用预分配的空间 n, err = rec.MarshalTo(e.buf) if err != nil &#123; return err &#125; data = e.buf[:n] &#125; // 3. 调用 encodeFrameSize 函数来构建 lenField 以及判断对齐的位数 lenField, padBytes := encodeFrameSize(len(data)) // 4. 先写记录编码后的长度字段 if err = writeUint64(e.bw, lenField, e.uint64buf); err != nil &#123; return err &#125; // 5. 然后，若需要对齐，则追加对齐填充数据 if padBytes != 0 &#123; data = append(data, make([]byte, padBytes)...) &#125; // 6. 最后正式写入记录的所包含的所有数据内容 _, err = e.bw.Write(data) return err&#125; // encoder.go 关于WAL文件创建相关逻辑已经阐述完毕，下一小节阐述与创建类似的操作即初始化操作。 WAL 初始化WAL初始化，我将表示它表示为打开文件逻辑，即在应用程序里面中的代码wal.Open()函数中的流程。具体而言，打开WAL文件的目的是为了从里面读取日志文件（读取的目的一般是重放日志）。因此，更准确而言，是从指定索引处打开，此索引即表示之前的已经执行的快照的索引，从那之后开始进行读操作，而且只有当把快照索引之后的日志全部读取完毕才能进行追加操作。另外，打开操作必须保证快照之前已经被存储，否则读取操作ReadlAll会执行失败。打开操作的相关的代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182func Open(lg *zap.Logger, dirpath string, snap walpb.Snapshot) (*WAL, error) &#123; // 只打开最后一个 seq 小于 snap 中的 index 之后的所有 wal 文件，并且以写的方式打开 w, err := openAtIndex(lg, dirpath, snap, true) if w.dirFile, err = fileutil.OpenDir(w.dir); err != nil &#123; return nil, err &#125; return w, nil&#125; // wal.go// 打开指定索引后的日志文件func openAtIndex(lg *zap.Logger, dirpath string, snap walpb.Snapshot, write bool) (*WAL, error) &#123; // 1. 读取所有 WAL 日志文件名称 names, err := readWALNames(lg, dirpath) if err != nil &#123; return nil, err &#125; // 2. 返回名称集合中最后一个小于或者等于 snap.Index 的名称索引（在文件名称集合中的索引） nameIndex, ok := searchIndex(lg, names, snap.Index) // 3. 检查 nameIndex 之后的文件名的 seq 是否有序递增的 if !ok || !isValidSeq(lg, names[nameIndex:]) &#123; return nil, ErrFileNotFound &#125; // open the wal files rcs := make([]io.ReadCloser, 0) rs := make([]io.Reader, 0) ls := make([]*fileutil.LockedFile, 0) // 3. 对返回的索引之后的文件进行遍历，同时构造 rcs、rs、ls 数组 for _, name := range names[nameIndex:] &#123; // 4. 构建文件路径 p := filepath.Join(dirpath, name) // 5. 如果是写模式打开，则进行如下操作 if write &#123; l, err := fileutil.TryLockFile(p, os.O_RDWR, fileutil.PrivateFileMode) if err != nil &#123; closeAll(rcs...) return nil, err &#125; ls = append(ls, l) // 写模式似乎有锁定文件属性 rcs = append(rcs, l) // 追加文件读取与关闭接口 &#125; else &#123; // 6. 如果是读模式打开，则进行如下操作 rf, err := os.OpenFile(p, os.O_RDONLY, fileutil.PrivateFileMode) if err != nil &#123; closeAll(rcs...) return nil, err &#125; ls = append(ls, nil) // 读模式并没有锁定文件属性 rcs = append(rcs, rf) // 同样追加文件读取与关闭接口 &#125; rs = append(rs, rcs[len(rcs)-1]) &#125; // 7. 构建用于文件读取与关闭的句柄集合 closer := func() error &#123; return closeAll(rcs...) &#125; // create a WAL ready for reading // 8. 利用以上信息构造 WAL 实例 w := &amp;WAL&#123; lg: lg, dir: dirpath, start: snap, // 初始化快照数据，实际上表示可以从哪一个索引位置处开始读 decoder: newDecoder(rs...), // decoder 又以上述打开文件的句柄集合为参数 readClose: closer, // 文件关闭句柄集合 locks: ls, // 具备锁定属性的文件集合 &#125; // 9. 若为写打开，则会重用读的文件描述符，因此不需要关闭 WAL 文件（需要释放锁）以直接执行追加操作 if write &#123; // write reuses the file descriptors from read; don't close so // WAL can append without dropping the file lock w.readClose = nil if _, _, err := parseWALName(filepath.Base(w.tail().Name())); err != nil &#123; closer() return nil, err &#125; // 10. 创建 FilePipeline 进行创建文件操作的空间预分配操作，具体是在 go routine 中循环执行空间分配操作， // 并将分配好的文件放到通道中，等待后面正式创建的时候使用 w.fp = newFilePipeline(w.lg, w.dir, SegmentSizeBytes) &#125; return w, nil&#125; // wal.go WAL文件打开以进行后续的读取与追加操作的相关逻辑已经阐述完毕。下面阐述日志项的读取相关逻辑。 WAL 日志项读取同样，在应用raftexample中启动初始化应用时(startRaft())中可能会涉及到日志的读取操作(w.ReadAll())。因此，我们来详细了解读取逻辑。大概地，它会读取WAL所有日志记录，当读取完毕后，就可以执行操作： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126// ReadAll reads out records of the current WAL.// If opened in write mode, it must read out all records until EOF. Or an error// will be returned.// If opened in read mode, it will try to read all records if possible.// If it cannot read out the expected snap, it will return ErrSnapshotNotFound.// If loaded snap doesn't match with the expected one, it will return// all the records and error ErrSnapshotMismatch.// TODO: detect not-last-snap error.// TODO: maybe loose the checking of match.// After ReadAll, the WAL will be ready for appending new records.func (w *WAL) ReadAll() (metadata []byte, state raftpb.HardState, ents []raftpb.Entry, err error) &#123; w.mu.Lock() defer w.mu.Unlock() // 1. 初始化一个空的记录项 rec := &amp;walpb.Record&#123;&#125; decoder := w.decoder // 2. 根据记录不同的类型（在数据结构部分已经详述），来执行不同操作 var match bool for err = decoder.decode(rec); err == nil; err = decoder.decode(rec) &#123; switch rec.Type &#123; // 2.1. 如果为 entryType 类型 case entryType: e := mustUnmarshalEntry(rec.Data) // 若读取到的日志的日志项的索引大于快照的索引，则将其追加到日志面集合， // 并且更新 WAL 的最后一条日志的日志索引 if e.Index &gt; w.start.Index &#123; ents = append(ents[:e.Index-w.start.Index-1], e) &#125; w.enti = e.Index // 2.2. 如果为 stateType 类型 case stateType: state = mustUnmarshalState(rec.Data) // 2.3 如果为 metadataType 类型，从此处来看 metadata 还可以用作检验 case metadataType: if metadata != nil &amp;&amp; !bytes.Equal(metadata, rec.Data) &#123; state.Reset() return nil, state, nil, ErrMetadataConflict &#125; metadata = rec.Data // 2.4 如果为 crcType 类型，则需要校验此 decoder 保存的 crc 检验和是否与记录的一致 case crcType: crc := decoder.crc.Sum32() // current crc of decoder must match the crc of the record. // do no need to match 0 crc, since the decoder is a new one at this case. if crc != 0 &amp;&amp; rec.Validate(crc) != nil &#123; state.Reset() return nil, state, nil, ErrCRCMismatch &#125; decoder.updateCRC(rec.Crc) // 2.5 如果为 snapshotType 类型 case snapshotType: var snap walpb.Snapshot pbutil.MustUnmarshal(&amp;snap, rec.Data) // 在反序列化之后，如果记录中的快照与 WAL 日志中快照不匹配，则报错 if snap.Index == w.start.Index &#123; if snap.Term != w.start.Term &#123; state.Reset() return nil, state, nil, ErrSnapshotMismatch &#125; match = true &#125; default: state.Reset() return nil, state, nil, fmt.Errorf("unexpected block type %d", rec.Type) &#125; &#125; // 3. 通过 WAL 日志文件中最后一条记录来做不同的处理 switch w.tail() &#123; case nil: // 如果是读模式，则并不需要读取所有的记录，因为最后一条记录可能是部分写的 // We do not have to read out all entries in read mode. // The last record maybe a partial written one, so // ErrunexpectedEOF might be returned. if err != io.EOF &amp;&amp; err != io.ErrUnexpectedEOF &#123; state.Reset() return nil, state, nil, err &#125; default: // 如果是写模式，则需要读取所有记录，直至返回 EOF // We must read all of the entries if WAL is opened in write mode. if err != io.EOF &#123; state.Reset() return nil, state, nil, err &#125; // decodeRecord() will return io.EOF if it detects a zero record, // but this zero record may be followed by non-zero records from // a torn write. Overwriting some of these non-zero records, but // not all, will cause CRC errors on WAL open. Since the records // were never fully synced to disk in the first place, it's safe // to zero them out to avoid any CRC errors from new writes. if _, err = w.tail().Seek(w.decoder.lastOffset(), io.SeekStart); err != nil &#123; return nil, state, nil, err &#125; if err = fileutil.ZeroToEnd(w.tail().File); err != nil &#123; return nil, state, nil, err &#125; &#125; err = nil if !match &#123; err = ErrSnapshotNotFound &#125; // 4. 读取完毕后，则关闭读操作 // close decoder, disable reading if w.readClose != nil &#123; w.readClose() w.readClose = nil &#125; w.start = walpb.Snapshot&#123;&#125; w.metadata = metadata // 5. 如果最后一条记录不为空，则创建 encoder，准备追加操作 if w.tail() != nil &#123; // create encoder (chain crc with the decoder), enable appending w.encoder, err = newFileEncoder(w.tail().File, w.decoder.lastCRC()) if err != nil &#123; return &#125; &#125; w.decoder = nil return metadata, state, ents, err&#125; // wal.go 另外，关于记录的decode操作，下面帖出简要的注释过程，基本上是encode操作的逆操作，但是加了一个校验的过程。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657// decode 日志记录项func (d *decoder) decode(rec *walpb.Record) error &#123; rec.Reset() d.mu.Lock() defer d.mu.Unlock() return d.decodeRecord(rec)&#125;func (d *decoder) decodeRecord(rec *walpb.Record) error &#123; // 1. 需要读取器 if len(d.brs) == 0 &#123; return io.EOF &#125; // 2. 首先读与长度相关字段 l, err := readInt64(d.brs[0]) // 3. 解析出记录数据的字节大小以及对齐字节的大小 recBytes, padBytes := decodeFrameSize(l) // 4. 构建缓冲区用于存储具体读出的数据 data := make([]byte, recBytes+padBytes) // 5. 执行读实际数据的操作 if _, err = io.ReadFull(d.brs[0], data); err != nil &#123; return err &#125; // 6. 对数据执行反序列化操作 if err := rec.Unmarshal(data[:recBytes]); err != nil &#123; return err &#125; // 7. 对非 crcType 类型的记录，需要校验 crc，即检测记录的 crc 数值与 decoder 的检验和是否一致 // skip crc checking if the record type is crcType if rec.Type != crcType &#123; d.crc.Write(rec.Data) if err := rec.Validate(d.crc.Sum32()); err != nil &#123; if d.isTornEntry(data) &#123; return io.ErrUnexpectedEOF &#125; return err &#125; &#125; // 8. 更新目前已经检验的字节索引，下一次从此处开始检验 // record decoded as valid; point last valid offset to end of record d.lastValidOff += frameSizeBytes + recBytes + padBytes return nil&#125;// 为 encoder.encodeFrameSize() 函数的逆过程func decodeFrameSize(lenField int64) (recBytes int64, padBytes int64) &#123; // the record size is stored in the lower 56 bits of the 64-bit length recBytes = int64(uint64(lenField) &amp; ^(uint64(0xff) &lt;&lt; 56)) // non-zero padding is indicated by set MSb / a negative length if lenField &lt; 0 &#123; // padding is stored in lower 3 bits of length MSB padBytes = int64((uint64(lenField) &gt;&gt; 56) &amp; 0x7) &#125; return recBytes, padBytes&#125; // decoder.go 最后一个部分来简要阐述日志项的追加逻辑。 WAL 日志项追加同样，在【etcd raftexample 源码简析】中，当应用收到底层raft协议的指令消息时，会先进行写日志(rc.wal.Save(rd.HardState, rd.Entries))，也即此处的日志项追加操作。 123456789101112131415161718192021222324252627282930313233343536373839404142// 日志项追加操作func (w *WAL) Save(st raftpb.HardState, ents []raftpb.Entry) error &#123; w.mu.Lock() defer w.mu.Unlock() // short cut, do not call sync // 1. 若无 需要持久化的字段 且无日志项数据，则返回 if raft.IsEmptyHardState(st) &amp;&amp; len(ents) == 0 &#123; return nil &#125; // 2. MustSync 会检查当前的 Save 操作是否需要同步存盘 // 事实上，其逻辑大致为检查 log entries 是否为0，或者 candidate id 是否变化或者是 term 有变化， // 一旦这些条件中之一满足，则需要先执行存盘操作。 // 这些字段为 raft 实例需要持久化的字段，以便重启的时候可以继续协议 mustSync := raft.MustSync(st, w.state, len(ents)) // TODO(xiangli): no more reference operator // 3. 遍历日志项，并保存，在 saveEntry 中，会构建 Entry 记录，并更新 WAL 的 enti 索引字段 for i := range ents &#123; if err := w.saveEntry(&amp;ents[i]); err != nil &#123; return err &#125; &#125; // 4. 保存 HardState 字段，并保存，在 saveState 中，会构建 State 记录，但不会更新 enti 索引字段 if err := w.saveState(&amp;st); err != nil &#123; return err &#125; // 5. 获取最后一个 LockedFile 的大小（已经使用的） curOff, err := w.tail().Seek(0, io.SeekCurrent) if err != nil &#123; return err &#125; // 6. 若小于预分配空间大小 64MB，则直接返回即可 if curOff &lt; SegmentSizeBytes &#123; if mustSync &#123; // 若需同步刷盘操作，则要将已经 encode 的记录存盘 return w.sync() &#125; return nil &#125; // 6. 若大于预分配空间，则需要另外创建一个文件 return w.cut()&#125; // wal.go 其中涉及到的几个保存不同类型的记录的函数如下，比较简单： 12345678910111213141516171819202122232425262728293031func MustSync(st, prevst pb.HardState, entsnum int) bool &#123; // Persistent state on all servers: // (Updated on stable storage before responding to RPCs) // currentTerm // votedFor // log entries[] return entsnum != 0 || st.Vote != prevst.Vote || st.Term != prevst.Term&#125; // node.go 由 raft 协议库核心提供func (w *WAL) saveEntry(e *raftpb.Entry) error &#123; // TODO: add MustMarshalTo to reduce one allocation. b := pbutil.MustMarshal(e) // 构建 entryType 类型的 Record，并对记录进行编码 rec := &amp;walpb.Record&#123;Type: entryType, Data: b&#125; if err := w.encoder.encode(rec); err != nil &#123; return err &#125; // 更新 WAL 日志项中最后一条日志的索引号 w.enti = e.Index return nil&#125; // wal.gofunc (w *WAL) saveState(s *raftpb.HardState) error &#123; if raft.IsEmptyHardState(*s) &#123; return nil &#125; w.state = *s b := pbutil.MustMarshal(s) rec := &amp;walpb.Record&#123;Type: stateType, Data: b&#125; return w.encoder.encode(rec)&#125; // wal.go 最后若当前的文件的预分配的空间不够，则需另外创建新的文件来进行保存日志项。cut()函数流程如下，它的流程同Create()函数非常类似： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788// cut closes current file written and creates a new one ready to append.// cut first creates a temp wal file and writes necessary headers into it.// Then cut atomically rename temp wal file to a wal file.// cut 函数实现了WAL文件切换的功能，即关闭当前WAL日志，创建新的WAL日志，继续用于日志追加。// 每个 WAL 文件的预分配空间为 64MB，一旦超过该大小，便需要创建新的 WAL 文件// 同样，cut 操作也会原子性的创建，能够创建临时文件来实现。func (w *WAL) cut() error &#123; // close old wal file; truncate to avoid wasting space if an early cut // 1. 关闭当前 WAL 文件，得到文件大小 off, serr := w.tail().Seek(0, io.SeekCurrent) if serr != nil &#123; return serr &#125; // 2. 截断文件 if err := w.tail().Truncate(off); err != nil &#123; return err &#125; if err := w.sync(); err != nil &#123; return err &#125; // 3. 构建新文件的路径（文件名），顺序递增 seq 及 enti fpath := filepath.Join(w.dir, walName(w.seq()+1, w.enti+1)) // create a temp wal file with name sequence + 1, or truncate the existing one // 4. 创建临时文件，其会使用先前 pipelinefile 预先分配的空间来执行此创建操作 newTail, err := w.fp.Open() if err != nil &#123; return err &#125; // update writer and save the previous crc // 5. 同 Create 函数类似，将文件加入到 WAL 的 locks 数组集合 w.locks = append(w.locks, newTail) // 6. 计算 crc 检验和，它是本文件之前的所有记录的检验和 prevCrc := w.encoder.crc.Sum32() // 7. 构建 WAL 实例的 encoder w.encoder, err = newFileEncoder(w.tail().File, prevCrc) if err != nil &#123; return err &#125; // 8. 先保存 检验和 if err = w.saveCrc(prevCrc); err != nil &#123; return err &#125; // 9. 再保存 metadata if err = w.encoder.encode(&amp;walpb.Record&#123;Type: metadataType, Data: w.metadata&#125;); err != nil &#123; return err &#125; // 10. 接着保存 HardState if err = w.saveState(&amp;w.state); err != nil &#123; return err &#125; // atomically move temp wal file to wal file if err = w.sync(); err != nil &#123; return err &#125; off, err = w.tail().Seek(0, io.SeekCurrent) if err != nil &#123; return err &#125; // 11. 重命名 if err = os.Rename(newTail.Name(), fpath); err != nil &#123; return err &#125; if err = fileutil.Fsync(w.dirFile); err != nil &#123; return err &#125; // reopen newTail with its new path so calls to Name() match the wal filename format newTail.Close() // 12. 重新打开并上锁新的文件（重命名之后的） if newTail, err = fileutil.LockFile(fpath, os.O_WRONLY, fileutil.PrivateFileMode); err != nil &#123; return err &#125; if _, err = newTail.Seek(off, io.SeekStart); err != nil &#123; return err &#125; // 13. 将新的文件加入数组 w.locks[len(w.locks)-1] = newTail // 14. 重新计算检验和 以及 encoder prevCrc = w.encoder.crc.Sum32() w.encoder, err = newFileEncoder(w.tail().File, prevCrc) if err != nil &#123; return err &#125; return nil&#125; // wal.go 至此关于WAL库的日志管理相关的接口已经分析完毕。简单总结一下，本文是从【etcd raftexample 源码简析】中对WAL库接口的调用切入（日志重放的操作），然后简要分析了WAL日志文件创建、WAL初始化（打开）、WAL日志项读取及WAL追加日志项等流程。最后，关于WAL库与如何与raft核心协议交互的内容，后面再了解。 参考文献 [1]. etcd-raft日志管理[2]. https://github.com/etcd-io/etcd/tree/master/wal]]></content>
      <categories>
        <category>分布式系统</category>
        <category>分布式协调服务</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>WAL 日志</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[etcd-raft 网络传输源码简析]]></title>
    <url>%2F2019%2F01%2F10%2Fetcd-raft-%E7%BD%91%E7%BB%9C%E4%BC%A0%E8%BE%93%E6%BA%90%E7%A0%81%E7%AE%80%E6%9E%90%2F</url>
    <content type="text"><![CDATA[上一篇文章简单分析了etcd raftexample的源码。我们知道，etcd raft只实现了raft协议核心部分，而将诸如日志、快照及消息的网络传输交给应用来管理。本文会简单分析raft集群用来实现消息在节点之间传输部分的相关逻辑。因为etcd raft会在节点之间传递各种消息指令，包括日志复制、快照拷贝等，这都需要通过应用来将对应的消息转发到集群中其它节点。简单而言，raft实现的节点之间的网络传输将消息的读写进行分离，即每两个节点之间存在两条消息通道，分别用作消息的接收与发送，另外针对不同类型的消息的收发，其也提供了不同的组件。本文会对大致的消息传输的流程进行介绍。 数据结构同上一篇博文类似，希望读者能够主动查看源码（主要涉及目录/etcd/etcdserver/api/rafthttp），文章只作参考。我们先来观察一下与网络传输相关的重要的数据结构，一般而言，只要理解了核心的数据结构的功能，基本就能推断相关的功能与大致的流程。网络传输最核心的结构为Transporter： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354type Transporter interface &#123; // Start starts the given Transporter. // Start MUST be called before calling other functions in the interface. // 在处理具体的消息收发之前，需要启动网络传输组件。它在应用初始化（如初始化 raftNode）时启动 // 网络传输组件 Start() error // Handler returns the HTTP handler of the transporter. // A transporter HTTP handler handles the HTTP requests // from remote peers. // The handler MUST be used to handle RaftPrefix(/raft) // endpoint. // 消息传输组件的消息处理器，它对不同消息配置不同的消息处理器（如pipelineHandler、streamHandler）。 Handler() http.Handler // Send sends out the given messages to the remote peers. // Each message has a To field, which is an id that maps // to an existing peer in the transport. // If the id cannot be found in the transport, the message // will be ignored. // 消息发送接口，即将消息发送到指定 id 的节点 Send(m []raftpb.Message) // SendSnapshot sends out the given snapshot message to a remote peer. // The behavior of SendSnapshot is similar to Send. // 快照数据发送接口 SendSnapshot(m snap.Message) // 后面都是关于节点的管理的方法，不作重点阐述 // AddRemote adds a remote with given peer urls into the transport. // A remote helps newly joined member to catch up the progress of cluster, // and will not be used after that. // It is the caller's responsibility to ensure the urls are all valid, // or it panics. AddRemote(id types.ID, urls []string) // AddPeer adds a peer with given peer urls into the transport. // It is the caller's responsibility to ensure the urls are all valid, // or it panics. // Peer urls are used to connect to the remote peer. AddPeer(id types.ID, urls []string) // RemovePeer removes the peer with given id. RemovePeer(id types.ID) // RemoveAllPeers removes all the existing peers in the transport. RemoveAllPeers() // UpdatePeer updates the peer urls of the peer with the given id. // It is the caller's responsibility to ensure the urls are all valid, // or it panics. UpdatePeer(id types.ID, urls []string) // ActiveSince returns the time that the connection with the peer // of the given id becomes active. // If the connection is active since peer was added, it returns the adding time. // If the connection is currently inactive, it returns zero time. ActiveSince(id types.ID) time.Time // ActivePeers returns the number of active peers. ActivePeers() int // Stop closes the connections and stops the transporter. Stop()&#125; // transport.go 需要补充一点的是，在上面的函数声明中，我们可以推测，节点采用peer的实例来进行消息的收发，由transport只是对外提供统一的接口，并提供逻辑框架。那remote又作何用？查看源码注释可以知道，remote是帮助新加入到集群的节点”追赶”当前集群正常节点的组件，除那之后，它没有其它作用。而相比之下，peer则代表raft节点与其它节点通信的实体。后面会详细阐述peer组件。下面来了解下Trasnporter的具体实现Transport结构： 1234567891011121314151617181920212223242526272829303132// Transport 实现了 Transporter 接口，用户使用其提供的接口实现完成消息收发type Transport struct &#123; Logger *zap.Logger DialTimeout time.Duration // maximum duration before timing out dial of the request // DialRetryFrequency defines the frequency of streamReader dial retrial attempts; // a distinct rate limiter is created per every peer (default value: 10 events/sec) DialRetryFrequency rate.Limit TLSInfo transport.TLSInfo // TLS information used when creating connection ID types.ID // local member ID URLs types.URLs // local peer URLs ClusterID types.ID // raft cluster ID for request validation Raft Raft // raft state machine, to which the Transport forwards received messages and reports status Snapshotter *snap.Snapshotter ServerStats *stats.ServerStats // used to record general transportation statistics // used to record transportation statistics with followers when // performing as leader in raft protocol LeaderStats *stats.LeaderStats // leader 节点用于记录传输消息到 follower 的相关数据统计 ErrorC chan error streamRt http.RoundTripper // roundTripper used by streams pipelineRt http.RoundTripper // roundTripper used by pipelines mu sync.RWMutex // protect the remote and peer map remotes map[types.ID]*remote // remotes map that helps newly joined member to catch up peers map[types.ID]Peer // peers map pipelineProber probing.Prober streamProber probing.Prober&#125; // transport.go 可以发现，Transport里面包含了一个对Raft状态机接口，容易想到，因为，当网络传输组件接收到涎宾，需要对消息进行处理，具体即需要交给Raft来处理，因此它提供这样一个接口。应用可以实现此接口以实现对接收到的消息进行处理。 1234567type Raft interface &#123; // 消息处理接口，raftNode 实现了此函数，并调用底层的 raft 协议库 node 的 Step 函数来处理消息 Process(ctx context.Context, m raftpb.Message) error IsIDRemoved(id uint64) bool ReportUnreachable(id uint64) ReportSnapshot(id uint64, status raft.SnapshotStatus)&#125; // transport.go 下面重点来查看一下peer数据结构（暂且忽略remote）。Peer接口定义如下： 12345678910111213141516171819202122232425type Peer interface &#123; // send sends the message to the remote peer. The function is non-blocking // and has no promise that the message will be received by the remote. // When it fails to send message out, it will report the status to underlying // raft. // 发送消息的接口，注意此接口是 non-blocking 的，但它不承诺可靠消息传输，但会报告出错信息 send(m raftpb.Message) // sendSnap sends the merged snapshot message to the remote peer. Its behavior // is similar to send. // 传输快照数据 sendSnap(m snap.Message) // update updates the urls of remote peer. update(urls types.URLs) // attachOutgoingConn attaches the outgoing connection to the peer for // stream usage. After the call, the ownership of the outgoing // connection hands over to the peer. The peer will close the connection // when it is no longer used. // 一旦接收到对端的连接，会把连接 attach 到节点 encoder 的 writer 中，以协同 encoder 和对端decoder的工作了 attachOutgoingConn(conn *outgoingConn) activeSince() time.Time stop()&#125; // peer.go 紧接着，我们了解下Peer接口的实现peer： 1234567891011121314151617181920212223242526272829type peer struct &#123; lg *zap.Logger localID types.ID // id of the remote raft peer node id types.ID r Raft status *peerStatus picker *urlPicker msgAppV2Writer *streamWriter writer *streamWriter pipeline *pipeline snapSender *snapshotSender // snapshot sender to send v3 snapshot messages msgAppV2Reader *streamReader msgAppReader *streamReader recvc chan raftpb.Message propc chan raftpb.Message mu sync.Mutex paused bool cancel context.CancelFunc // cancel pending works in go routine created by peer. stopc chan struct&#123;&#125;&#125; // peer.go 首先，需要说明的是，peer包含两种机制来发送消息：stream及pipeline。其中stream被初始化为一个长轮询的连接，在消息传输过程中保持打开的状态。另外，peer也提供一种优化后的stream以用来发送msgApp类型的消息，这种消息由leader向follower节点发送，其占据一大部分的消息内容。而对比之下，pipeline则是为http请求提供的http客户端。它只在stream还没有被建立的时候使用。另外，从peer结构中发现还有一个专门用于发送snap的发送器。换言之，针对不同的类型的消息采用不同的传输方式应该可以提高效率。 关键流程下面从组件启动开始监听、消息发送及消息接收三个方面来阐述相关的逻辑，这三个方面可能会相互穿插，但如果读者跟着代码来解读，相信也较容易理解。 启动监听下面会从raftNode(raft.go)中初始化代码开始索引(startRaft())，它使用rc.transport.Start()启动网络传输组件，并通过t.peers[id] = startPeer(t, urls, id, fs)启动各节点上的网络传输实体。在startPeer函数中，分别创建启动了pipeline以及stream，并提供了两个管道，一个作为消息的缓冲区，但因为消息会被阻塞处理（调用了Process()），可能花费较长时间，因此额外提供了一个pending的管理用于接收消息。 另外，我们接紧着先来查看一下，stream监听消息的逻辑（pipeline监听的逻辑更为简单，但流程类似，初始化，然后设置监听）。注意到在startPeer函数中有两行代码（针对不同的版本同时启动了相关的逻辑处理），启用了stream监听(p.msgAppV2Reader.start())，在start()方法中，开启了一个 go routine，它这个协程中(run()方法)，它会先与对端建立连接，通过dial()来实现，然后调用decodeLoope()函数来循环读取远程的节点发来的消息，并调用decode()函数进行消息解码处理。 消息发送下面梳理一下消息的发送的流程，即在raft.serveChannels()函数中，当raft应用层收到底层raft的消息指令时，需要把消息指令转发给其它peer（rc.transport.Send(rd.Messages)）。在Send()方法中，其大致逻辑为取出对端地址，然后对消息进行发送。在peer.send()函数中，它将消息发送到指定的writerc中，writerc是pipeline的一个结构p.pipeline.msgc，它在pipeline.start()中被初始化，并且在handler()方法中持续监听此通道的消息，一旦管道中有消息，则取出消息，并使用post()函数发送。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263func (p *peer) send(m raftpb.Message) &#123; p.mu.Lock() paused := p.paused p.mu.Unlock() if paused &#123; return &#125; // 1. 根据消息的类型选择具体的传输方式 writec, name := p.pick(m) select &#123; // 2. 将消息放到管道中 case writec &lt;- m: default: p.r.ReportUnreachable(m.To) if isMsgSnap(m) &#123; p.r.ReportSnapshot(m.To, raft.SnapshotFailure) &#125; // ... &#125;&#125; // peer.go// pick picks a chan for sending the given message. The picked chan and the picked chan// string name are returned.func (p *peer) pick(m raftpb.Message) (writec chan&lt;- raftpb.Message, picked string) &#123; var ok bool // Considering MsgSnap may have a big size, e.g., 1G, and will block // stream for a long time, only use one of the N pipelines to send MsgSnap. if isMsgSnap(m) &#123; return p.pipeline.msgc, pipelineMsg &#125; else if writec, ok = p.msgAppV2Writer.writec(); ok &amp;&amp; isMsgApp(m) &#123; return writec, streamAppV2 &#125; else if writec, ok = p.writer.writec(); ok &#123; return writec, streamMsg &#125; return p.pipeline.msgc, pipelineMsg&#125; // peer.gofunc (p *pipeline) start() &#123; p.stopc = make(chan struct&#123;&#125;) p.msgc = make(chan raftpb.Message, pipelineBufSize) p.wg.Add(connPerPipeline) for i := 0; i &lt; connPerPipeline; i++ &#123; go p.handle() &#125; // ...&#125; // pipeline.gofunc (p *pipeline) handle() &#123; defer p.wg.Done() for &#123; select &#123; case m := &lt;-p.msgc: start := time.Now() err := p.post(pbutil.MustMarshal(&amp;m)) // 发送消息 end := time.Now() if err != nil &#123; // ... &#125; // ... &#125;&#125; // pipeline.go 因此，整个消息发送的流程还是比较简单且清晰的。 消息接收还记得在raftNode初始化的过程中，有一行这样的代码go rc.serveRaft()，没错，它是用于启动节点网络传输监听。它将监听的处理程序设置为transport.Handler()，相关代码如下： 123456789101112131415161718192021222324func (rc *raftNode) serveRaft() &#123; url, err := url.Parse(rc.peers[rc.id-1]) ln, err := newStoppableListener(url.Host, rc.httpstopc) err = (&amp;http.Server&#123;Handler: rc.transport.Handler()&#125;).Serve(ln) // 开启监听，设置处理器 select &#123; case &lt;-rc.httpstopc: default: log.Fatalf("raftexample: Failed to serve rafthttp (%v)", err) &#125; close(rc.httpdonec)&#125; // raft.go// 为不同的消息类型设置了不同类型的处理器程序func (t *Transport) Handler() http.Handler &#123; pipelineHandler := newPipelineHandler(t, t.Raft, t.ClusterID) streamHandler := newStreamHandler(t, t, t.Raft, t.ID, t.ClusterID) snapHandler := newSnapshotHandler(t, t.Raft, t.Snapshotter, t.ClusterID) mux := http.NewServeMux() mux.Handle(RaftPrefix, pipelineHandler) mux.Handle(RaftStreamPrefix+"/", streamHandler) mux.Handle(RaftSnapshotPrefix, snapHandler) mux.Handle(ProbingPrefix, probing.NewHandler()) return mux&#125; // transport.go 我们具体到其中一个处理器进行查看，比如pipelineHandler，其相关代码如下： 123456789101112131415161718192021222324252627func (h *pipelineHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) &#123; // 1. 请求数据检查 if r.Method != "POST" &#123; w.Header().Set("Allow", "POST") http.Error(w, "Method Not Allowed", http.StatusMethodNotAllowed) return &#125; w.Header().Set("X-Etcd-Cluster-ID", h.cid.String()) limitedr := pioutil.NewLimitedBufferReader(r.Body, connReadLimitByte) b, err := ioutil.ReadAll(limitedr) // ... &#125; // 2. 消息解码 var m raftpb.Message if err := m.Unmarshal(b); err != nil &#123; // ... &#125; receivedBytes.WithLabelValues(types.ID(m.From).String()).Add(float64(len(b))) // 3. 调用 Raft 的 Process 函数进行消息处理 if err := h.r.Process(context.TODO(), m); err != nil &#123; switch v := err.(type) &#123; case writerToResponse: v.WriteTo(w) default: // ... &#125;&#125; // http.go 同样，整个消息的接收的流程也较为简单，针对不同类型的消息采用不同的接收及发送处理器，并将接收到的消息直接交给由应用定义的消息处理接口。至此，整个关于etcd-raft的网络传输相关逻辑的大致流程已经梳理完毕，介绍得比较浅显，只大概梳理了整个流程，如果读者想要深入了解，可以具体到每一个环节的代码深入分析。 参考文献 [1]. etcd-raft网络传输组件实现分析[2]. https://github.com/etcd-io/etcd/blob/master/etcdserver/api/rafthttp]]></content>
      <categories>
        <category>分布式系统</category>
        <category>分布式协调服务</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>网络传输</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[etcd raftexample 源码简析]]></title>
    <url>%2F2019%2F01%2F09%2Fetcd-raftexample-%E6%BA%90%E7%A0%81%E7%AE%80%E6%9E%90%2F</url>
    <content type="text"><![CDATA[最近集中了解了ZAB、Raft及Paxos协议的基本理论，因此想进一步深入到源代码仔细体验一致性协议如何在分布式系统中发挥作用。虽然在 MIT 6.824 课程中有简单实现Raft协议，并基于Raft构建了一个粗糙的 kv 存储系统。但还是想了解下工业生产级别的Raft协议的实现内幕，故选择etcd进行解读。etcd是 CoreOS 基于Raft协议使用 go 开发的分布式 kv 存储系统，可用于服务发现、共享配置及其它利用一致性保障的功能（如leader选举及分布式锁、队列等）。这些功能ZooKeeper不也有提供？没错。它们都可以作为其它分布式应用的独立协调服务，这通过通用的一致性元信息存储来实现。但在易用性上，etcd可谓略胜一筹。因此，后续的一系列博客会简单对etcd各重要组成部分的源码进行简要分析（重点在Raft实现）。本文主要是分析etcd的raftexample的代码。它是etcd官方提供的如何使用etcd内部的Raft协议组件来构建分布式应用的一个简单示例。 etcd内部使用Raft协议对集群各节点的状态（数据、日志及快照等）进行同步。类似于ZooKeeper利用ZAB协议作为底层的可靠的事务广播协议。但etcd对Raft的实现有点特殊，它底层的Raft组件库只实现了Raft协议最核心的部分，这主要包括选主逻辑、一致性具体实现以及成员关系变化。而将诸如WAL、snapshot以及网络传输等模块让用户来实现，这明显增加了使用的难度，但对于应用本质上也更灵活。 本文会简单分析etcd提供的如何其核心的Raft协议组件来构建一个简单的高可用内存 kv 存储（其本质是一个状态机），用户可以通过 http 协议来访问应用（kv 存储系统），以对数据进行读写操作，在对日志进行读写过程中，Raft组件库能够保证各节点数据的一致性。其对应的源码目录为/etcd-io/etcd/tree/master/contrib/raftexample。另外，需要强调的是，本文的主题是利用Raft协议库来构建一个简单的 kv 存储，关于Raft协议库实现的细节不会过多阐述。若读者想继续了解此文，个人建议clone源代码，在阅读源代码的过程中，参考本文效果可能会更好，如果有理解错误的地方，欢迎指正！ 数据结构在按raftexample/main的示例完整解读整个流程之前，先熟悉几个重要的数据结构会有好处。此示例构建的应用为 kv 存储系统，因此，先来了解 kvstore定义的相关字段： 1234567// a key-value store backed by rafttype kvstore struct &#123; proposeC chan&lt;- string // channel for proposing updates mu sync.RWMutex kvStore map[string]string // current committed key-value pairs snapshotter *snap.Snapshotter&#125; // kvstore.go 关键结构成员解释如下： proposeC: 应用与底层Raft核心库之间的通信channel，当用户向应用通过 http 发送更新请求时，应用会将此请求通过channel传递给底层的Raft库。 kvStore: kv 结构的内存存储，即对应应用的状态机。 snapshotter: 由应用管理的快照snapshot接口。 接下来分析一下应用封装底层Raft核心库的结构raftNode，应用通过与raftNode结构进行交互来使用底层的Raft核心协议，它封装完整的Raft协议相关的逻辑（如WAL及snapshot等）。我们先列举它的相关处理逻辑，然后展示其结构内容。具体地逻辑如下： 将应用的更新请求传递给Raft核心来执行。 同时，将Raft协议已提交的日志传回给应用，以指示应用来将日志请求应用到状态机。 另外，它也处理由Raft协议相关的指令，包括选举、成员变化等。 处理WAL日志相关逻辑。 处理快照相关的逻辑。 将底层Raft协议的指令消息传输到集群其它节点。 123456789101112131415161718192021222324252627282930313233// A key-value stream backed by rafttype raftNode struct &#123; proposeC &lt;-chan string // proposed messages (k,v) confChangeC &lt;-chan raftpb.ConfChange // proposed cluster config changes commitC chan&lt;- *string // entries committed to log (k,v) errorC chan&lt;- error // errors from raft session id int // client ID for raft session peers []string // raft peer URLs join bool // node is joining an existing cluster waldir string // path to WAL directory snapdir string // path to snapshot directory getSnapshot func() ([]byte, error) lastIndex uint64 // index of log at start confState raftpb.ConfState snapshotIndex uint64 appliedIndex uint64 // raft backing for the commit/error channel node raft.Node raftStorage *raft.MemoryStorage wal *wal.WAL snapshotter *snap.Snapshotter snapshotterReady chan *snap.Snapshotter // signals when snapshotter is ready snapCount uint64 transport *rafthttp.Transport stopc chan struct&#123;&#125; // signals proposal channel closed httpstopc chan struct&#123;&#125; // signals http server to shutdown httpdonec chan struct&#123;&#125; // signals http server shutdown complete&#125; // raft.go 关键结构成员解释如下： proposeC: 同kvStore.proposeC通道类似，事实上，kvStore会将用户的更新请求传递给raftNode以使得其最终能传递给底层的Raft协议库。 confChangeC: Raft协议通过此channel来传递集群配置变更的请求给应用。 commitC: 底层Raft协议通过此channel可以向应用传递准备提交或应用的channel，最终kvStore会反复从此通道中读取可以提交的日志entry，然后正式应用到状态机。 node: 即底层Raft协议组件，raftNode可以通过node提供的接口来与Raft组件进行交互。 raftStorage: Raft协议的状态存储组件，应用在更新kvStore状态机时，也会更新此组件，并且通过raft.Config传给Raft协议。 wal: 管理WAL日志，前文提过etcd将日志的相关逻辑交由应用来管理。 snapshotter: 管理 snapshot文件，快照文件也是由应用来管理。 transport: 应用通过此接口与集群中其它的节点(peer)通信，比如传输日志同步消息、快照同步消息等。网络传输也是由应用来处理。 其它的相关的数据结构不再展开，具体可以查看源代码，辅助注释理解。 关键流程我们从main.go中开始通过梳理一个典型的由客户端发起的状态更新请求的完整流程来理解如何利用Raft协议库来构建应用状态机。main.go的主要逻辑如下： 123456789101112131415161718func main() &#123; // 解析客户端请求参数信息 ... proposeC := make(chan string) defer close(proposeC) confChangeC := make(chan raftpb.ConfChange) defer close(confChangeC) // raft provides a commit stream for the proposals from the http api var kvs *kvstore getSnapshot := func() ([]byte, error) &#123; return kvs.getSnapshot() &#125; commitC, errorC, snapshotterReady := newRaftNode(*id, strings.Split(*cluster, ","), *join, getSnapshot, proposeC, confChangeC) kvs = newKVStore(&lt;-snapshotterReady, proposeC, commitC, errorC) // the key-value http handler will propose updates to raft serveHttpKVAPI(kvs, *kvport, confChangeC, errorC)&#125; // main.go 显然，此示例的步骤较为清晰。主要包括三方面逻辑：其一，初始化raftNode，并通过 go routine 来启动相关的逻辑，实际上，这也是初始化并启动Raft协议组件，后面会详细相关流程。其二，初始化应用状态机，它会反复从commitC通道中读取raftNode/Raft传递给它的准备提交应用的日志。最后，启动 http 服务以接收客户端读写请求，并设置监听。下面会围绕这三个功能相关的逻辑进行阐述。 Raft 初始化首先我们来理顺Raft初始化的逻辑，这部分相对简单。 12345678910111213141516171819202122232425262728func newRaftNode(id int, peers []string, join bool, getSnapshot func() ([]byte, error), proposeC &lt;-chan string, confChangeC &lt;-chan raftpb.ConfChange) (&lt;-chan *string, &lt;-chan error, &lt;-chan *snap.Snapshotter) &#123; commitC := make(chan *string) errorC := make(chan error) rc := &amp;raftNode&#123; proposeC: proposeC, confChangeC: confChangeC, commitC: commitC, errorC: errorC, id: id, peers: peers, join: join, waldir: fmt.Sprintf("raftexample-%d", id), snapdir: fmt.Sprintf("raftexample-%d-snap", id), getSnapshot: getSnapshot, snapCount: defaultSnapshotCount, // 只有当日志数量达到此阈值时才执行快照 stopc: make(chan struct&#123;&#125;), httpstopc: make(chan struct&#123;&#125;), httpdonec: make(chan struct&#123;&#125;), snapshotterReady: make(chan *snap.Snapshotter, 1), // rest of structure populated after WAL replay &#125; go rc.startRaft() // 通过 go routine 来启动 raftNode 的相关处理逻辑 return commitC, errorC, rc.snapshotterReady&#125; // raft.go newRaftNode初始化一个Raft实例，并且将commitC、errorC及snapshotterReady三个通道返回给raftNode。raftNode初始化所需要的信息包括集群中其它peer的地址、WAL管理日志以及snapshot管理快照的目录等。接下来，分析稍为复杂的startRaft的逻辑： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657func (rc *raftNode) startRaft() &#123; if !fileutil.Exist(rc.snapdir) &#123; // 若快照目录不存在，则创建 if err := os.Mkdir(rc.snapdir, 0750); err != nil &#123; log.Fatalf("raftexample: cannot create dir for snapshot (%v)", err) &#125; &#125; rc.snapshotter = snap.New(zap.NewExample(), rc.snapdir) rc.snapshotterReady &lt;- rc.snapshotter oldwal := wal.Exist(rc.waldir) //判断是否已存在 WAL 日志（在节点宕机重启时会执行） rc.wal = rc.replayWAL() // 重放 WAL 日志以应用到 raft 实例中 rpeers := make([]raft.Peer, len(rc.peers)) for i := range rpeers &#123; // 创建集群节点标识 rpeers[i] = raft.Peer&#123;ID: uint64(i + 1)&#125; &#125; c := &amp;raft.Config&#123; // 初始化底层 raft 协议实例的配置结构 ID: uint64(rc.id), ElectionTick: 10, HeartbeatTick: 1, Storage: rc.raftStorage, MaxSizePerMsg: 1024 * 1024, MaxInflightMsgs: 256, MaxUncommittedEntriesSize: 1 &lt;&lt; 30, &#125; if oldwal &#123; // 若已存在 WAL 日志，则重启节点（并非第一次启动） rc.node = raft.RestartNode(c) &#125; else &#123; startPeers := rpeers if rc.join &#123; // 节点可以通过两种不同的方式来加入集群，应用以 join 字段来区分 startPeers = nil &#125; // 启动底层 raft 的协议实体 node rc.node = raft.StartNode(c, startPeers) &#125; // 初始化集群网格传输组件 rc.transport = &amp;rafthttp.Transport&#123; Logger: zap.NewExample(), ID: types.ID(rc.id), ClusterID: 0x1000, Raft: rc, ServerStats: stats.NewServerStats("", ""), LeaderStats: stats.NewLeaderStats(strconv.Itoa(rc.id)), ErrorC: make(chan error), &#125; // 启动（初始化）transport 的相关内容 rc.transport.Start() for i := range rc.peers &#123; // 为每一个节点添加集群中其它的 peer，并且会启动数据传输通道 if i+1 != rc.id &#123; rc.transport.AddPeer(types.ID(i+1), []string&#123;rc.peers[i]&#125;) &#125; &#125; // 启动 go routine 来处理本节点与其它节点通信的 http 服务监听 go rc.serveRaft() // 启动 go routine 来处理 raftNode 与 底层 raft 通过通道来进行通信 go rc.serveChannels()&#125; 应用初始化应用初始化相关代码较为简单，它只需要初始化内存状态机，并且监听从raftNode传来的准备提交的日志的channel即可，以将commitC读到的日志应用到内存状态机。应用初始化相关代码如下： 12345678func newKVStore(snapshotter *snap.Snapshotter, proposeC chan&lt;- string, commitC &lt;-chan *string, errorC &lt;-chan error) *kvstore &#123; s := &amp;kvstore&#123;proposeC: proposeC, kvStore: make(map[string]string), snapshotter: snapshotter&#125; // replay log into key-value map s.readCommits(commitC, errorC) // read commits from raft into kvStore map until error go s.readCommits(commitC, errorC) return s&#125; // kvstore.go 其中readComits即循环监听通道，并从其中取出日志的函数。并且如果本地存在snapshot，则先将日志重放到内存状态机中。 12345678910111213141516171819202122232425262728293031323334func (s *kvstore) readCommits(commitC &lt;-chan *string, errorC &lt;-chan error) &#123; for data := range commitC &#123; if data == nil &#123; // done replaying log; new data incoming // OR signaled to load snapshot snapshot, err := s.snapshotter.Load() if err == snap.ErrNoSnapshot &#123; return &#125; if err != nil &#123; log.Panic(err) &#125; log.Printf("loading snapshot at term %d and index %d", snapshot.Metadata.Term, snapshot.Metadata.Index) // 将之前某时刻快照重新设置为状态机目前的状态 if err := s.recoverFromSnapshot(snapshot.Data); err != nil &#123; log.Panic(err) &#125; continue &#125; // 先对数据解码 var dataKv kv dec := gob.NewDecoder(bytes.NewBufferString(*data)) if err := dec.Decode(&amp;dataKv); err != nil &#123; log.Fatalf("raftexample: could not decode message (%v)", err) &#125; s.mu.Lock() s.kvStore[dataKv.Key] = dataKv.Val s.mu.Unlock() &#125; if err, ok := &lt;-errorC; ok &#123; log.Fatal(err) &#125;&#125; // kvstore.go 开启 http 服务监听此应用对用户（客户端）提供 http 接口服务。用户可以通过此 http 接口来提交对应用的数据更新请求，应用启动对外服务及设置监听相关逻辑如下： 1234567891011121314151617181920// serveHttpKVAPI starts a key-value server with a GET/PUT API and listens.func serveHttpKVAPI(kv *kvstore, port int, confChangeC chan&lt;- raftpb.ConfChange, errorC &lt;-chan error) &#123; srv := http.Server&#123; Addr: ":" + strconv.Itoa(port), Handler: &amp;httpKVAPI&#123; store: kv, confChangeC: confChangeC, &#125;, &#125; go func() &#123; if err := srv.ListenAndServe(); err != nil &#123; log.Fatal(err) &#125; &#125;() // exit when raft goes down if err, ok := &lt;-errorC; ok &#123; log.Fatal(err) &#125;&#125; // httpapi.go 而接收并解析用户的请求相关逻辑如下所示，它将从用户接收到的对应用的读写请求，传递给raftNode，由raftNode传递至底层的raft协议核心组件来处理。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162func (h *httpKVAPI) ServeHTTP(w http.ResponseWriter, r *http.Request) &#123; key := r.RequestURI switch &#123; case r.Method == "PUT": v, err := ioutil.ReadAll(r.Body) if err != nil &#123; log.Printf("Failed to read on PUT (%v)\n", err) http.Error(w, "Failed on PUT", http.StatusBadRequest) return &#125; // 将请求传递至 raftNode 组件，最终会传递到底层的 raft 核心协议模块 h.store.Propose(key, string(v)) // Optimistic-- no waiting for ack from raft. Value is not yet // committed so a subsequent GET on the key may return old value w.WriteHeader(http.StatusNoContent) case r.Method == "GET": if v, ok := h.store.Lookup(key); ok &#123; w.Write([]byte(v)) &#125; else &#123; http.Error(w, "Failed to GET", http.StatusNotFound) &#125; case r.Method == "POST": url, err := ioutil.ReadAll(r.Body) if err != nil &#123; log.Printf("Failed to read on POST (%v)\n", err) http.Error(w, "Failed on POST", http.StatusBadRequest) return &#125; nodeId, err := strconv.ParseUint(key[1:], 0, 64) if err != nil &#123; log.Printf("Failed to convert ID for conf change (%v)\n", err) http.Error(w, "Failed on POST", http.StatusBadRequest) return &#125; cc := raftpb.ConfChange&#123; Type: raftpb.ConfChangeAddNode, NodeID: nodeId, Context: url, &#125; h.confChangeC &lt;- cc // As above, optimistic that raft will apply the conf change w.WriteHeader(http.StatusNoContent) case r.Method == "DELETE": nodeId, err := strconv.ParseUint(key[1:], 0, 64) if err != nil &#123; log.Printf("Failed to convert ID for conf change (%v)\n", err) http.Error(w, "Failed on DELETE", http.StatusBadRequest) return &#125; cc := raftpb.ConfChange&#123; Type: raftpb.ConfChangeRemoveNode, NodeID: nodeId, &#125; h.confChangeC &lt;- cc // .. &#125;&#125; // httpapi.go 状态机更新请求在 httpapi.go 的逻辑中，我们选择 PUT 请求分支来进行分析。当它接收到用户发送的更新请求时。它会调用 kvstore的Propose函数，并将更新请求相关参数传递过去： 12345678func (s *kvstore) Propose(k string, v string) &#123; var buf bytes.Buffer // 编码后，传递至 raftNode if err := gob.NewEncoder(&amp;buf).Encode(kv&#123;k, v&#125;); err != nil &#123; log.Fatal(err) &#125; s.proposeC &lt;- buf.String()&#125; // kvstore.go 在kvstore将请求 buf 压到管道后，raftNode可以在管道的另一端取出，即在serverChannel函数取出请求，并交由底层 raft协议核心库来保证此次集群状态的更新。相关代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889func (rc *raftNode) serveChannels() &#123; snap, err := rc.raftStorage.Snapshot() if err != nil &#123; panic(err) &#125; // 利用 raft 实例的内存状态机初始化 snapshot 相关属性 rc.confState = snap.Metadata.ConfState rc.snapshotIndex = snap.Metadata.Index rc.appliedIndex = snap.Metadata.Index defer rc.wal.Close() // 初始化一个定时器，每次触发 tick 都会调用底层 node.Tick()函数，以表示一次心跳事件， // 不同角色的事件处理函数不同。 ticker := time.NewTicker(100 * time.Millisecond) defer ticker.Stop() // send proposals over raft // 开启 go routine 以接收应用层(kvstore)的请求（包括正常的日志请求及集群配置变更请求） go func() &#123; confChangeCount := uint64(0) // 循环监听来自 kvstore 的请求消息 for rc.proposeC != nil &amp;&amp; rc.confChangeC != nil &#123; select &#123; // 1. 正常的日志请求 case prop, ok := &lt;-rc.proposeC: if !ok &#123; rc.proposeC = nil &#125; else &#123; // blocks until accepted by raft state machine // 调用底层的 raft 核心库的 node 的 Propose 接口来处理请求 rc.node.Propose(context.TODO(), []byte(prop)) &#125; // 2. 配置变更请求类似处理 case cc, ok := &lt;-rc.confChangeC: if !ok &#123; rc.confChangeC = nil &#125; else &#123; confChangeCount++ cc.ID = confChangeCount rc.node.ProposeConfChange(context.TODO(), cc) &#125; &#125; &#125; // client closed channel; shutdown raft if not already close(rc.stopc) &#125;() // event loop on raft state machine updates // 开启 go routine 以循环处理底层 raft 核心库通过 Ready 通道发送给 raftNode 的指令 for &#123; select &#123; // 触发定时器事件 case &lt;-ticker.C: rc.node.Tick() // store raft entries to wal, then publish over commit channel // 1.通过 Ready 获取 raft 核心库传递的指令 case rd := &lt;-rc.node.Ready(): // 2. 先写 WAL 日志 rc.wal.Save(rd.HardState, rd.Entries) if !raft.IsEmptySnap(rd.Snapshot) &#123; rc.saveSnap(rd.Snapshot) rc.raftStorage.ApplySnapshot(rd.Snapshot) rc.publishSnapshot(rd.Snapshot) &#125; // 3. 更新 raft 实例的内存状态 rc.raftStorage.Append(rd.Entries) // 4. 将接收到消息传递通过 transport 组件传递给集群其它 peer rc.transport.Send(rd.Messages) // 5. 将已经提交的请求日志应用到状态机 if ok := rc.publishEntries(rc.entriesToApply(rd.CommittedEntries)); !ok &#123; rc.stop() return &#125; // 6. 如果有必要，则会触发一次快照 rc.maybeTriggerSnapshot() // 7. 通知底层 raft 核心库，当前的指令已经提交应用完成，这使得 raft 核心库可以发送下一个 Ready 指令了。 rc.node.Advance() case err := &lt;-rc.transport.ErrorC: rc.writeError(err) return case &lt;-rc.stopc: rc.stop() return &#125; &#125;&#125; // raft.go 上述关于 raftNode与底层Raft核心库交互的相关逻辑大致已经清楚。大概地，raftNode会将从kvstore接收到的用户对状态机的更新请求传递给底层raft核心库来处理。此后，raftNode会阻塞直至收到由raft组件传回的Ready指令。根据指令的内容，先写WAL日志，更新内存状态存储，并分发至其它节点。最后如果指令已经可以提交，即底层raft组件判定请求在集群多数节点已经完成状态复制后，则应用到状态机，具体由kvstore来执行。并且若触发了快照的条件，则执行快照操作，最后才通知raft核心库可以准备下一个Ready指令。关于 Ready结构具体内容，我们可以大致看一下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950// Ready encapsulates the entries and messages that are ready to read,// be saved to stable storage, committed or sent to other peers.// All fields in Ready are read-only.// Ready 结构包装了事务日志，以及需要发送给其它 peer 的消息指令，这些字段都是只读的，且有些必须进行持久化，或者已经可以提交应用。type Ready struct &#123; // The current volatile state of a Node. // SoftState will be nil if there is no update. // It is not required to consume or store SoftState. // 包含了内存中的状态，即瞬时状态数据 *SoftState // The current state of a Node to be saved to stable storage BEFORE // Messages are sent. // HardState will be equal to empty state if there is no update. // 包含了持久化的状态，即在消息发送给其它节点前需要保存到磁盘 pb.HardState // ReadStates can be used for node to serve linearizable read requests locally // when its applied index is greater than the index in ReadState. // Note that the readState will be returned when raft receives msgReadIndex. // The returned is only valid for the request that requested to read. // 用于节点提供本地的线性化读请求，但其条件是节点的 appliedIndex 必须要大于 ReadState 中的 index，这容易理解，否则会造成客户端的读的数据的不一致 ReadStates []ReadState // Entries specifies entries to be saved to stable storage BEFORE // Messages are sent. // 表示在发送其它节点之前需要被持久化的状态数据 Entries []pb.Entry // Snapshot specifies the snapshot to be saved to stable storage. // 与快照相关，指定了可以持久化的 snapshot 数据 Snapshot pb.Snapshot // CommittedEntries specifies entries to be committed to a // store/state-machine. These have previously been committed to stable // store. // 可以被提交应用到状态机的状态数据 CommittedEntries []pb.Entry // Messages specifies outbound messages to be sent AFTER Entries are // committed to stable storage. // If it contains a MsgSnap message, the application MUST report back to raft // when the snapshot has been received or has failed by calling ReportSnapshot. // 当 Entries 被持久化后，需要转发到其它节点的消息 Messages []pb.Message // MustSync indicates whether the HardState and Entries must be synchronously // written to disk or if an asynchronous write is permissible. MustSync bool&#125; // /etcd/raft/node.go 日志管理raftexample中使用了etcd提供的通用日志库来管理WAL日志，我们下面来分析下应用管理日志的相关逻辑。在上面的状态机更新请求中，注意到当raftNode接收到raft核心传递的Ready指令，第一步就进行写WAL日志操作，这种操作较为常见，以避免更新丢失。值得一提的的，WAL日志也会在各节点进行同步。另外在startRaft函数中，即启动raftNode相关逻辑时，便进行了WAL日志重放rc.wal = rc.replayWAL()，我们详细看一下日志重放的流程： 123456789101112131415161718192021222324252627282930313233// replayWAL replays WAL entries into the raft instance.// 重放节点 WAL 日志，以将重新初始化 raft 实例的内存状态func (rc *raftNode) replayWAL() *wal.WAL &#123; log.Printf("replaying WAL of member %d", rc.id) // 1. 加载快照数据 snapshot := rc.loadSnapshot() // 2. 借助快照数据（的相关属性）来打开 WAL 日志。应用只会重放快照时间点（索引）之后的日志，因为快照数据直接记录着状态机的状态数据（这等同于将快照数据所对应的 WAL 日志重放），因此可以直接应用到内存状态结构。换言之，不需要重放 WAL 包含的所有的日志项，这明显可以加快日志重放的速度。结合 openWAL 函数可以得出结论。 w := rc.openWAL(snapshot) // 3. 从 WAL 日志中读取事务日志 _, st, ents, err := w.ReadAll() if err != nil &#123; log.Fatalf("raftexample: failed to read WAL (%v)", err) &#125; // 4. 构建 raft 实例的内存状态结构 rc.raftStorage = raft.NewMemoryStorage() if snapshot != nil &#123; // 5. 将快照数据直接加载应用到内存结构 rc.raftStorage.ApplySnapshot(*snapshot) &#125; rc.raftStorage.SetHardState(st) // append to storage so raft starts at the right place in log // 6. 将 WAL 记录的日志项更新到内存状态结构 rc.raftStorage.Append(ents) // send nil once lastIndex is published so client knows commit channel is current if len(ents) &gt; 0 &#123; // 更新最后一条日志索引的记录 rc.lastIndex = ents[len(ents)-1].Index &#125; else &#123; rc.commitC &lt;- nil &#125; return w&#125; // raft.go 通过查看上述的流程，关于 WAL日志重放的流程也很清晰。 快照管理快照(snapshot)本质是对日志进行压缩，它是对状态机某一时刻（或者日志的某一索引）的状态的保存。快照操作可以缓解日志文件无限制增长的问题，一旦达日志项达到某一临界值，可以将内存的状态数据进行压缩成为snapshot文件并存储在快照目录，这使得快照之前的日志项都可以被舍弃，节约了磁盘空间。我们在上文的状态机更新请求相关逻辑中，发现程序有可能会对日志项进行快照操作即这一行代码逻辑rc.maybeTriggerSnapshot()，那我们来具体了解快照是如何创建的： 1234567891011121314151617181920212223242526272829303132333435func (rc *raftNode) maybeTriggerSnapshot() &#123; // 1. 只有当前已经提交应用的日志的数据达到 rc.snapCount 才会触发快照操作 if rc.appliedIndex-rc.snapshotIndex &lt;= rc.snapCount &#123; return &#125; log.Printf("start snapshot [applied index: %d | last snapshot index: %d]", rc.appliedIndex, rc.snapshotIndex) // 2. 生成此时应用的状态机的状态数据，此函数由应用提供，可以在 kvstore.go 找到它的定义 data, err := rc.getSnapshot() if err != nil &#123; log.Panic(err) &#125; // 2. 结合已经提交的日志以及配置状态数据正式生成快照 snap, err := rc.raftStorage.CreateSnapshot(rc.appliedIndex, &amp;rc.confState, data) if err != nil &#123; panic(err) &#125; // 4. 快照存盘 if err := rc.saveSnap(snap); err != nil &#123; panic(err) &#125; compactIndex := uint64(1) // 5. 判断是否达到阶段性整理内存日志的条件，若达到，则将内存中的数据进行阶段性整理标记 if rc.appliedIndex &gt; snapshotCatchUpEntriesN &#123; compactIndex = rc.appliedIndex - snapshotCatchUpEntriesN &#125; if err := rc.raftStorage.Compact(compactIndex); err != nil &#123; panic(err) &#125; log.Printf("compacted log at index %d", compactIndex) // 6. 最后更新当前已快照的日志索引 rc.snapshotIndex = rc.appliedIndex&#125; // raft.go 需要注意的是，每次生成的快照实体包含两个方面的数据：一个显然是实际的内存状态机中的数据，一般将它存储到当前的快照目录中。另外一个为快照的索引数据，即当前快照的索引信息，换言之，即记录下当前已经被执行快照的日志的索引编号，因为在此索引之前的日志不需要执行重放操作，因此也不需要被WAL日志管理。快照的索引数据一般存储在日志目录下。 另外关于快照的操作还有利用快照进行恢复操作。这段逻辑较为简单，因为快照就代表内存状态机的瞬时的状态数据，因此，将此数据执行反序列化，并加载到内存状态机即可： 12345678910func (s *kvstore) recoverFromSnapshot(snapshot []byte) error &#123; var store map[string]string if err := json.Unmarshal(snapshot, &amp;store); err != nil &#123; return err &#125; s.mu.Lock() s.kvStore = store s.mu.Unlock() return nil&#125; // kvstore.go 至此，raftexmaple主要流程已经简单分析完毕。这是一个简单的应用etcd提供的raft核心库来构建一个 kv 存储的示例，虽然示例的逻辑较为简单，但它却符合前面提到的一点：raft核心库只实现了raft协议的核心部分（包括集群选举、成员变更等），而将日志管理、快照管理、应用状态机实现以及消息转发传输相关逻辑交给应用来处理。这使得底层的raft核心库的逻辑简单化，只要实现协议的核心功能（一致性主义的保证），然后提供与上层应用的接口，并通过channel与上层应用组件交互，如此来构建基于Raft协议的分布式高可靠应用。 参考文献 [1]. etcd-raftexample [2]. etcd-raft示例分析]]></content>
      <categories>
        <category>分布式系统</category>
        <category>分布式协调服务</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>分布式协调服务</tag>
        <tag>分布式存储</tag>
        <tag>分布式缓存</tag>
        <tag>一致性协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[简单对比 Raft 及 ZAB 协议]]></title>
    <url>%2F2019%2F01%2F08%2F%E7%AE%80%E5%8D%95%E5%AF%B9%E6%AF%94-Raft-%E5%8F%8A-ZAB-%E5%8D%8F%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[如果你了解过Raft协议、ZAB(ZooKeeper&#39;s Atomic Broadcast)协议及Paxos算法，你会发现它们本质上都是为了解决共识问题，即属于一种一致性算法（原子广播协议通常意义上可以等同于一致性协议）。但你可能会觉得相比于Paxos，ZAB与Raft可能更相似。从直观感受上，Paxos协议（Basic Paxos）更像是一种广义上的一致性算法的理论版本，它泛化了很多问题，并且没有基于特定场景的（工程）设计，因此相对而言也更难理解。而ZAB及Raft则像是具化的一致性化算法，并且简化了一些问题的前提设定，这也使得它们更易理解，也更易实现。本文对Raft协议及ZAB协议进行简单理解对比，主要讨论它们的不同之处。考虑到Raft论文给出了关于实现的详细细节，但官方提供的ZAB论文并没有涉及太多实现细节（Andr´e Medeiros 于 2012 年发表了一篇理论结合实践的论文），因此关于ZAB的细节是针对ZooKeeper的实现而言的。 首先，考虑一个问题，为什么需要选举出一个leader？我们知道，在Basic Paxos中并没有强调一定需要一个leader。但在Raft中包含了leader的强领导原则，而ZAB协议，正常的Broadcast阶段也需要一个leader。很自然地，若能够选举出一个leader节点，由其来统筹所有的客户端请求，可以方便并发控制，而且，因为leader是具备最新日志的节点，这使得日志同步过程也变得更简单，单向地由leader流向follower。另外，其实在日志恢复过程中，需要挑选出包含最新日志的节点，如果将它作为leader，那将使得失败恢复过程加快。最后，根本上而言，Raft及ZAB的对日志的应用都差不多归纳为一个二阶段过程，先收集follower反馈，然后，根据特定规则决定是否提交。那么收集反馈的工作若交由leader来处理，明显简化了协议流程。 接下来，我们简述Raft协议与ZAB协议中选举流程的对比情况。明显地，二者都是先选投票给自己，然后广播投票信息，另外它们都包含了选举轮次的概念（在Raft中为任期term，在ZAB中为round，两者的选举过程可能会涉及多轮），这确实比较类似，但需要注意的是，选举完成后，对于Raft而言，term即为leader所在的任期，而ZAB协议却额外使用了一个任期概念(epoch)。在具体的选举过程中，Raft协议规定一旦节点认为它能够为候选者投票，则在此轮投票过程中，都不会改变。而在ZAB协议中，集群中各节点反复交换选票信息（里面包含各自已提交的历史事务日志），以更新选票信息。二者都有quorum选票成功的概念。 与选举流程相关的另一个问题就是如何定义节点包含更新的事务日志。在Raft中，是通过依次比较term及index来确定。而ZAB协议是依次比较epoch及counter来决定（即通过比较zxid），值得注意的是选举轮次round也会作为比较因素。另外，在Raft中有一个很重要的一点为，被选举出来的leader只能提交本term的事务日志（不能显式提交之前term的未提交的事务日志，论文中详细阐述了原因），即在提交当前term的事务日志时，隐式（顺便）提交了之前term的未提交的（但已被复制到quorum节点）事务日志。在ZAB协议中，当leader选举未完成后，不会存在这样的情况，因为在Broadcast阶段之前，Synchronization阶段（Raft协议并未提供此阶段）会保证各节点的日志处于完全一致的状态。 另外，ZAB与Raft协议在选举阶段都使用了超时机制，以保证节点在超时时间内未收到投票信息，会自动转入下一轮的选举。具体而言，Raft的选举流程还可能会出现瓜分选票的情况(split vote)，因此，Raft通过随机化超时(randomized timeout)时间来缓解这个问题（不是解决）。而ZAB协议不会存在瓜分选票的情况，唯一依据是节点的选票的新旧程度。因此，理论上Raft可能存在活性的问题，即不会选举过程不会终止。而ZAB的选举时间应该会比Raft的选举时间更长（更频繁的交换选票信息）。 其次，在ZAB论文中有提到过，follower及leader由Broadcast阶段进入选举阶段，有各自判定依据，或者，这可以表述为，各节点如何触发leader选举过程。明显，在集群刚启动时，节点会先进行选举。另外，Raft协议通过周期性地由leader向follower发送心跳，心巩固leader的领导地位，一旦超时时间内，follower未收到心跳信息，则转为candidate状态、递增term，并触发选举流程（当leader发现消息回复中包含更高term时，便转为follower状态）。而在ZAB协议中，也是通过leader周期性向follower发送心跳，一旦leader未检测到quorum个回复，则会转为election状态，并进入选举流程（它会断开与follower的连接）。而此时follower一旦检测到leader已经卸任，同样会进入election状态，进入选举流程。 如果不幸leader发生了宕机，集群因此重新进行了选举，并生成了新的leader，上一个term并不会影响到当前的leader的工作。这在Raft及ZAB协议中分别可以通过term及epoch来判定决定。那上一任期遗留的事务日志如何处理？典型地，这包含是否已被quorum节点复制的日志。而对于之前term的事务日志，Raft的策略在前文已经叙述，不会主动提交，若已经被过半复制，则会隐式提交。而那些未过半复制的，可能会被删除。而ZAB协议则采取更激进的策略，对于所有过半还是未过半的日志都判定为提交，都将其应用到状态机。 最后，是关于如何让一个新的节点加入协议流程的问题。在Raft中，leader会周期性地向follower发送心跳信息，里面包含了leader信息，因此，此节点可以重构其需要的信息。在ZAB中会有所不同，刚启动后，它会向转入election状态，并向所有节点发送投票信息，因此，正常情况下它会收到集群中其它的follower节点发送的关于leader的投票信息，当然也会收到leader的消息，然后从这些回复中判断当前的leader节点的信息，然后转入following状态，会周期性收到leader的心跳消息。需要注意的一点是，对于Raft而言，一个节点加入协议（不是新机器）不会阻塞整个协议的运行，因为leader保存有节点目前已同步的信息，或者说下一个需要同步的日志的索引，因此它只需要将后续的日志通过心跳发送给follower即可。而ZAB协议中是会阻塞leader收到客户端的写请求。因此，leader向follower同步日志的过程，需要获取leader数据的读锁，然后，确定需要同步给follower的事务日志，确定之后才能释放锁。值得注意的是，Raft的日志被设计成是连续的。而ZAB的日志被设计成允许存在空洞。具体而言，leader为每个follower保存了一个队列，用于存放所有变更。当follower在与leader进行同步时，需要阻塞leader的写请求，只有等到将follower和leader之间的差异数据先放入队列完成之后，才能解除阻塞。这是为了保证所有请求的顺序性，因为在同步期间的数据需要被添加在了上述队列末尾，从而保证了队列中的数据是有序的，从而进一步保证leader发给follower的数据与其接受到客户端的请求的顺序相同，而follower也是一个个进行确认请求（这不同于Raft，后者可以批量同步事务日志），所以对于leader的请求回复也是严格有序的。 最后，从论文来看，二者的快照也略有不同。Raft的快照机制对应了某一个时刻状态机数据（即采取的是准确式快照）。而ZooKeeper为了保证快照的高性能，采用一种fuzzy snapshot机制（这在ZooKeeper博文中有介绍），大概地，它会记录从快照开始的事务标识，并且此时不会阻塞写请求（不锁定内存），因此，它会对部分新的事务日志应用多次（事务日志的幂等特性保证了这种做法的正确性）。 顺便提一下，ZooKeepr为保证读性能的线性扩展，让任何节点都能处理读请求。但这带来的代价是过期数据。（虽然可通过sync read来强制读取最新数据）。而Raft不会出现过期数据的情况（具体如何保证取决于实现，如将读请求转发到leader）。 本文是从协议流程的各个阶段来对比Raft及ZAB协议。这里也提供更系统、更理论、更深入的对比（加入了Viewstamped Replication和Paxos一致性协议），它简要概括了论文。 关于ZAB协议与Paxos的区别，这里便不多阐述了。在ZAB文章中有简略介绍。另外，也可以在这里进行了解。这篇博文主要参考了文献[1]。 参考文献 [1]. Raft对比ZAB协议[2]. Vive La Différence: Paxos vs Viewstamped Replication vs Zab[3]. Van Renesse R, Schiper N, Schneider F B. Vive la différence: Paxos vs. viewstamped replication vs. zab[J]. IEEE Transactions on Dependable and Secure Computing, 2015, 12(4): 472-484.]]></content>
      <categories>
        <category>分布式系统</category>
        <category>一致性算法</category>
      </categories>
      <tags>
        <tag>一致性算法</tag>
        <tag>原子广播协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[理解 ZAB 协议]]></title>
    <url>%2F2019%2F01%2F05%2F%E7%90%86%E8%A7%A3-ZAB-%E5%8D%8F%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[ZAB 协议是应用于 ZooKeeper 分布式协调框架中的可靠原子广播协议(atomic broadcast protocol)（或者称之为全局有序的广播协议totaly ordered broadcast protocol，二者基本等价），这使得ZooKeeper实现了一个主从(primary-backup)模式的架构以通过主服务器接受客户端的数据变更请求，并使用ZAB协议将数据变更请求增量的传播(progpagate)到集群副本节点。在一定程度上，原子广播协议等价于一致性算法(consensus algorithm)，但它们的侧重点有所不同。本质上而言，ZooKeeper依赖于ZAB协议为其它分布式应用提供诸如配置管理、分布式互斥锁以及leader选举等协调原语服务。另一方面，ZooKeeper之所以能提供高可用(highly-available)（比如支持支持崩溃恢复efﬁcient crash-recovery）及高性能(highly-performance)（包括低延迟low latency、高吞吐量good throughput）的协调服务，部分原因是ZAB协议的核心设计（区别于paxos）及工程实现上的优化。大致地，ZAB协议可以分为四个阶段：leader 选举(leader election)、发现(Discovery)、同步(Synchronization)以及广播(Broadcast)，论文中将阶段一与二合并了，ZAB的实际工程实现耦合了阶段二与三（与论文论述并发完全一致），因此也可以称之为三个阶段。 本文主要阐述自己对ZAB协议的理解，这源自于ZAB相关的三篇论文的总结，但并非对原论文的完整翻译，因此更准确、更完整且更正式的内容可以参考原论文。值得注意的是，本论文并非如原论文那般详细、正式且全面地阐述ZAB协议，因此读者最好先阅读原论文，可以参考本文的协议解读。另外，本文不会过多阐述ZooKeeper的关键原理及系统架构，读者有兴趣可以参考文章，以大致了解ZooKeeper协调服务，并从应用层面整体把握ZAB协议。本文先介绍ZAB协议与二阶段提交的关系及与paxos作简单地对比论述。然后按照ZAB协议的四个阶段展开论述。因为本人暂未详细阅读过 Apache ZooKeeper/ZAB的实现源码，因此本文基本不会涉及与实现相关的细节，最后，考虑到本人知识的局限性，如有论述不当之处，谢谢指正！ 在阅读ZAB相关之前，本人已初步了解过raft和paxos这两个一致性算法，如果你有了解过raft或者paxos，那么ZAB也较容易理解。直观上理解，paxos和ZAB都可以视作改进的二阶段提交的协议，因为原始的二阶段（包括三阶段）提交协议因为至少受到网络分区影响而不能称被直接应用于分布式系统构建。实际上，ZAB协议本质上是一个简化的二阶段协议，从协议构成的阶段形式上看，leader首先提出一个请求(称之为request或者proposal)，等待follower对请求的投票结果返回，最后综合投票结果以提交请求。但相比原始的二阶段提交，ZAB中follower（或者称backup，协议不同阶段的不同称呼）不会abort来自leader的请求，具体地，它只要么接受(acknowledge)leader的proposal，要么放弃此leader，重新进入新的一轮选举。另外，避免abort操作也意味着在ZAB协议中，leader提交请求并不需要经集群中所有的follower的同意，即只要quorum个follower给leader返回了ACK，则leader即请求已经在集群中达成一致。简化的二阶段提交也使得ZAB不得不面临leader失败的情况，因此，ZAB整个协议流程中必须考虑如何从leader失败中恢复的问题。在二阶段提交中，如果协调者失败，可以选择abort事务（准确而言是三阶段，在这里我们并不作严格区分）。 那么对比于paxos算法，ZAB协议有什么优势（即利用ZAB可以方便、正确且高效实现或满足，但paxos则不能达到此要求）？这包括两个方面：其一，ZAB协议允许客户端并发地发送请求消息，换言之，ZAB（ZAB的primary）能够同时处理若干个消息请求，并能保证请求消息以客户端提出的顺序（请求消息的FIFO顺序）被广播到backup节点。事实上，ZAB的能够提供这样的保证的原因是，ZAB中所有的请求消息 （准确而言，所有的写请求消息，因为只有写请求消息才需要被广播，以保持数据的一致性）都由ZAB中的（唯一一个）primary进行广播。因此，ZAB需要保证协议的始终只存在一个primary节点。然而，paxos协议却不能简单直接地保证此属性。简单而言，在paxos协议中，若各primary并发地提出请求（请求之间遵循一定的依赖关系，即只能按照其提出的顺序应用到集群），那么learner并不能保证按照primary提出事务请求的顺序来学习（应用）消息请求。虽然可以一次性将多个proposal进行打包形成一个单独的proposal，即对这些请求进行批处理，但这会影响到整个算法的性能，而且单个打包的proposal数量也不能简单求得。 其二，ZAB协议被设计成能够迅速从失败（可能是由于leader或follower崩溃或者网络故障而断连）中恢复，即efficient recovery。ZAB使用事务标识机制(trasaction identification scheme)来全局排序事务日志，并保证准leader(prospective leader)能够容易获知需要同步或截断的日志项。详细而言，ZAB采用&lt;value, (epoch|counter)&gt;来唯一标识一条事务日志，其中value为事务日志的内容。epoch（也被称为是instance）为leader的任期，每一个任期内保证只存在一个leader，每当重新进入leader选举时，需要递增此任期，事实上，任期可用于保证当上一任的leader失败重启后不会干扰到当前任期的leader的广播操作（这同raft类似，都采用了epoch以在一段逻辑时间内唯一标识leader）。counter为事务消息计数器，每次重新选举时，需要清空counter，此值随着客户端发送的请求消息而递增。epoch与counter各占 32 位以构成事务的zxid，即作为事务日志的标识。这提供了一种简单且方便的方式来比较事务日志的新旧：先比较epoch，epoch越大，日志越新，当epoch相等时，比较counter，counter越大，日志越新。在此种事务日志标识机制下，只有具备了最新的事务日志的节点才允许将其日志项拷贝到准leader。换言之，准leader只需从各节点返回的所有的日志中选择包含最新的日志的节点，以从此节点拷贝其缺失的事务日志（若需要的话）（需要注意的是，事实上这属于Discover阶段中的协议内容，若把此阶段的协议归并到leader选举中，则选举算法阶段会直接选择包含最新的事务日志的节点作为准leader，因此避免了准leader去包含最新的日志项的节点去拷贝操作）。而paxos协议并未要求失败恢复的高效执行。详细地，在其恢复阶段，只凭借拥有最大的日志编号（在paxos中proposer提出的每一条日志都有一个全局唯一的编号）并不能要求其对应的值被新的leader接受(accpet)（更多可以参考paxos论文或者这里 ），因此，新的leader必须为其缺少的日志编号所对应的日志项重新执行paxos协议阶段一的协议内容。 另外值得注意的是，ZAB采用了TCP（可靠的）作为节点之间的通信协议，因此避免了部分网络故障问题（如消息乱序、重复及丢失），TCP协议能够保证消息能够按照其发出的顺序(FIFO)达到目标节点。但paxos和raft协议并不依赖此条件。 在介绍ZAB协议的各阶段前，先简要声明一些术语。在ZAB协议中，每个节点可能处于三种状态中的一种：following、leading及election。所有的leader和follower都会依次循环执行前述的三个阶段：Discover（发现集群中全局最新的事务）、Synchronization（由leader向follower同步其缺失的事务日志）及Broadcast（由leader向follower广播复制客户端的事务日志），且在阶段一之前，节点处于election状态，当它通过执行leader选举流程后，它会判断自己是否有资格成为leader（收到quorum张选票），否则成为follower，我们暂且将leader选举作为协议的第零个阶段。显然，正常情况下，协议只循环在Broadcast阶段中执行，一旦发生follower与leader断连，则节点自动切换到选举阶段。在节点进入Broadcast前，必须保证集群的数据处于一致的状态。另外，在本文中节点、机器或者server同义；请求日志、事务日志、提案及日志命令等也作同义处理（不严谨，但读者需明白它们的细微区别）。下面各阶段涉及的术语： − history: 已被节点所接收的提案日志信息− acceptedEpoch: 接收到的最后一个NEWEPOCH消息的epoch（由准leader生成的epoch）− currentEpoch: 接收到的最后一个NEWLEADER消息的epoch（旧的leader的epoch）− lastZxid: history中最后一个（最新的）事务提案的Zxid编号 Leader Election在leader选举阶段，所有节点的初始状态为election，当选举结束后，节点将选举的结果持久化。在此阶段，若节点p给节点q投票，则节点q称节点p的准leader(prospective leader)，直至进入阶段三Broadcast，准leader才能被称为正式的leader(estabilshed leader)，同时它也会担任primary的角色（这样设计有许多优点）。ZAB协议中，leader与primary的称呼基本表示同一个节点，只不过它们是作为同一节点不同阶段（承担不同功能）的称呼。在leader选举过程中，所有的节点最开始都会为自己投票，若经过若干轮的投票广播后，发现自己不够”资格”成为leader时，就会转入following的状态，否则转为leadering状态。leader选举阶段需要为后面的阶段(Broadcast)提供一个后置条件(postcondition)，以保证在进入Broadcast阶段前，各节点的数据处于一致的状态，所谓的postcondition可以表述为leader必须包含所有已提交(commit)的事务日志。 前文提到，部分leader选举实现会直接选择包含最新的日志的节点作为准leader，FLP(Fast Leader Election)正是这样一种选举算法的实现。它通过选择包含有最大的lastZxid（历史日志中最后一条日志记录的zxid）值的节点作为准leader（因为具有最大lastZxid日志的节点必定具有最全的历史日志提交记录），这可以为后阶段的事务广播提供postcondition保证，FLE由若干轮(round)选举组成，在每一轮选举中，状态为election节点之间互相交换投票信息，并根据自己获得的选票信息(发现更好的候选者)不断地更新自己手中的选票。注意，在FLE执行过程中，节点并不会持久化相关状态属性（因此round的值不会被存盘）。 − recvSet: 用于收集状态为election、following及leading的节点的投票信息− outOfElection: 用于收集状态为following及leading的节点的投票信息（说明选举过程已完成） 具体的选举的流程大致如下（更详细的流程可以参考论文)： 一旦开始选举，节点的初始状态为election，初始化选举超时时间，初始化recvSet及outOfElection。每个节点先为自己投票，递增round值，并把投票(vote包含节点的lastZxid及id)的消息（notification包含vote, id, state及round）广播给其它节点，即将投票信息发送到各节点的消息队列，并等待节点的回复，此后节点循环从其消息队列中取出其它节点发送给它的消息： 若接收到的消息中的round小于其当前的round，则忽略此消息。 若接收到的消息中的round大于节点当前的round，则更新自己的 round，并清空上一轮自己获得的选票的信息集合recvSet。此时，如果消息中的选票的lastZxid比自己的要新，则在本地记录自己为此节点投票，即更新recvSet，否则在本地记录为自己投票。最后将投票信息广播到其它节点的消息队列中。 如果收到的消息的round与节点本地的round相等，即表示两个节点在进行同一轮选举。并且若此消息的state为election并且选票的lastZxid比自己的要新，则在本地记录自己为此节点投票，并广播记录的投票结果。若消息的提案号比自己旧或者跟自己一样，则记录这张选票。 整个选举过程中（节点的状态保持为election，即节点消息队列中的消息包含的状态），若节点检测到自己或其它某个节点得到超过集群半数的选票，自己切换为leading/following状态，随即进入阶段二(Recovery)（FLE选举后，leader具备最新的历史日志，因此，跳过了Discovery阶段，直接进入Synchronization阶段。否则进入Discovery阶段）。 另外，如果在选举过程中，从消息队列中检索出的消息的状态为following或者leading，说明此时选举过程已经完成，因此，消息中的vote即为leader的相关的信息。 具体而言，如果此时消息中的round与节点相同，先在本地记录选票信息，然后若同时检测到消息中的状态为leading，则节点转为following状态，进入下一阶段，否则若非leading状态，则需检查recvSet来判断消息中的节点是否有资格成为leader。 否则，如果round不同，此时很有可能是选举已经完成。此时节点需要判断消息被投票的节点（有可能为leader）是否在recvSet或outOfElection字典中具备quorum张选票，同时，还要检查此节点是否给自己发送给投票信息，而正式确认此节点的leading状态。这个额外的检查的目的是为了避免这种情况：当协议非正常运行时，如leader检测到与follower失去了心跳连接，则其会自动转入election状态，但此时follower可能并没有意识到leader已经失效（这需要一定的时间，因为不同于raft，在ZAB协议中，leader及follower是通过各自的方式来检测到需要重新进行选举过程）。如果在follower还未检测到的期间内，恰好有新的节点加入到集群，则新加入的节点可能会收到集群中quorum个当前处于following状态的节点对先前的leader的投票（此时它已转入election状态），因此，此时仍需要此新加入的节点进行额外的判断，即检查它是否会收到leader发给它的投票消息（如果确实存在）。 最后，补充一点，ZAB的选举过程同样加入了超时机制（且很可能并非线性超时），以应对当节点超时时间内未收到任何消息时，重新进入下一轮选举。 DiscoveryDiscovery阶段的目的是发现全局（quorum个也符合条件）最新的事务日志，并从此事务日志中获取epoch以构建新的epoch，这可以使历史epoch的leader失效，即不再能提交事务日志。另外，一旦一个处于非leadering状态节点收到其它节点的FOLLOWERINFO消息时，它将拒绝此消息，并重新发起选举。简而言之，此阶段中每一个节点会与它的准leader进行通信，以保证准leader能够获取当前集群中所包含的被提交的最新的事务日志。更详细的流程阐述如下： 首先，由follower向其准leader发送FOLLOWERINFO（包含节点的accpetedEpoch）消息。当leader收到quorum个FOLLOWERINFO消息后，从这些消息中选择出最大的epoch值，并向此quorum个follower回复NEWEPOCH（包含最大的epoch）消息。接下来，当follower收到leader的回复后，将NEWEPOCH中的epoch与其本地的epoch进行对比，若回复消息中的epoch更大，则将自己本地的accpetedEpoch设置为NEWEPOCH消息中的epoch值，并向leader回复ACKEPOCH（包含节点的currentEpoch，history及lastZxid）消息。反之，重新进入选举阶段，即进入阶段零。当leader从quorum个节点收到follower的ACKEPOCH消息后，从这些ACKEPOCH消息中(history)查找出最新的（先比较currentEpoch，再比较lastZxid）历史日志信息，并用它覆盖leader本地的history事务日志。随即进入阶段二。 SynchronizationSynchronization阶段包含了失败恢复的过程，在这个阶段中，leaer向follower同步其最新的历史事务日志。简而言之，leader向follower发送其在阶段一中更新的历史事务日志，而follower将其与自己本地的历史事务日志进行对比，如果follower发现本地的日志集更旧，则会将这些日志应用追加到其本地历史日志集合中，并应答leader。而当leader收到quorum个回复消息后，立即发送commit消息，此时准leader(prospective leader)变成了正式leader(established leader)。更详细的流程阐述如下： 首先由准leader向quorum发送NEWLEADER（包含阶段一中的最大epoch及history），当follower收到NEWLEADER消息后，其对比消息中的epoch与其本地的acceptedEpoch，若二者相等，则更新自己的currentEpoch并且接收那些比自己新的事务日志，最后，将本地的history设置为消息中的history集合。之后向leader回复ACKNEWLEADER消息。若leader消息中的epoch与本地的不相等，则转为election状态，并进入选举阶段。当leader收到quorum个ACKNEWLEADER消息后，接着向它们发送COMMIT消息，并进入阶段三。而follower收到COMMIT消息后，将上一阶段接收的事务日志进行正式提交，同样进入阶段三。 事实上，在有些实现中，会对同步阶段进行优化，以提高效率。具体而言，leader实际上拥有两个与日志相关的属性（在前述中，我们只用了history来描述已提交的事务日志），其一为outstandingProposals：每当leader提出一个事务日志，都会将该日志存放至outstandingProposals字典中，一旦议案被过半认同了，就要提交该议案，则从outstandingProposals中删除该议案；其二为toBeApplied：每当准备提交一个议案，就会将该议案存放至toBeApplied中，一旦议案应用到ZooKeeper的内存树中了，就可以将该议案从toBeApplied集合中删除。因此，这将日志同步大致分为两个方面： 一方面，对于那些已应用的日志（已经从toBeApplied集合中移除）可以通过不同的方式来进行同步：若follower消息中的lastZxid要小于leader设定的某一个事务日志索引(minCommittedLog)，则此时采用快照会更高效。也存在这样一种情况，follower中包含多余的事务日志，此时其lastZxid会大于leader的最新的已提交的事务日志索引(maxCommittedLog)，因此，会把多余的部分删除。最后一种情况是，消息中的lastZxid位于二个索引之间，因此，leader需要把follower缺失的事务日志发送给follower。当然，也会存在二者存在日志冲突的情况，即leader并没有找到lastZxid对应的事务日志，此时需要删除掉follower与leader冲突的部分，然后再进行同步。 另一方面，对于那些未应用的日志的同步方式为：对于toBeApplied集合中的日志（已提交，但未应用到内存），则直接将大于follower的lastZxid的索引日志发送给follower，同时发送提交命令。对于outstandingProposals的事务日志，则同样依据同样的规则发送给follower，但不会发送提交命令。 需要注意的的，在进行日志同步时，需要先获取leader的内存数据的读锁（因此在释放读锁之前不能对leader的内存数据进行写操作）。但此同步过程仅涉及到确认需要同步的议案，即将需要被同步的议案放置到对应follower的队列中即可，后续会通过异步方式进行发送。但快照同步则是同步写入阻塞。 当同步完成后，leader会几follower发送UPTODATE命令，以表示同步完成。此时，leader开始进入心跳检测过程，周期性地向follower发送心跳，并检查是否有quorum节点回复心跳，一旦出现心跳断连，则转为election状态，进入leader选举阶段。 BroadcastBroadcast为ZAB正常工作所处的阶段。当进入此阶段，leader会调用ready(epoch)，以使得ZooKeeper应用层能够开始广播事务日志到ZAB协议。同时，此阶段允许动态的加入新节点(follower)，因此，leader必须在新节点加入的时候，与这些节点建立通信连接，并将最新日志同步到这些节点。更详细的流程阐述如下： 当leader(primary)收到客户端发送的消息（写）请求value，它将消息请求转化为事务日志(epoch, &lt;value,zxid&gt;), zxid=(epoch|counter)，广播出去。当follower从leader收到事务请求时，将此事务日志追加到本地的历史日志history，并向leader回复ACK。而一旦leader收到quorum个ACK后，随即向quorum节点发送COMMIT日志，当follower收到此命令后，会将未提交的日志正式进行提交。需要注意的是，当有新的节点加入时，即在Broadcast阶段，若leader收到FOLLOWINFO消息，则它会依次发送NEWEPOCH和NEWLEADER消息，并带上epoch及history。收到此消息的节点会将设置节点本地的epoch并更新本地历史日志。 根据在Synchronization提到的两个数据结构outstandingProposals及toBeApplied。因此，事实上，leader会将其提出的事务日志放至outstandingProposals，如果获得了quorum节点的回复，则会将其从outstandingProposals中移除，并将事务日志放入toBeApplied集合，然后开始提交议案，即将事务日志应用到内存中，同时更新lastZxid，并将事务日志保存作缓存，同时更新maxCommittedLog和minCommittedLog。 最后，讨论ZAB协议中两个额外的细节： 若leader宕机，outstandingProposals字典及toBeApplied集合便失效（并没有持久化），因此它们对于leader的恢复并不起作用，而只是在Synchronization阶段（该阶段实际上是leader向follower同步日志，即也可以看成是follower挂了，重启后的日志同步过程），且同步过程包含快照同步及日志恢复。 另外，在日志恢复阶段，协议会将所有最新的事务日志作为已经提交的事务来处理的，换言之，这里面可能会有部分事务日志还未真正提交，而这里全部当做已提交来处理。（这与raft不同，个人认为，这并不会产生太大影响，因为在日志恢复过程中，并不会恢复那些未被quorum节点通过的事务日志，只是在ZAB在提交历史任期的日志的时机与raft不同，rfat不会主动提交历史任期未提交的日志，只在新的leader提交当前任期内的日志时顺便提交历史的未提交但已经复制到quorum节点的日志项）。 需要注意的是，本文使用的一些术语与Yahoo!官方发表的论文[2]可能不一样（个人参照另外一篇论文[4]阐述），但它们的问题意义相同。而且，对于每个阶段，本文先是大概阐述其流程，然后从实际实现的角度进行拓展，希望不要造成读者的困扰。另外，实际工程实现可能并不完全符合这些阶段，而且ZooKeeper各版本的实现也可能会包含不同的工程优化细节。具体参考论文，当然，查看ZooKeeper源码实现可能更清晰。 参考文献 [1] Gray J N. Notes on data base operating systems[M]//Operating Systems. Springer, Berlin, Heidelberg, 1978: 393-481.[2] Junqueira F P, Reed B C, Serafini M. Zab: High-performance broadcast for primary-backup systems[C]//Dependable Systems &amp; Networks (DSN), 2011 IEEE/IFIP 41st International Conference on. IEEE, 2011: 245-256.[3] Reed B, Junqueira F P. A simple totally ordered broadcast protocol[C]//proceedings of the 2nd Workshop on Large-Scale Distributed Systems and Middleware. ACM, 2008: 2.[4] Medeiros A. ZooKeeper’s atomic broadcast protocol: Theory and practice[J]. Aalto University School of Science, 2012, 20.[5] 倪超. 从 Paxos 到 Zookeeper: 分布式一致性原理与实践[J]. 2015.[6]. ZooKeeper的一致性算法赏析]]></content>
      <categories>
        <category>分布式系统</category>
        <category>一致性算法</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>一致性协议</tag>
        <tag>原子广播协议</tag>
        <tag>选举算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[理解 Paxos Made Simple]]></title>
    <url>%2F2018%2F12%2F20%2F%E7%90%86%E8%A7%A3-Paxos-Made-Simple%2F</url>
    <content type="text"><![CDATA[Paxos 算法在分布式系统领域早已是如雷贯耳般的存在，基本成为了分布式一致性协议的代名词，想必对于任何一个从事分布式领域的人来说都充满敬畏——即感叹算法的精巧，也畏惧算法的晦涩。Leslie Lamport 早在 1980s 就写作了描述 Paxos最原始的论文 《The Part-Time Parliament》，但因其难以理解（与论述方式相关?）而没有得到过多的关注（相反，Lamport 本人却坚持认为自己采用了一种更加形象恰当且容易理解的方式阐述，摈弃了传统学术论文的”死板“风格）。在 2001年，Lamport 对 Paxos 论文进行整理简化并发表了《Paxos Made Simple》，引起了广泛关注。论文的第一句话 The Paxos algorithm, when presented in plain English, is very simple 可以体会到 Leslie Lamport 似乎仍旧对众人对 Paxos 冠以难理解性的言行的”不屑“。 最近重新阅读了《Paxo Made Simple》论文，想从论文本身出发，阐述自己对论文的一些（浅显，且可能有误）的理解，因为还未了解Paoxs系列其它论文（如 Fast Paxos），因此个人的理解可能存在一定的局限性。同时，个人坚持认为，反复读原始论文是理解算法的最根本途径，最好结合开源实现进行理解（开源实现一般都会对算法进行工程上的优化与”妥协”）。当然读完原论文可能会有困惑，因此，也可以尝试参考别人的理解（从不同的角度思考问题，或许会有收获），但最终还是要回归论文。如果你对本文有兴趣，你需要先阅读论文。另外，你需要先了解其应用场景。本文先简述其应用场景，然后按照原论文推理的逻辑和步骤来逐步阐述自己对这些步骤的理解。 Paxos 应用场景Paxos用于解决分布式场景的一致性问题。换言之，Paxos是一个一致性（共识）算法。这个说法可能比较笼统宽泛，因为你可能在很多领域了解过一致性问题（虽然这些解释背后的含义可能也存在共性）。比如对于分布式存储，典型的Nosql数据库领域，所谓的一致性可能是要求客户端能够读取其最新写入的数据。换言之，最近写入的数据需要对所后续的客户端的读都可见，强调的是可见性。这可以用线性一致性(Linearizability)来描述；再者，在数据库领域，顺序一致性(serializability)是事务正确性的保证，即强调正确性；而复制状态机(replicated state machine)是很多一致性算法的典型应用场景（包括Paxos），其强调的是让一组互为备份的节点执行一系列相同的命令日志来保证存储在此节点集合中的数据的一致，以达到容错目的。另外，从一致性算法的强弱角度来考虑，一致性算法包括强一致性，弱一致性以及最终一致性。而Paxos则属于强一致性算法。另外，我们再简单了共识算法的正确性的保证： Agreement - all N (or a majority) nodes decide on the same value Validity - the value that is decided upon must have been proposed by some node in N Termination - all nodes eventually decide 这些都容易理解，比如，对于Agreement而言，若某个算法都不难最后表决出来的值是同一个，那就不能称之为共识算法，而Validity可能觉得是很显然的事情，可以从这样一个角度思考，如果所有节点始终回复相同的值，而不管实际提出的值是什么，那么Agreement能够得到保证，但却违反了Validity条件。最后的Termination保证了算法最终能够停止，即我们不仅希望你们能够做表决，也希望能够最终表决出一个结果，否则此表决过程没有意义。而Paxos论文提到的safty requirement 如下： Only a value that has been proposed may be chosen, Only a single value is chosen, and A process never learns that a value has been chosen unless it actually has been. 明确提出了，只保证了前面两点(Agreement及Validity，只是换了一种说法，并颠倒1与2的顺序)，换言之，理论上而言，Paxos是存在活锁的问题，后面会详细阐述。当然Paxos算法只考虑节点存在non-Byzantine及asynchronous网络的条件下。 那么Paxos如何应用于复制状态机呢？简单而言，Paxos试图通过对所有的（客户端发送的）命令日志（如SET X=1）进行全局编号，如果能够全局编号成功，那么互为备份的节点按照此全局编号顺序来执行对应的命令日志，即能够保证数据的一致性。在一个分布式系统中，若执行命令日志序列前，系统处于一致的状态，且节点都执行了相同的命令日志序列，那么最终整个系统也处于一个一致的状态。因此为了保证每个节点都能够以相同的顺序执行命令日志，所有节点必须对于每一条命令日志达成共识（比如，有两个节点尝试提交命令日志，节点a尝试让v=i，而节点b尝试让v=j，明显这会产生冲突，因此需要协调以达成共识，即最终v的值要么是i，那么所有节点都会认为v=a），即每个节点看到的指令顺序是一致的。显然，问题在于不同的节点可能接收到的日志的编号的顺序是不同的，因此不能按照单个节点的意愿进行命令日志的执行（否则会出现数据一致的情况），换言之，所有节点需要相互通信协调，每个节点都对全局编号的排序进行表决。每一次表决，只能对一条命令日志（数据）进行编号，这样才能保证确定的日志执行，这也正是Paxos所做的，即Paxos的核心在于确保每次表决只产生一条命令日志（一个value，这里的命令日志可以表示一个操作，也可以表示一个值）。当然某一次表决成功（达成一致）并不意味着此时所有节点的本地的value都相同，因为可能有节点宕机，即通常而言，只要保证大多数(quorum)个节点存储相同的value即可。 论文理解这里省略了协议的一些基本术语及概念。但还是再强调一下，协议对某个数据达成一致的真正含义提什么，其表示proposer、acceptor及learner都要认为同一个值被选定。详细而言，对于acceptor而言，只要其接受了某个proposal，则其就认定该proposal的value被选定了。而对于proposer而言，只要其issue的proposal被quorum个acceptor接受了，则其就认定该proposal对应的value就被选定了。最后对于learner而言，需要acceptor将最终决定的value发送给它，则其就认定该value被选定了。另外，acceptor是可能有多个的，因为单个acceptor很明显存在单点故障的问题。 我们直接一步步来观察 Lamport 论文中的推导，以达到最终只有一个值被选中的目的（确定一个值），即Only a single value is chosen。这句话很重要，它暗示了不能存在这样的情形，某个时刻v被决定为了i，而在另一时刻v又被决定成了j。 P1. An acceptor must accept the ﬁrst proposal that it receives. 乍一看此条件，让人有点不知所措。论文前一句提到，在没有故障的情况，我们希望当只有一个proposer的时候，并且其只提出一个value时，能够有一个value被选中，然后就引出了P1。这是理所当然的，因为此acceptor之前没有收到任何的value，或许后面也不会收到了，那它选择此value就无可厚非。换言之，此时acceptor并没有一个合适的拒绝策略，只能先选择这个值。但很明显，这个条件远不能达到我们的目的（比如，多个acceptor可能会接受到不同的proposer提出的不同的value，直接导致不同的value被选定，因此不可能只决定一个值）。而且仔细想想，作者提出的这个条件确实比较奇怪，因为你不知道此条件与最终协议的充要条件有什么联系，而且，你可能会想，既然已经选择了第一个值，若后面又有第二个proposal来了应该如何处理（才能保证最终只选择一个值）。直观上我们可能会推断出，每个acceptor只接受一个proposal是行不通的，即它可能会接受多个proposal，那既然会接受多个proposal，这些proposal肯定是不同的（至少是不同时间点收到的），因此需要进行区分衡量，这也正是提案编号proposal id的作用。另外还暗示了一点，正常情况下，对于proposer而言，一个proposal不能由只被一个acceptor接受了就认定其value被选定，必须要由大多数的（即法定集合quorum）选定才能说这个值被选定了。 直观上理解，虽然我们允许了一个acceptor可以accept多个proposal，但为了保证最终只能决定一个value，因此很容易想到的办法是保证acceptor接受的多个proposal的value相同。这便引出了P2： P2. If a proposal with value v is chosen, then every higher-numbered proposal that is chosen has value v. 为了保证每次只选定一个值，P2规定了如果在一个value已经被选定的情况下，若还有的proposer提交value，那么之后（拥有更高编号higher-numbered）被accept的value应该与之前已经被accept的保持一致。这是一个比较强的约束条件。显然，如果能够保证P2，那么也能够够保证Paxos算法的正确性。 但从另一方面考虑，对比P1与P2，感觉它们有很大的不同，它们阐述的不是同一个问题。P1讨论的是如何选择proposal的问题，而P2则直接跳到了选出来后的问题：一旦value被选定了，后面的被选出来的value应该保持不变。从论文中后面的推断不断增强可以分析出，P2其实包含了P1，两个条件并不是相互独立的，因为P2其实也是一个如何选的过程，只不过它表示了一般情况下应该如何选的问题，而P1是针对第一个proposal应该如何选的问题。换言之，P1是任何后续的推论都需要保证的，后续作出的任何推断都不能与P1矛盾。 注意到，后续若有其它的proposal被选定，前提肯定是有acceptor接受了这个proposal。自然而然，可以转换P2的论述方式，于是就有了P2a： P2a . If a proposal with value v is chosen, then every higher-numbered proposal accepted by any acceptor has value v. P2a其实是在对acceptor做限制。事实上，P2与P2a是一致的，只要满足了P2a就能满足P2。但前面提到过P1是后续推断所必须满足的，而仔细考量P2a，它似乎违反了P1这个约束底线。可以考虑这样一个场景：若有 2 个proposer和 5 个acceptor。首先由proposer-1提出了[id1, v1]的提案，恰好acceptor1~3都顺利接受了此提案，即quorum个节点选定了该值v1，于是对于proposer-1及acceptor1~3而言，它们都选定了v1。而acceptor4在proposer-1提出提案的时候，刚好宕机了（事实上，只要其先接受proposer-2的提案即可，且proposer-2的编号大于proposer-1的编号）而后有proposer-2提出了提案[id2, v2]且id2&gt;id1 &amp; v1!=v2。那么由P1知，acceptor-4在宕机恢复后，必须接受提案[id2, v2]，即选定v2。很明显这不符合P2a的条件。因此，我们只有对P2a进行加强，才能让它继续满足P1所设定的底线。 我们自己可以先直观思考，为了保证acceptor后续通过的proposal的值与之前已经认定的值是相同的。如果直接依据之前的简单流程：proposer直接将其提案发送给acceptor，这可能会产生冲突。所以，我们可以尝试限制后续的proposer发送的提案的value，以保证proposer发送的提案的value与之前已经通过的提案的value相同，于是引出了P2b： P2b. If a proposal with value v is chosen, then every higher-numbered proposal issued by any proposer has value v. P2b的叙述同P2a类似，但它强调（约束）的是proposer的issue提案的过程。因为，issue是发生在accept之前，那么accept的proposal一定已经被issue过的。因此，P2a可以由P2b来保证，而且，P2b的限制似乎更强。另外，P1也同时得到满足。 对于P2b这个条件，其实是难以实现。因为直观上，你不能限定各个proposer该issue什么样的proposal，不能issue什么样的proposal。那么又该如何保证P2b呢？我们同样可以先自己主观思考，为了让proposer之后issue的proposal的value与之前已经被通过的proposal的value的值保持一致，我们是不是可以尝试让proposer提前与acceptor进行沟通，以获取之前已经通过的proposal的value呢？具体如何沟通，无非是相互通信，接收消息或者主动询问，接收消息未免显得过于消极，而主动询问显然是更好的策略。如果的确存在这样的value，那为了保证一致，我就不再指定新的value了，与先前的value保持一致即可。而原论文给出了P2c: P2c. For any v and n, if a proposal with value v and number n is issued, then there is a set S consisting of a majority of acceptors such that either (a) no acceptor in S has accepted any proposal numbered less than n, or (b) v is the value of the highest-numbered proposal among all proposals numbered less than n accepted by the acceptors in S. 作者认为，P2c里面包含了P2b。P2c中的(a)容易理解，因为如果从来没有accept过编号小于n的提案，那由P1自然而然就可以接受。而对于(b)可以用法定集合的性质简单证明，即两个法定集合(quorum)必定存在一个公共元素。我们可以采用反证法结合归纳法来简单证明。假定编号为m且值为v的提案已经被选定，那么，存在一个法定集合C，C中每一个acceptor都选定了v。然后有编号为n的proposal被提出 ：那么， ① 当n=m+1 时，假设编号为n的提案的value不为v而为w。则根据P2c，存在一个法定集合S，要么S中的acceptor从来没有批准过小于n的提案；要么在批准的所有编号小于n的提案中，编号最大的提案的值为w。但因为S和C至少存在一个公共acceptor，明显两个条件都不满足。所以假设不成立。因此n的值为v。② 当编号m属于m ... (n-1)，同样假设编号为n的提案的value不为v，而为w’ 。则存在一个法定集合S’，要么在S’中没有一个acceptor批准过编号小于n的提案；要么在S’中批准过的所有的编号小于n的提案中，编号最大的提案的值为w’。根据假设条件，编号属于m...(n-1)的提案的值都为v，并且S’和C至少有一个公共acceptor，所以由S’中的acceptor批准的小于n的提案中编号最大的那个提案也属于m...(n-1)。从而必然有w’=v。 若要满足P2c，其实也从侧面反映出若要使得proposer提交一个正确的value，必须同时对proposer和acceptor作出限制。我们现在回顾一下先前的推断的递推关系：P2c=&gt;P2b=&gt;P2a=&gt;P2。因此，P2c最终确保了P2，即当一个value被选定之后，后续的编号更大的被选定的proposal都具有先前已经被选定的value。整个过程，先是对整个结果提出要求形成P2，然后转为对acceptor提出要求P2a，进行转为对proposer提出要求P2b，最后，同时对acceptor及proposer作出要求P2c。 Paxos 算法步骤最后，我们简单阐述一下Paxos算法的步骤。其大致可以分为两个阶段。 阶段一，prepare阶段。 proposer选择一个新的编号n发送给quorum个acceptor，并等待回应。 如果acceptor收到一个针对编号为n的prepare请求，则若此prepare请求的编号n大于它之前已经回复过的proposal的所有编号的值，那么它会 (1) 承诺不再接受编号小于n的proposal。(b) 向proposer回复之前已经接受过的proposal中编号最大的proposal（如果有的话）。否则，不予回应。或者，回复一个error给proposer以让proposer终止此轮决议，并重新生成编号。 阶段二，accept阶段。 如果proposer收到了quorum个acceptor对其编号为n的prepare请求的回复，那么它就发送一个针对[n, v]的proposal给quorum个acceptor（此quorum与prepare阶段的quorum不必相同）。其中，v是收到的prepare请求的响应的proposal集合中具有最大编号的proposal的value。如果收到的响应集合中不包含任何proposal，则由此proposer自己决定v的值。 如果acceptor收到一个针对编号为n的accept请求，则若其没有对编号大于n的prepare请求做出过响应，就接受该proposal。 Paxos 算法活性前面提到，理论上Paxos可能永远不会终止（即永远无法达成一致），即使是在没有故障发生的情况。考虑这样一个场景，proposer-1发起了prepare阶段并获得了大多数acceptor的支持，然后proposer-2立刻带着更高的编号来了，发起了prepare阶段，同样获得了大多数的acceptor的支持（因为proposer-2的编号更高，acceptor只能对prepare请求回复成功）。紧接着proposer-a进入了accept阶段，从acceptor的回复中得知大家又都接受了一个更高的编程，因此不得不选择更大的编号并重新发起一轮prepare阶段。同样，proposer-2也会面临proposer-1同样的问题。于是，它们轮流更新编号，始终无法通过。这也就是所谓的活锁问题。FLP定理早就证明过即使允许一个进程失败，在异步环境下任何一致性算法都存在永不终止的可能性。论文后面提出为了避免活锁的问题，可以引入了一个proposer leader，由此leader来提出proposal。但事实上，leader的选举本身也是一个共识问题。而在工程实现上，存在一些手段可以用来减少两个提案冲突的概率（在raft中采用了随机定时器超时的方式来减小选票瓜分的可能性）。 最后，为了更好地理解Paxos算法时，补充（明确）以下几点。 Paxos算法的目的是确定一个值，一轮完整的paxos交互过程值用于确定一个值。且为了确定一个值，各节点需要协同互助，不能”各自为政”。且一旦接受提案，提案的value就被选定。 Paxos算法的强调的是值value，而不是提案proposal，更加不是编号。提案和编号都是为了确定一个值所采用的辅助手段。显然，当一个值被确定时，acceptor接受的提案可能是多个，编号当然也就不同，但是这些提案所对应的值一定是一样的。 Paxos流程保证最终对选定的值达到一致，这需要一个投票决议过程，需要一定时间。 上面描述的大多流程都是正常情况，但毫无疑问，acceptor收到的消息有可能错位，比如 (1) acceptor还没收到prepare请求就直接收到了accept请求，此时要直接写入日志。(2) acceptor还未返回对prepare请求的确认，就收到了accept请求，此时直接写入日志，并拒绝后续的prepare请求。 因为节点任何时候都可能宕机，因此必须保证节点具备可靠的存储。具体而言，(1) 对于proposer需要持久化已提交的最大proposal编号、决议编号(instance id)（表示一轮Paxos的选举过程）。(2) 对于acceptor需要持久化已经promise的最大编号、已accept的最大编号和value以及决议编号。 参考资料 [1]. Lamport L. Paxos made simple[J]. ACM Sigact News, 2001, 32(4): 18-25.[2]. https://blog.csdn.net/chen77716/article/details/6166675[3]. 如何浅显易懂地解说 Paxos 的算法]]></content>
      <categories>
        <category>分布式系统</category>
        <category>一致性算法</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>一致性算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅析分布式事务]]></title>
    <url>%2F2018%2F12%2F11%2F%E6%B5%85%E6%9E%90%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[分布式系统中，将数据块冗余到不同节点使得系统具备容错能力，但其代价是必须要保证各数据副本间的一致性。同样，我们可以将计算（执行）分发到不同节点，以更有效地利用节点并行处理能力，但其代价是必须要对各节点的执行进行协调，以产生应用程序期望的结果。换言之，我们需要推断出节点内部执行的正确性，以保证应用程序可见的语义。而数据库通常能提供涉及事务(transaction)和可序列化(serializability)的相对较强的语义。因此，对于分布式系统而言，此种语义的正确性可以通过分布式事务(distributed transaction)来保证，其通常涉及两个或多个在物理上分离且通过网络连接的主机的数据库事务。 正式而言，分布式事务包含两个方面：并发控制(concurrency control)及原子提交(atomic commit)。并发控制描述事务并发执行的正确性，而原子提交表示事务包含的一组操作要么全部执行，要么全部不执行，这通常与失败(failure)相关。本文会依次阐述分布式事务的并发控制、原子提交相关内容。 并发控制我们以一个例子来展开对并发控制的讨论。考虑一个银行转账的场景：有两个银行账户x和y，且x与y仅次于不同的服务器上，x与y账户初始数目都是 10 。客户端c1将从x账户转账1到y账户，同时，c2是一个审计者以检查银行各账户的钱是否有丢失。因此，抽象化c1及c2的操作为： 1234c1: c2:add(x, 1) tmp1 = get(x)add(y, -1) tmp2 = get(y) print tmp1, tmp2 我们（应用程序）期待最终的结果为：x=11, y=9，同时c2打印 10, 10或者11, 9。但并发执行的操作可能并不会按照应用期待的结果输出。比如，若c2的两个操作完全运行在c1的两个操作之间，导致最终的结果为：x=11, y=9，同时打印11, 10。显然，对于此应用场景而言，我们并不希望出现后者。因此我们需要对并发执行的操作进行协调，以保证其操作结果的语义能够符合应用程序。 先引出一个概念before-or-after atomicity，其定义如下。 Concurrent actions have the before-or-after property if their effect from the point of view of their invokers is the same as if the actions occurred either completely before or completely after one another. 显然，若并发操作能before-or-after atomicity属性，则此转账应用产生的结果是正确的。基于此，我们尝试给出一个能够保证应用程序的正确性的论断。 Coordination among concurrent actions can be considered to be correct if every result is guaranteed to be one that could have been obtained by some purely serial application of those same actions. 可以通过如下几个步骤来认证此观点的正确性：考虑一个系统被应用（可能是并发执行的）操作之后从一个状态转换到另一个状态，如果系统的初始状态是正确的（由具体应用程序确定），并且操作正确地被执行应用到系统，则系统新的状态也是正确的。并且此论述独立于应用程序。同样，如果如果是多个操作并发执行，则上述的论断变更为，若系统最终所处的状态是应用到系统的并发操作集的某个顺序执行后系统的状态，那么此时系统的新的状态也是正确的。换言之，结合before-or-after atomicity属性，可以得出这样的结论：若协调并发操作的规则遵循before-or-after atomicity，则这些并发操作是可序列化的，即存在某些并发事务构成的串行执行顺序，若遵循这些顺序，将导致系统处于相同的终止状态，此时并发操作的结果是正确的。这同样是传统数据事务正确性定义——serializability所要求的。 理论上而言，并发操作的中间过程是不重要的，因为只要保证并发操作所产生的系统新的状态与按照某一个顺序顺序执行所有的“单个”的原子操作所产生的系统新的状态相同，我们并不关心具体与哪一个操作顺序相同，甚至，我们都不要求所谓的顺序操作的中间状态是否真实存在（如图所示，即若操作执行的中间状态的路径是按照虚线进行的），只要此中间状态不会被外部应用程序所观察到，那么我们同样认为这样的操作具备before-or-after atomicity属性，即符合serializability的要求。值得注意的是，对系统应用并发操作的目的是提高性能，但具备before-or-after atomicity属性，或满足serializability的并发操作并不保证系统具备最佳的执行性能。另外，满足serializability特性的并发操作，对编程人员是友好的，因为，我们不必关心并发操作细节。 基于锁的 before-or-after atomicity 属性的实现基于锁来实现事务的并发控制可以分为两个类别：悲观锁(pessimistic)及乐观锁(optimistic)。前者会在操作共享对象之前获取锁，如果在获取锁时，锁已经被其它事务占用了，则必须等待。而后者并不要求在操作共享对象之前获取锁，它会先将对象进行拷贝，然后操作对象，在提交事务的时候检查原始对象是否有被更改过，若没有，则提交事务，否则中止事务，换言之，在获取锁失败时，乐观并发控制(optimistic cocurrency controll)采用的是abort+retry的模式来操作共享对象，因为它没有直接给对象加锁，因此若对象访问没有冲突时，它比悲观锁要快，反之，若在一个充满锁竞争的事务环境下，乐观锁的效果一种会比悲观锁要差。而本节下面提到的基于锁的before-or-after atomicity属性（或serializability）的实现都属于悲观锁的实现。 system-wide lock，即系统级锁。这是基于锁实现的before-or-after atomicity属性最简单的版本。顾名思义，它在系统开始运行时便在内存中创建一个（唯一一个）锁对象，并且必须在事务执行的开始与结束位置插入获取锁与释放锁的代码。显然，system-wide lock一次只允许运行单个事务，它会将所有的事务按照其获取锁的顺序依次执行，不支持事务的并发执行。因为system-wide lock锁住孙事务涉及的所有对象，因此在某些场合其是不必根据，换言之，其锁的粒度（范围）过大。 simple locking，即简单锁。它满足两个规则：其一，每个事务在对某一对象执行实际的读写操作时，必须提前获取此对象的锁。其二，当事务所有操作完成后被提交或者事务被中断时才释放锁。其中，lock point被定义为事务获取其范围内操作所有对象的锁的时刻。而lock set被定义为截止lock point时间点，其所获取的锁的集合。因此，为了保证能正确地协调事务的并发执行，应用程序在执行其每个事务前必须获取事务所对应的lock set，同样，在事务执行完成时释放lock set中的锁。下面简单证明simple locking的策略能够保证before-or-after atomicity。 假定有一个外部观察者维护一个事务标识符的列表，并且一旦某个事务到达其lock point，其标识符就会被添加到此列表，并在事务执行完毕即将释放锁时将其从列表中移除。simple locking能够保证：每个事务都不会在其被添加到列表之前读或写任何对象，并且列表中此事务前面的所有事务都已经通过其对应的lock point。由于任意两个事务lock set不会出现相同的数据对象，因此任何事务的lock set中的数据对象都不会出现在列表中它前面的事务的lock set中，所以也不会出现在列表中更早的事务的lock set中。因此，此事务的输入所涉及的对象内容与列表中的其前一个事务commit（事务顺利完成）或abort（事务中止）后的输出的对象的内容相同。因此，simple locking规则保证此事务before-or-after atomicity属性。 显然，simple locking 所提供的并发粒度也过大，因为，它必须对事务可能涉及到的每一个共享对象加锁，因此它有可能锁住那些原本并不需要的对象。 two-phase locking(2PL)，即两阶段锁。相比于simple locking，它并不要求事务在操作共享对象之前获取其所涉及到的所有对象的锁（准确而言，对于simple locking，一旦事务操作任一共享对象，都需要获取所有对象的锁，而two-phase locking只有等到事务真正操作某一对象时，才去尝试获取此对象对应的锁，因此其锁的粒度要比simple locking要小）。典型地，2PL包括两个过程：1. 扩展锁阶段(expanding phase)，根据操作共享对象的顺序依次获取锁，在此过程中不会有锁被释放。2. 收缩锁阶段(shrinking phase)，锁逐渐被释放，并且在此过程不会尝试获取锁（如果阶段一没有明确的完成标志，那么为了保证事务安全，会等到事务提交或者事务中止时，才会一次性释放所有锁）。但同simple locking类似的是，2PL也允许应用程序并发执行事务，其也会保证所有事务的执行所产生的结果同它们以某一个顺序（到达lock point的顺序）执行所产生的结果相同（因此，2PL有可能导致死锁）。虽然，同simple locking相比，2PL提供更强的事务并发执行能力，但其同样会导致原本允许并发执行的事务的串行顺序执行。参考文献[1]还讨论了当事务执行失败时，锁与日志的交互如何保证事务的顺序执行。 原子提交若构成事务的操作分布在不同机器上，为了确保事务被正确执行，则必须保证事务原子性提交，即分布在不同机器上的事务要么全部执行，要么都不执行。 Two-phase commit(2PC)，两阶段提交。它被用于解决分布式事务原子提交问题（但并没有完全解决）。先简要阐述经典的2PC协议，整个事务由一个事务协调者(transaction coordinator及若干事务参与者(participant)构成，协议的执行大致可以分为如下两个阶段： prepare阶段：客户端向TC发送事务提交请求，TC开始执行两阶段提交。它首先通过RPC向所有的participant发送prepare消息，若participant当前能够执行事务，则向TC回复prepare成功(YES)，并且锁定事务执行所需要的锁与资源，否则回复NO。 commit阶段：若TC收到所有participant回复的YES消息，则开始正式commit事务。它会给所有的participant发送commit消息。participant收到commit消息后，释放事务过程中持有的锁和其他资源，并将事务在本地提交，然后向TC回复commit成功，即YES，否则回复NO。TC收到所有participant回复的commit成功的消息后，向客户端返回成功。反之，一旦TC收到某个participant对preapre消息回复了NO消息，则向所有的participant回复abort消息。 显然，若整个过程无任何故障发生，2PC能够保证分布式事务提交的原子性，因为所有事务参与者对事务的提交都是经由事务协调者来协调决定，因此它们要么全部提交事务要么都不会提交事务。 上述为正常条件下协议执行流程，即没有节点宕机，也没有网络故障。下面讨论若发生失败，会有怎样的情况： 事务参与者宕机，然后重启。若此participant在宕机前对TC的prepare消息回复了YES，那么它必须在宕机前对日志记录。因为其它的participant也有可能同意了prepare消息。具体而言，如果participant重启后，其日志文件记录了prepare的YES消息，但其并没有commit事务，此时它必须主动发消息给TC，或者等待TC重新向它发送commit消息。且在整个过程中，participant必须一直保持对资源及锁的占用。 事务协调者宕机，然后重启。因为TC可能在宕机前对所有协调者发送了commit消息，因此它也必须对此作日志记录。因为或许某个participant已经执行了事务的commit。如果其在重启后，收到了participant的询问消息，必须重新发送commit消息（或者等待一段超时时间后，重新发送commit消息）。 事务协调者一直未收到事务参与者的对prepare消息的回复。可能此时participant已经宕机并且没有重启，也有可能网络发生了故障。因此TC必须设置超时机制，一旦超时未收到回复，则中止事务的提交（因为此时并没有发送commit消息，所有participant都不会提交，保证了事务提交的原子性）。 事务参与者在收到prepare消息前宕机，或超时（一直未收到）。此时，因为participant并没有回复prepare消息（即未对TC作出事务执行的任何承诺），因此其允许单方面中止事务，释放锁及其它资源，此时可能是协议还未开始执行（自然而然，participant的宕机对协议是没有任何影响，直到下一次协议开始执行了，若此participant仍旧处于宕机状态，则将导致abort事务）。 事务协调者在未发送prepare消息前宕机。此时，同上一种情况类似，协议很可能还未开始执行，因此TC的宕机并不影响事务正确性。 事务参与者对prepare消息回复了YES，但是一直未收到commit/abort消息。此时，participant不能单方面中止事务，因为其已经向TC的prepare消息回复了YES，且其它participant也有可能向TC回复了YES，因此TC可能已经向除此participant之外的所有participant发送了commit消息，然后TC发生了宕机。但收到commit消息的participant可能已经commit本地事务。因此，此participant不能单方面abort事务（否则造成事务不一致）。同时，此participant也不能单方面的commit本地事务，因为同样，其它的participant也有可能对TC的prepare消息回复了NO，因此TC在收到所有的prepare消息的回复后，中止了事务的提交。总而言之，若participant对TC的prepare消息回复了YES，则它不能单方面作出任何决定，只能一直阻塞等待TC对事务的决定。 因此，通过上述分述，经典的2PC协议存在明显的局限性： 事务协调者宕机：2PC为一个阻塞式协议，一旦事务协调者宕机，则若有参与者处于执行commit/abort之前的任何阶段，事务进程都将会被阻塞，必须等待事务协调者重启后，事务才能继续执行。 交互延迟：事务协调者必须将事务的commit/abort写日志后才能发送commit/abort‘消息。因此整个过程至少包含2次RPC(prepare+commit)，以及3次日志记录的延迟（prepare写日志+事务协调者状态持久化+commit写日志）。 参考文献 [1] https://en.wikipedia.org/wiki/Two-phase_locking[2] Saltzer J H, Kaashoek M F. Principles of computer system design: an introduction[M]. Morgan Kaufmann, 2009.[3]. 两阶段提交的工程实践]]></content>
      <categories>
        <category>分布式系统</category>
        <category>分布式事务</category>
      </categories>
      <tags>
        <tag>分布式事务</tag>
        <tag>并发控制</tag>
        <tag>原子提交</tag>
        <tag>二阶段提交</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[理解分布式协调服务 zookeeper]]></title>
    <url>%2F2018%2F12%2F04%2F%E7%90%86%E8%A7%A3%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%B0%83%E6%9C%8D%E5%8A%A1-ZooKeeper%2F</url>
    <content type="text"><![CDATA[ZooKeeper是 Yahoo! 于 2010 年在 USENIX 会议上发表的一篇论文中提出的，被用作分布式应用程序的协调服务(coordination service)。虽然ZooKeeper被认为是 Google Chubby的开源实现，但其设计理念却存在较大差异：ZooKeeper致力于提供一个简单且高性能(high performance)的内核(kernel)以为客户端（应用程序）构建更复杂、更高层(high level)的协调原语(coordination primitives)。换言之，ZooKeeper并不针对特定应用或者具体某一协调服务而设计实现，它只提供构建应用协调原语的内核，而将具体协调原语的构建逻辑放权给客户端，并且，它确保了客户端在不需要更改内核服务的前提下，能够灵活构建出新的、更高级的且更强大的协调原语，比如分布式互斥锁、分布式队列等。ZooKeeper为每个客户端操作提供FIFO顺序保证，并且为所有写操作提供linearlizablity保证。ZooKeeper的实现原理为构建在其之上的服务提供高性能保证。 Zookeeper 为分布式应用提供诸如配置管理(configuration managation)、leader 选举等协调服务，这通过为应用程序提供构建协调原语的 API来实现。并且，与那些提供阻塞原语的服务不同，ZooKeeper实现的 wait-free 数据对象确保其容错和高性能特性，因为若利用阻塞原语来构建协调服务，可能会导致那些慢的(slow)或者有错误的(faulty)的客户端影响正常的客户端的服务性能。此博客阐述个人对ZooKeeper的理解，并从一个ZooKeeper的应用实例开始讨论，分别阐述ZooKeeper两个ordering guarantees、。因为本文并非对原论文的完整翻译，因此你需要提前阅读原论文，确保熟知ZooKeeper数据模型以及客户端API等内容，而且，博客也会省略论文所阐述的利用ZooKeeper来实现部分协调服务部分，具体内容可以参考原论文。 一个应用实例阐述我们知道MapReduce需要知道集群master的ip:port以使得其它节点能够与master建立连接通信，为此，MapReduce可以利用ZooKeeper作为动态配置服务，让master candidate在ZooKeeper上并发注册（创建）各自ephemeral类型的ip:port节点，并让slave监听对应节点的watch event，因此一旦有master candidate注册成功（且只能有一个创建成功），则其它节点将能获取到master的ip:port。 若使用基于raft构建的复制状态机实现，比如在raft集群上构建一个key/value存储系统来存放GFS master的元信息。则整个过程大致如下：首先，master candidate向raft发送Put(&quot;gfs-master&quot;, &quot;ip:port&quot;)命令日志，当raft集群apply此命令日志后，其它节点可通过向raft发送Get(&quot;gfs-master&quot;)命令来获取master的ip:port。但此过程存在几个问题：其一，若多个master candidate同时向raft发送节点地址的注册命令日志，此时将产生race condition，其会导致后发送的命令被应用到状态机，因此master candidate需要进一步判断自己是否成为真正的master（不能仅通过发送了节点地址命令日志来确定）；其二，若master失效，其地址项日志必须要从存储中移除，那么谁来执行此操作？因此，必须对master的元数据信息设置timeout timestamp，并且让master通过定期向raft发送Put(ip:port, timestamp)日志来更新timeout的timestamp，而集群其它节点通过向raft轮询(poll)此timestamp来确保master正常工作，毫无疑问，这将产生大量不必要的poll cost。对比使用ZooKeeper来提供此协调服务（上一段），问题是如何被ZooKeeper高效便捷地解决呢？首先它会确保在多个master candidate同时注册地址信息时，只会有一个操作成功；其次，ZooKeeper的session机制简化了timestamp timeout设置，一旦master宕机，其在ZooKeeper上注册的元信息节点将会自动清除。而且，对应的节点移除消息也会通知到其它节点，避免了slave的大量的轮询消耗。由此可见，使用ZooKeeper来进行集群配置信息的管理，有利于简化服务实现的逻辑。 ZooKeeper 两个 ordering guarantees在讨论ZooKeeper两个基本的ordering guarantees之前，先了解什么是 wait-free，你可以从维基或者 Herlihy的论文 上找到其明确定义： A wait-free implementation of a concurrent data object is one that guarantees that any process can complete any operation in a finite number of steps, regardless of the execution speeds of the other processes. Wait-freedom is the strongest non-blocking guarantee of progress, combining guaranteed system-wide throughput with starvation-freedom. An algorithm is wait-free if every operation has a bound on the number of steps the algorithm will take before the operation completes 而对于ZooKeeper而言，其提供的API被称为是wait-free的，因为ZooKeeper直接响应客户端请求，即此请求的返回并不会受到其它客户端操作的影响（通常是slow或者faulty）。换言之，若此客户端请求为写节点数据操作，只要ZooKeeper收到状态变更，则会立即响应此客户端。如果在这之前某一客户端监听了此节点的数据变更事件，则一旦此节点的数据发生变化，则ZooKeeper会推送变更事件给监听的客户端，然后立即返回给写数据的客户端，并不会等待此监听客户端确认此事件。相比于同步阻塞的调用，wait-free明显提供更好的性能，因为客户端不用同步等待每次调用的返回，且其可以进行异步的批量调用batch call操作，以均摊(amortize)网络传输和IO开销。wait-free的API是ZooKeeper具备高性能的基础，因此也是ZooKeeper的设计核心。 ZooKeeper提供了两个基本的ordering guarantees：Linearizable writes及FIFO client order。Linearizable write表示对ZooKeeper的节点状态更新的请求都是线性化的(serializable)，而FIFO client order则表示对于同一个客户端而言，ZooKeeper会保证其操作的执行顺序与客户端发送此操作的顺序一致。毫无疑问，这是两个很强的保证。 ZooKeeper提供了Linearizable write，那什么是Linearizablility？Herlihy的论文同样给出了其定义，为了方便，你也可以参考这里或者这里。 Linearizability is a correctness condition for concurrent objects that provides the illusion that each operation applied by concurrent processes takes effect instantaneously at some point between its invocation and its response, implying that the meaning of a concurrent object’s operations can be given by pre- and post-conditions. 简单而言，Linearizability是分布式系统领域的概念（区别于数据库领域与事务相关的概念Serializability），一个分布式系统若实现了linearizability，它必须能够保证系统中存在一个时间点，在此时间点之后，整个系统会提交到新的状态，且绝不会返回到旧的状态，此过程是即时的(instantaneous)，一旦这个值被提交，其它所有的进程都会看到，系统的写操作会保证是全局有序(totally ordered)。 而ZooKeeper论文提到其write具备Linearizability，确切而言是A-linearizability(asynchronous linearizability)。简而言之，Linearizability原本（原论文）是针对单个对象，单个操作(single object, single operation)而言的，但ZooKeeper扩大其应用范围，它允许客户端同时执行多个操作（读写），并且保证每个操作同样会遵循Linearizability。 值得注意的是，ZooKeeper对其操作（create,delete等）提供pipelining特性，即ZooKeeper允许客户端批量地执行异步操作（比如发送了setData操作后可以立即调用geData），而不需要等到上一个操作的结果返回。毫无疑问，这降低了操作的延迟(lantency)，增加了客户端服务的吞吐量(throughtout)，也是ZooKeeper高性能的保证。但通常情况下，这会带来一个问题，因为所有操作都是异步的，因此这些操作可能会被重排序(re-order)，这肯定不是客户端希望发生的（比如对于两个写操作而言，re-order后会产生奇怪的行为）。因此，对于特定客户端，ZooKeeper还提供client FIFO order的保证。 ZooKeeper 实现原理同分布式存储系统类似，ZooKeeper也会对数据进行冗余备份。在客户端发送请求之前，它会连接到一个ZooKeeper server，并将后续的请求提交给对应的server，当server收到请求后，有做如下三个保证：其一，若请求所操作的节点被某些客户端注册了监听事件，它会向对应的客户端推送事件通知。其二，若此请求为写操作，则server一次性只会对一个请求做处理（不会同时处理其它的读或者写请求）。其三，写操作最终是交由leader来处理（若接收请求的server并非leader，其主动会对请求进行转发），leader会利用Zab（原子广播协议，ZooKeper atomic broadcast）对此请求进行协调，最终各节点会对请求的执行结果达成一致，并将结果 replica到ensemble servers。ZooKeeper将数据存储到内存中（更快），但为了保证数据存储的可靠性，在将数据写到内存数据库前，也会将数据写到磁盘等外部存储。同时，对操作做好相应的replay log，并且其定期会对数据库进行snapshot。 若请求为读操作，则接收请求的server直接在本地对请求进行处理（因此读操作仅仅是在server的本地内存数据库进行检索处理，这也是ZooKeeper高性能的保证）。正因为如此，同GFS可能向客户端返回过期数据的特点类似，ZooKeeper也有此问题。如果应用程序不希望得到过期数据（即只允许得到最近一次写入的数据），则可以采用sync操作进行读操作前的写操作同步，即如果在读操作之前集群还有pending的写操作，会阻塞直至写操作完成。值得注意的是，每一次的读操作都会携带一个zxid，它表示ZooKeeper最近一次执行事务的编号（关于事务，后面会介绍），因此zxid定义了读操作与写操作之间的偏序关系。同时，当客户端连接到server时，如果此server发现其本地存储的当前zxid小于客户端提供的zxid的大小，其会拒绝客户端的连接请求，直至其将本地数据库同步至全局最新的状态。 在ZooKeeper内部，它会将接收到的写操作转换为事务(transaction)操作。因为ZooKeeper可能需要同时处理若干个操作，因此其会提前计算好操作被提交后数据库所处的状态。这里给出论文中提到的一个事务转换的示例：如果客户端发送一个条件更新的命令setData并附带上目标节点的version number及数据内容，当ZooKeeper server收到请求后，会根据更新后的数据，版本号以及更新的时间戳，为此请求生成一个setDataTXN事务。当事务执行出错时（比如版本号不对应），则会产生一个errorTXN的事务。 值得注意的是，ZooKeeper内部所构建的事务操作是幂等的(idempotent)。这有利于ZooKeeper执行失效恢复过程。具体而言，为了应对节点宕机等故障，ZooKeeper会定期进行snapshot操作，ZooKeeper称其为fuzzy snapshot。但与普通的分布式系统不同的是，它在进行快照时，并不会锁定当前ZooKeeper集群（一旦锁定，便不能处理客户端的写操作，且快照的时间一般也相对较长，因此会降低客户端的服务性能），它会对其树形存储进行深度优先搜索，并将搜索过程中所遍历的每一个节点的元信息及数据写到磁盘。因为ZooKeeper快照期间并没有锁定ZooKeeper的状态，因此在此过程中，若有server在同步写操作，则写操作可能只被replica到部分节点，最终使得snapshot的结果处于不一致的状态。但正是由于ZooKeeper的事务操作是idempontent，因此，在recover过程应用snapshot时，还会重新按顺序提交从快照启动开始到结束所涉及到的事务操作。原论文给出了一个快照恢复过程示例。因此我们会发现，fuzzy snapshot同样是ZooKeeper 高性能的体现。另外，事务幂等的特性也使得ZooKeeper不需要保存请求消息的ID（保存的目的是为了防止对重复执行同一请求消息），因为事务的重复执行并不会导致节点数据的不一致性。由此可见，事务幂等性的大大设计简化了ZooKeeper的请求处理过程及日志恢复的过程。 最后，关于原论文所阐述的基于ZooKeeper内核来构建协调服务的相关实例部分，参考实现代码在这里。 参考文献 [1] Hunt P, Konar M, Junqueira F P, et al. ZooKeeper: Wait-free Coordination for Internet-scale Systems[C]//USENIX annual technical conference. 2010, 8(9).[2] Herlihy M P, Wing J M. Linearizability: A correctness condition for concurrent objects[J]. ACM Transactions on Programming Languages and Systems (TOPLAS), 1990, 12(3): 463-492.[3] https://medium.com/databasss/on-ways-to-agree-part-2-path-to-atomic-broadcast-662cc86a4e5f[4] https://en.wikipedia.org/wiki/Non-blocking_algorithm[5] http://www.bailis.org/blog/linearizability-versus-serializability/]]></content>
      <categories>
        <category>分布式系统</category>
        <category>分布式协调服务</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>分布式协调服务</tag>
        <tag>原子广播协议</tag>
        <tag>分布式锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MapReduce 原型实现]]></title>
    <url>%2F2018%2F11%2F16%2FMapReduce-%E5%8E%9F%E5%9E%8B%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[MapReduce 最早是由谷歌于 2004 年在操作系统顶会 OSDI 上发表的一篇面向大规模数据处理的分布式计算框架（并行计算模型）论文中提出。MapReduce使用 Google File System 作为数据存储，支撑起了谷歌全网搜索等大规模数据存储与处理业务。MapReduce 对于大规模数据的高效处理体现在三个方面：其一，大规模数据并行处理，分而治之；其二，MapReduce编程模型；最后，MapReduce运行时环境（失败恢复、任务调度以及负载均衡等）。它简化了并行编程，使得开发人员很容易编写出高效且具备容错能力的并行化程序。 博客基于 MIT 6.824 (2018) 的课程 Lab1。整个实验实现了MapReduce原型，并且对其关键特性进行测试，主要包括MapReduce编程模型，集中在 Map与Reduce两个阶段，以及任务失败处理。在阅读原论文 MapReduce 的基础，Lab1 能够让我们对 MapReduce原理有更为深刻的理解，也能够提高我们实现分布式系统的实践能力，这包括节点通信模型、系统构建框架以及诸如失败恢复机制等。而且，仔细阅读整个 Lab 的代码可以学习到很多原理及设计知识，而不仅仅是完成其 Lab 任务。下文会简单介绍整个 Lab1 框架，然后阐述几个关键点（模块）。 Sequential 及 Distributed 运行模式Lab1 实现了两种不同运行模式的MapReduce原型框架：一种是Sequential运行模式，它顺序编程实现MapReduce过程，也不具备容错功能，因此并非真正意义上的实现。具体地，基于此种运行模式，所有task串行执行且Map与Reduce两个阶段也是串行执行，且未提供任务执行失败的恢复机制。大概地，它首先创建输入文件并读取Map输入，同时创建对应数量的Map task（即循环调用Map函数来处理输入文件），并顺序调度执行，将中间结果写到磁盘上，当所有Map task执行完成后，启动一定数量的Reduce task，并让Reduce task从本地磁盘相应位置读取Map task输出，同样被顺序调度执行，最后，将Reduce task输出写到本地磁盘，最终merge所有输出文件，以合并写到本地输出文件。 另一种是 Distributed运行模式，它更接近真实的MapReduce原型框架实现。客户端会依次启动一个master节点及多个slave节点(go 的goroutine)，并将输入文件信息传给master节点，此后客户端会阻塞等待master返回 。master启动后开始监听slave的连接(one client one goroutine），slave启动后会主动往master节点注册，并等待master分配任务。所有节点通过go rpc实现对等通信。一旦有slave/worker注册成功，master开始实施任务调度，通过rpc将任务信息（任务类型、任务输入文件位置等）发送给worker，而worker在注册成功后，就不断监听master的连接并调用worker的任务执行handler(doTask)， doTask会调用应用程序的Map或Reduce执行MapReduce任务，所有的worker在本节点执行任务的过程同Sequential运行模式下类似，只是各个worker并行执行，互不干扰。值得注意的是，在整个MapReduce Job调度执行过程中，worker允许动态加入，master一旦发现worker注册加入，若此时有未完成的任务等待调度，就会将此任务让新加入的worker调度执行。只有所有的Map task调度完成后，Reduce task才会被调度。当所有Reduce task执行完成后，同样会进行merge的过程，然后从MapReduce框架返回。 Map 及 Reduce 工作流程这里简要阐述 Map &amp; Reduce阶段执行流程。当worker执行map task时，包括以下几个步骤：首先从本地磁盘读取其负责处理的原始输入文件；然后，通过将文件名及文件内容作为参数传递给MapFun来执行用户自定义逻辑；最后，对于每一个Reduce task，通过迭代MapFunc返回的执行结果，并按记录(record)的key进行partition以将分配给对应的Reducer的中间输出结果写到本地磁盘对应文件。 Reduce task的执行过程大致如下：首先读取本Reduce task负责的输入文件，并使用JSON来decode文件内容，并将decode后的kev/value存储到map中，同一个key对应一个value list，然后将整个map的key进行排序，并对每一个key/value list通过调用ReduceFunc来执行用户名自定义逻辑，同时，将其返回的结果，经JSON encode后写入输出文件。这些由Reduce task输出的文件内容，会被merge到最终的输出文件。 再谈失败恢复容错（失败恢复）是MapReduce运行时的一个关键特性。且 Lab1 也模拟实现了任务执行失败后所采取的措施。任务执行失败，典型的包括两种情况：网络分区（网络故障）及节点宕机，且事实上无法很好地区分这两种情形（在两种情形下，master都会发现不能成功ping通 worker）。而实验则是采用阻止worker与master的rpc连接来模拟实现。具体地，所有worker在执行若干个rpc连接请求后（一个rpc连接请相当于一次任务分配），关闭其rpc连接，如此master不能连接worker而导致任务分配执行失败。个人认为，一般情况下会让 master缓存worker的连接handler，并不会在每次发送rpc请求时，都需要执行Dial/DialHttp，若是如此，便不能以原实验的方式来模拟任务执行失败（虽然这可能并不影响）。另外 Lab1 显式禁止了worker同时被分配两个任务的情况，这是显而易见的。 关于失败恢复（节点容错），下面讨论更多细节。容错是MapReduce的一个重要特性，因为节点失效在大数据处理工作中过于频繁，而且当发生节点宕机或者网络不可达时，整个MapReduce job会执行失败，此时MapReduce并不是重启整个job，那样会导致重新提交执行一个庞大的job而耗时（资源）过多，因此它只会重启对应worker所负责执行的task。值得注意的是，正是因为worker并不维护task相关信息，它们只是从磁盘读取输入文件或者将输出写到磁盘，也不存在与其它worker进行通信协调，因此task的执行是幂等的，两次执行会产生相同的执行结果，这也可以说是MapReduce并行执行任务的约束条件之一，也是MapReduce同其它的并行执行框架的不同之处，但无论如何，这样设计使得MapReduce执行任务更为简单。因为Map task会为Reduce task产生输入文件，因此若Reduce task已经从Map task获得了其所需要的所有输入，此时Map的失败，并不会导致其被重新执行。另外关键的是，GFS的atomic rename机制确保即使Map/Reduce task在已经溢写了部分内容到磁盘后失败了，此时重新执行也是安全的，因为GFS会保证直到所有输出写磁盘完成，才使得其输出文件可见，这种情况也会发生在两个Reduce task执行同一个任务，GFS atomic rename机制同样会保证其安全性。那么，若两个Map执行同一个task结果会如何？这种情况发生在，master错误地认为Map task宕机（可能只是发生了网络拥塞或者磁IO过慢，事实上，MapReduce的stragger worker正描述的是磁盘IO过慢的情况），此时即便两个Map task都执行成功（它们不会输出到相同的中间文件，因此不会有写冲突），MapReduce运行时也保证只告诉Reduce task从其中之一获取其输入。最后，注意MapReduce的失败恢复机制所针对的错误是fail-stop故障类型，即要么正常运行，要么宕机，不会产生不正确的输出。 参考代码在这里。 参考文献 [1] Dean J, Ghemawat S. MapReduce: simplified data processing on large clusters[J]. Communications of the ACM, 2008, 51(1): 107-113.[2].MIT 6.824]]></content>
      <categories>
        <category>分布式系统</category>
        <category>分布式计算框架</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>分布式计算框架</tag>
        <tag>MapReduce</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[理解 The Google File System]]></title>
    <url>%2F2018%2F11%2F11%2F%E7%90%86%E8%A7%A3-The-Google-File-System%2F</url>
    <content type="text"><![CDATA[分布式文件系统是构建整个分布式系统的基石，为分布式计算提供底层数据存储。谷歌早在 2013 年就发表了论文 The Google File System，它在谷歌内部是配合其分布式计算框架MapReduce使用，共同为谷歌搜索等业务提供技术栈支撑。虽然数据量激增以及技术革新使得GFS不断演进，但理解其最初的设计理念、运行原理以及关键实现技术同样让人受益匪浅，并指导着我们实际的学习和工程实践。这篇博文阐述个人对原论文的一些理解与心得，并不是对原论文的完整翻译，因此你需要提前阅读论文。 设计动机与目标设计一个通用的分布式文件系统是不现实的，它不仅在实现上异常困难（因为不得不考虑所有应用场景），而且实际使用也难以满足要求（往往存在显而易见的性能或容错瓶颈）。GFS 设计初衷是利用数以千计的廉价机器为MapReduce提供底层可靠且高性能的分布式数据存储，以应对海量离线数据存储与处理的应用场景，比如存储应用程序持续产生的日志流以提供离线日志分析。由此，其设计目标为容错可靠(fault tolerance)、高性能读写(high-performance read&amp;write)以及节约网络带宽(save bandwidth)。 一致性(consistency)是分布式系统不可回避的问题。对于分布式文件系统而言，为了提供容错，必须维持数据副本(replica），那如何保证各副本间一致显得至关重要，特别是在应用并发访问场合。一致性是个极其宽泛的术语，你可以实现数据的强一致性(strong consistency)以保证用户始终读到的是最新的数据，这对于用户（客户端）而言是个极佳选择，但它提高了系统的实现难度，因为你必须设计复杂的一致性协议（如Paxos或Raft）来实现强一致性，它也会损害系统性能，典型的它需要机器之间通信以对副本状态达成一致。而弱一致性(weak consistency)则几乎相反。因此，必须根据特定的应用场景，在保证系统逻辑正确的提前下，放宽一致性要求，设计具备良好性能且能提供足够的一致性(sufficient consistency)的系统。对于GFS而言，它针对MapReduce应用程序进行了特定优化，比如，对大文件高性能读取、允许出现文件空洞(hole)、数据记录重复(record duplicate)以及偶尔读取不一致(inconsistent reads)。具体在数据读写方面，其侧重于大规模一次性写入和追加写入，而并非覆盖写和随机写；读取同样倾向于顺序读取，并不关心随机读取。 Trade-off 理念哲学GFS在设计上存在大量的trade-off。正如前文所述，你不能企图设计出一个完美的系统，而只能针对具体应用场景作出各方面的权衡考量，以达到工程最佳实践目的。 chunk大小设计。GFS针对大文件存储（数百上千兆）设计，因此若存储大量小文件则不能体现其性能。其默认块大小为 64MB。选择大文件作为存储目标原因如下：首先它减少了client与master的交互次数（即使client并不需要整个数据块，但实际上往往存在“就近原则”）；另外，这也直接减少了网络带宽；最后，它减少了存储在master内存中的元数据(metadata)的大小。但凡事总利弊相随。较大的块大小设定使得小文件也不得不占用整个块，浪费空间。 集群元数据‘存储。在master的内存中存放着三种类型的元数据：文件和chunk的名称空间(namespace)、文件到chunk的映射信息以及chunk副本的位置信息。且前两种元数据会定期通过operation log持久化到磁盘以及副本冗余。为什么将这些元信息存储到内存？一方面，缓存在内存无疑会提高性能，另外它也不会造成内存吃紧，因为每个64MB 的chunk只会占用到 64B 的内存空间（粗略估算普通 2G 内存的机器可以容纳 2PB 数据），而且为机器增加内存的代价也很小。那为什么chunk位置信息没有持久化？首先master在启动的时候可以通过heartbeat从各chunk server获取。另一方面，chunk的位置信息有时会变动频繁，比如进行chunk garbage collection、chunk re-replication以及chunk migration，因此，若master也定期持久化chunk位置信息，则master可能会成为集群性能bottleneck。从另一个角度来看，chunck是由chunk server保存，而且随时可能发生disk failure而导致chunk暂时不可被访问，因此其位置信息也应该由chunk server负责提供。 chunk副本（默认3个）存放策略。chunk副本选择目标机器的原则包括两个方面：一是最大化数据可靠性(reliability)及可用性(availability)，这就要求不能把所有的副本存放在一台机器上，如果此机器的发生disk failure，则数据的所有副本全部不可用。放在同一个机架也类似，因为机架之间的交换机或其它网络设计也可能出现故障。另外一个原则是，最大化网络带宽，如果两个副本的位置相隔太远，跨机架甚至跨数据中心，那么副本的写复制代价是巨大的。因此一般的存放位置包括本机器、同一机架不同机器以及不同机架机器。 垃圾回收。当一个文件被删除，GFS不会真正回收对应的chunk，而只是在log operation记录删除日志后，将对应的文件名设置为隐藏。在一定期限内（默认3天），用户可以执行撤销删除操作。否则，master会通过其后台进程定期扫描其文件系统，回收那些隐藏的文件，并且对应的元数据信息也会从内存中擦除。另外，master的后台进程同时还会扫描孤儿块(orphaned chunk)，即那些不能链接到任何文件的chunk，并将这些chunk的元信息删除，这样在后续的heartbeat中让chunk server将对应的chunk删除。这种垃圾回收机制的优点如下：其一，很明显允许用户作出撤销删除操作。其二，统一管理的垃圾回收机制对于故障频繁的分布式系统而言是便捷且可靠的（系统中很容易出现孤儿块）；最后，也有利于提升系统性能。垃圾回收发生在后台进程定期扫描活动中，此时masetr相对空闲，它不会一次性将大量文件从系统移除，从而导致 IO 瓶颈，换言之，其chunk回收成本被均摊(amortized）。但其同样有缺点：如果系统中一段时间内频繁出现文件删除与创建操作时，可能使得系统的存储空间紧张（原论文中也提供了解决方案）。 一致性模型 和 原子 Record Append前文提到GFS并没有采用复杂的一致性协议来保证副本数据的一致性，而是通过定义了三种不同的文件状态，并保证在这三种文件状态下，能够使得客户端看到一致的副本。三种状态描述如下：GFS将文件处于consistent状态定义为：当chunk被并发执行了操作后，不同的客户端看到的并发执行后的副本内容是一致的。而defined状态被定义为：在文件处于consistent状态的基础上，还要保证所有客户端能够看到在此期间对文件执行的所有并发操作，换言之，当文件操作并发执行时，如果它们是全局有序执行的（执行过程中没有被打断），则由此产生的文件状态为defined（当然也是consistent）。换言之，如果某一操作在执行过程中被打断，但所有的并发操作仍然成功执行，只是对文件并发操作的结果不能反映出任一并发操作，因为此时文件的内容包含的是各个并发操作的结果的混合交叉，但无论如何，所有客户端看到的副本的内容还是一致的，在这种情况下就被称为consistent。自然而然，如果并发操作文件失败，此时各客户端看到的文件内容不一致，则称文件处于undefined状态，当然也处于inconsistent状态。 我们先区分几种不同的文件写类型：write指的是由应用程序在写入文件时指定写入的offset；而append同样也是由应用程序来指定写入文件时的offeset，只是此时的offset默认为文件末尾；而record append则指的是应用程序在写入文件时，只提供文件内容，而写入的offset则由GFS来指定，并在写成功后，返回给应用程序，而record append操作正是GFS提供一致性模型的关键，因为它能够保证所有的record append都是原子的(atomic)，并且是at least once atomically。这一点并非我们想像的简单，其所谓的at least once atomic，并不表示采用了atomic record append后，即使在客户端并发操作的情况，也能保证所有的副本完全相同(bytewise idetical)，它只保证数据是以原子的形式写入的，即一次完整的从start chunk offset到end chunk offset的写入，中间不会被其它操作打断。且所有副本被数据写入的chunk offset是相同的。但存在这种情况，GFS对某一副本的执行结果可能会出现record duplicate或者inset padding，这两种情况的写入所占居的文件区域被称为是inconsistent。而最后为了保证应用程序能够从所有副本看到一致的状态，需要由应用程序协同处理。 如果文件的并发操作成功，那么根据其定义的一致性模型，文件结果状态为defined。这通过两点来保证：其一，对文件的副本应用相同的客户端操作顺序。其二，使用chunk version number来检测过期(stale)副本。 record append操作流程如下：客户端首先去请求master以获取chunk位置信息，之后当客户端完成将数据 push 到所有replica的最后一个chunk后，它会发送请求给primiary chuck server准备执行record append。primary首先为每一个客户端操作分配sequence number，然后立即检查此次的record append操作是否会使得chunk大小超过chunk预设定的值（64MB），若超过了则必须先执行insert padding，并将此操作命令同步给所有副本chunk server，然后回复客户端重新请求一个chunk并重试record append。如果未超过chunk阈值，primary会选择一个offset，然后先在本地执行record append操作，然后同样将命令发送给所有副本chunk server，最后回复写入成功给客户端。如果副本chunk server在执行record append的过程中宕机了，则primary会回复客户端此次操作失败，要求进行重试。客户端会请求master，然后重复上述流程。此时，毫无疑问会造成副本节点在相同的chunk offset存储不同的数据，因为有些副本chunk server可能上一次已经执行成功写入了所有数据(duplicate record)，或者写了部分数据(record segment)，因此，必须先进行inset padding，使得各副本能够有一个相同且可用的offset，然后才执行record append。GFS将这种包含paddings &amp; record segments的操作结果交由应用程序来处理。 应用程序的writer会为每个合法的record在其起始位置附加此record的checksum或者一个predictable magic number以检验其合法性，因此能检测出paddings &amp; record segments。如果应用程序不支持record duplicate（比如非幂等idempotent操作），则它会为每一个record赋予一个unique ID，一旦发现两个record具有相同的ID它便认为出现了duplicate record。由GFS为应用程序提供处理这些异常情况的库。 除此之外，GFS对namespace的操作也是原子的（具体通过文件与目录锁实现）。 我们再来理解为什么GFS的record append提供的是at least once atomically语义。这种一致性语义模型较为简单（简单意味着正确性易保证，且有利于工程实践落地，还能在一定程度上提升系统性能），因为如果客户端写入record失败，它只需要重试此过程直至收到操作成功的回复，而server也只需要正常对等待每一个请求，不用额外记录请求执行状态（但不表示不用执行额外的检查）。除此之外，若采用Exactly-once语义模型，那将使整个实现变得复杂：primary需要对请求执行的状态进行保存以实现duplicate detection，关键是这些状态信息必须进行冗余备份，以防primary宕机。事实上，Exactly-once的语义模型几乎不可能得到保证。另外，如果采用at most once语义模型，则因为primary可能收到相同的请求，因此它必须执行请求duplicate detection，而且还需缓存请求执行结果（而且需要处理缓存失效问题），一旦检测到重复的请求，对客户端直接回复上一次的请求执行结果。最后，数据库会采用Zero or once的事务语义(transactional semantics)模型，但严格的事务语义模型在分布式场景会严重影响系统性能。 延迟 Copy On Write快照(snapshot)是存储系统常见的功能。对于分布式系统而言，一个关键挑战是如何尽可能地降低snapshot对成百上千的客户端并发访的性能影响。GFS同样采用的是copy on write技术。事实上，它延迟了snapshot的真正执行时间点，因为在分布式系统中，副本是必须的，大多数情况下，快照涉及的副本可能不会被修改，这样可以不用对那些副本进行 copy，以最大程度提升系统性能。换言之，只有收到客户端对快照的副本执行mutations才对副本进行 copy，然后，将客户端的mutations应用到新的副本。具体的操作流程如下：当master收到客户端的snapshot指令时，首先会从primary节点revoke相应chunk的lease（或者等待lease expire），以确保客户端后续对涉及snapshot的chunk的mutations必须先与master进行交互，并对这些操作执行log operation，然后会对涉及到的chunk的metadata执行duplicate操作，并且会对chunk的reference count进行累加（换言之，那些chunk reference count大于1的chunk即表示执行了snapshot）。如此一来，当客户端发现对已经快照的chunk的操作请求时，master发现请求的chunk的reference count大于1。因此，它会先defer客户端的操作请求，然后选择对应chunk的handler并将其发送给对应的chunk server，让chunk server真正执行copy操作，最后将chunk handler等信息返回给客户端。这种delay snapshot措施能够改善系统的性能。 最后，值得注意的是，虽然客户端并不缓存实际的数据文件（为什么？），但它缓存了chunk位置信息，因此若对应的chunk server因宕机而miss了部分chunk mutations，那客户端是有可能从这些stale的replica中读取到premature数据，这种读取数据不一致的时间取决于chunk locations的过期时间以及对应的文件下一次被open的时间（因为一旦触发这两个操作之一，客户端的cache信息会被purge）。 参考文献： [1] Ghemawat S, Gobioff H, Leung S T. The Google file system[M]. ACM, 2003.[2].MIT 6.824 Lecture]]></content>
      <categories>
        <category>分布式系统</category>
        <category>分布式文件系统</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>分布式文件系统</tag>
        <tag>GFS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式互斥算法解析与实现]]></title>
    <url>%2F2018%2F11%2F09%2F%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%92%E6%96%A5%E7%AE%97%E6%B3%95%E8%A7%A3%E6%9E%90%E4%B8%8E%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[资源共享非常普遍，在单机系统中，进程间对共享资源的互斥访问可以通过互斥锁、信号量以及进程间通信等机制来实现。而在分布式系统中，也不可避免多个节点共享某一资源或同时执行某一函数，比如全局配置文件，因此分布式互斥算法必须保证任何时刻只允许一个进程访问资源或执行临界区(critical section)代码，即互斥算法的安全性，有些场景也有公平性要求。另外，好的互斥算法应该能尽可能降低消息带宽(message overhead)，减少进程（节点）等待时间，即时延(latency)，无系统瓶颈(bottleneck)，也能容忍消息乱序。 分布式互斥算法分为集中式算法(centralized algorithm)和分布式算法(distributed algorithm)，而分布式算法又包括了基于令牌的算法(token based algorithm)以及基于请求的算法(permission based algorithm)。无论基于何种原理实现，一般而言，理想的分布式互斥算法需要保证以下目标： 安全性，即任何时刻只能有一个进程访问共享资源，即持有互斥锁。 公平性，有些场景需要尽量保证访问共享资源的公平性，这表明：系统不能出现死锁，任何进程持有锁的时间是有限的，任何等待的进程最终都能获取锁，以及等待获取锁的进程的等待时间是有限的。 低带宽，即尽量减少消息传输的数目。 低延迟，即进程进入临界区之前的等待的时间。 动态性，即允许进程在任何时刻加入到访问共享资源的进程集合中，或者从其中退出。 容忍进程失败，即允许访问共享资源的进程集合中的进程因失败而退出，而保证整个系统不受影响。 容忍消息丢失，即在消息不能按时到达、乱序甚至丢失的情况下，整个系统依然正常工作。 在本文我们讨论前四个要求，假设进程数目是确定的，没有进程会失败，消息也不会丢失。下面我们通过简要阐述算法原理以及实现关键点来依次介绍Centralized Mutual Server算法、Ricart Agrawala算法、Lamport Distributed Mutual Exclusion算法以及Token Ring算法。 Centralized Mutual Server顾名思义，Centralized Muutal Server为集中式的互斥算法。整个系统内部包括两种消息：请求(reqeust)消息、授权(grant)消息以及释放(release)消息。核心数据结构为一个请求消息队列。算法核心为：它选取一个进程(centralized server)作为协调者，负责对名进程的请求进行即时或推迟(defer)授权。它内部维护一个互斥锁锁请求队列，当收到请求消息时，如果队列为空，则直接授权，否则将其加入到队列中。当收到释放消息时，如果列队不为空，则从队列中取出一个请求并授权响应。算法公平性依赖于队列实现，如使用FIFO则能够保证各个进程的锁请求消息能够被公平地授权。消息带宽为3(1 request, 1 grant, 1 release)，即在某一进程从准备进入临界区到退出临界区所传输消息的数量。很明显，集中式互斥算法的缺点是协调者的瓶颈。 集中式互斥算法最容易实现。在网络通信层，可以采用基于TCP的client-server通信模型。关于协调者的实现，你可能需要关注当前是否已经授权了锁请求。同时，如果有必要，注意单进程内部锁的使用。 Ricart AgrawalaRicart &amp; Agrawala算法是在1981年被提出的一个基于请求的分布式互斥算法。它基于lamport clock，即依赖于全局有序的逻辑时钟。整个系统内部包括两种消息：请求(reqeust,i,ts)消息与回复(reply,j)消息。核心数据结构包括缓存其它进程回复消息的队列(replyQueue)以及缓存推迟回复进程请求消息队列(deferQueue)。算法核心为：当进程i准备进入临界区时，必须发送一个带（逻辑）时间戳的请求消息给其它所有进程，当其收到了其它所有进程的对此请求的回复（响应）时，则进入临界区。但如果某一进程j在收到进程i的请求之前，发出了一个更早的请求消息，则它会将此进程(i)的请求消息放入到延迟队列(deferQueue)，并且先执行完临界区的代码，当准备退出临界区时，才发送请求响应给进程(i)。算法的公平性容易保证。而消息带宽为{request: n-1, reply: n-1} =&gt; 2(n-1)，其中n为进程数。 Ricart Agrawala算法的相比集中式算法在实现上更为复杂。同样在通信层，则不能构建one server, muliti-client模型，而采用peer to peer模型，因为所有进程都是对等的，即同时充当server与client，而且作为一种简化实现，所有进程在启动后，应该互相建立连接。除此之外，你需要实现（模拟）lamport clock 算法，否则互斥算法的正确性不能得到保证，注意对于某些消息（如reply）的发送事件，虽然可以更新消息时间戳，但其实不影响算法正确性。 Lamport Distributed Mutual ExclusionLmpoart Distributed Mutual Exclusion算法于1978年由 Lamport 在关于lamport clock理论论文中提出，其作为lamport clock的实际应用，因此，显然其依赖于lamport clock。事实上，此算法不仅可以作为分布式互斥算法，其内部的请求优先级队列也能作为分布式节点副本一致性的实现参考模型。但原论文提出的互斥算法基于消息按顺序到达的假设，解释如下： 比如，进程i在时间片1发送锁请求a，但因为网络原因被极端延时了。而且在其它进程收到进程i发送的请求消息a之前，进程j在时间片5发送了请求b，而请求b恰好被顺利传输，很快被其他进程接收，并且其他进程（包括进程i）立刻发送了对请求消息b的回复消息，同时回复消息也立刻被进程j接收，但此时进程j仍未收到进程i的请求消息a，所以进程j以为自己成功获取到锁（收到了其它所有进程对请求消息b的回复）。而事实上，进程i的请求消息a要比进程j的请求消息b更早发送，因此应该是进程i先获取锁。其根本原因在于，进程i在收到其他节点请求消息（进程j的请求消息b）时，没有进行额外检查，理论上它需要判定自己是否在更早前发出过请求消息，而不只是直接对请求消息回复，即使最后其在请求消息队列里移除的消息是它自己的请求消息（因为自己是请求消息是最早的）。但这造成了整个系统的不正确性。 因此，改变Lmpoart Distributed Mutual Exclusion算法在接收请求消息后发送回复消息的条件，消除了消息按序到达的假设，但同时也使得变更后的算法更为复杂。 系统内部包括三种消息：请求(reqeust,i,ts)消息、回复(reply,j)消息以及释放(release)消息。核心数据结构包括缓存其它进程回复消息的队列(replyQueue)、缓存推迟回复进程请求消息队列(deferQueue)以及一个以时间戳为依据的请求消息优先级队列(requestPriorityQueue)。算法变更的核心为：进程i在收到进程j的请求消息(request, j, t)时，（条件1）先判断自己是否发送过更早的请求消息，（条件2）并且未收到进程j针对此请求消息的回复消息。如果二者之中任一个未被满足，则对进程i的请求消息发送回复，否则将其加入到deferQueue。原因如下：条件1是明显的；关于条件2，如果进程j已经收到了进程i的消息回复，说明进程i先前发出的请求消息肯定已经被进程j接收（换言之，进程i若发送过请求消息，则此请求消息必定已经缓存到了进程j的requestPriorityQueue），因此消除了消息延迟（乱序）的影响。另一方面，当进程i收到请求回复消息时，它会先将其加入到replyQueue，并判断发送此回复消息的进程是否被加入到了其deferQueue中，如果已经加入到了，则将其移除，然后对此进程发送回复消息（因为进程i确认它已经收到被移除进程的回复消息）。其它的算法逻辑同论文中描述一致。事实上，消除消息按序到达的关键为deferQueue。算法的公平性容易保证。而消息带宽为{request: n-1, reply: n-1, release: n-1} =&gt; 3(n-1)，其中n为进程数。 Lmpoart Distributed Mutual Exclusion算法的相比Ricart Agrawala算法在实现上更为复杂。通信层采用peer to peer模型。 Token RingToken Ring是基于令牌的互斥算法。是一种简单的互斥算法模型，局限性也较大。系统内部只有一种消息：传递 token 的(OK)消息。算法核心为：将所有进程在逻辑上组成一个环，并将 token 在环上依次传递，获取到 token 的进程则具备进行临界区的条件，未收到 token 的进程则必须等待。在进程启动时，必须先将 token 传递给某一进程，若此接收进程需要锁，则进入临界区，执行完临界区代码后，再将 token 传递给相邻的下一个进程。否则直接将 token 传递给相邻下一个进程。算法的公平性同样易保证。消息带宽为n-1，其中n为进程数。 Token Ring算法较易实现，同样采用peer to peer通信模型。注意进程启动时，初始的 token 持有者。 关于测试在实现上述四种算法时(go语言)，采用TCP协议（可靠的）。测试的流程包含两个独立的阶段：Phase a. 每个进程独立的重复以下操作若干次。 执行本地操作。采用 sleep [100, 300]ms 来模拟。 开始进入临界区(critical section)。执行获取互斥锁逻辑。 执行临界区代码。对一个共享变量进行累加，在 [100, 200]ms超时时间内，每隔100ms，对共享变量随机增加 [1,10]。将累加过程写入文件，同时将累加的中间值记录到全局数组。 退出临界区。执行释放互斥锁逻辑。 Phase b. 每个进程独立的重复以下操作若干次。 进程号为偶数的进程 sleep [100, 300]ms，然后重复 Phase a 操作流程。进程号奇数的进程直接重复 Phase b 流程。 对上述四个分布式互斥算法的测试结果的验证侧重于两个方面： 算法正确性。通过检查 Phase a&amp;b 中全局数组的记录情况来确保共享资源的互斥访问。另外，核查 Phase a&amp;b 中进程访问共享资源的访问日志文件。 带宽与延时。统计每个进程的消息读写数目，及获取互斥锁的延时，并计算平均延时。 参考代码在这里。 参考文献： [1] Ricart G, Agrawala A K. An Algorithm for Mutual Exclusion in Computer Networks[R]. MARYLAND UNIV COLLEGE PARK DEPT OF COMPUTER SCIENCE, 1980.[2] Lamport L. Time, clocks, and the ordering of events in a distributed system[J]. Communications of the ACM, 1978, 21(7): 558-565.[3].CMU Distributed System Lecture.]]></content>
      <categories>
        <category>分布式系统</category>
        <category>互斥算法</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>互斥算法</tag>
        <tag>资源共享</tag>
        <tag>lamport clock</tag>
        <tag>逻辑时钟</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式系统时间、时钟与事件顺序]]></title>
    <url>%2F2018%2F11%2F05%2F%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E6%97%B6%E9%97%B4%E3%80%81%E6%97%B6%E9%92%9F%E4%B8%8E%E4%BA%8B%E4%BB%B6%E9%A1%BA%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[如何确定分布式系统各节点（进程）中事件发生的先后顺序至关重要。时钟不一致会导致系统发生不可预料的逻辑错误。然而绝大部分情况下，不能依赖于物理时钟，因为不同的系统的物理时钟总会存在不同程度的时钟漂移（多处理器机器中也类似），即便各节点定期通过网络从时钟源进行时钟同步，也无法确保各节点时钟完全一致。因此，早在1978年，Leslie Lamport 便提出了逻辑时钟的概念，并描述了如何利用逻辑时钟来定义分布式系统中事件的发生顺序。它大致基于事件发生的因果关系，并保证能够正确排列系统中具有因果关系的事件，这使得分布式系统在逻辑上不会将具有因果关系事件的发生顺序倒置。 时钟同步事实上，计算机的时钟会以不同速率来计时，普通的石英钟漂移(skew drift)1秒所需的时间大概为11-12天。因此如果使用物理时钟physical clock所定义的时间戳来确定系统中事件发生顺序，需要对物理时钟进行定期同步(clock synchronization)。在理想网络环境下，通过网络将带有时间戳的消息在时钟源（UTC,Coordinated Universal Time）与本地机器之间传输，能够保证本地时间与时钟源基本一致。但事实上，网络是异步的且有延时，因此无法保证不同节点之间的时钟完全同步。尽管如此，我们可以通过算法来尽可能提高时钟同步精度。著名的时钟同步算法如Cristian&#39;s Time Sync和Berkeley algorithm。 Lamport Clock相比于通过同步物理时钟的方式来协调各节点的时间，在分布式系统中，更为普遍且合理的方式是使用逻辑时钟(logical clock)。Lamport 提出的逻辑时钟舍弃了物理时钟固有的无限粒度的性质，它基于事件发生的因果关系(causality)。换言之，所有的事件通过happened before来关联，以-&gt;表示。对于事件a与b，a-&gt;b表示a happened before b，它是一种偏序关系(partial order)，分布式系统中所阐述的事件发生的先后顺序一般为偏序。Lamport 在分布式系统内定义了三种类型的事件，包括进程（节点）内事件、进程发送消息事件以及进程接收消息事件。a happened before b由以下三个条件中任一一个触发： 若a与b表示同一进程内的事件，并且a发生在b之前，则有a-&gt;b。 若a代表某一进程发送消息的事件，b代表另一进程接收此消息的事件，则有a-&gt;b。 happened before关系满足传递性。 如下图（水平方向表示物理时钟增加方向，垂直方向表示不同进程），由规则(1): a-&gt;b及c-&gt;d; 由规则(2): b-&gt;c和d-&gt;f; 由规则(3): b-&gt;f。但并非所有的事件都能通过-&gt;关联，比如a与e为不同进程不同消息链上的事件，则只能被定义为并发的两个事件，记作a||e。事实上，事件a与e没有因果关系，因此，从系统正确性的角度而言，它们之间真正的发生顺序不会影响到系统的正确性，所以我们不需要关注它们发生的先后顺序。 如果将系统中所有发生的事件e标记一个单调递增的时间戳(L(e))（与物理时钟没有关系），也称为lamport timestamp/clock，每一个进程都会维护自己的逻辑时钟，时间戳标记原理如下： 每个事件对应一个初始的时间戳，初始值为0。 如果发生的事件为进程内事件，则时间戳加1。 如果事件为发送事件，则将时间戳加1，并在消息中带上该时间戳。 如果事件为接收事件，则其时间戳为max(进程时间戳，消息中附带的时间戳)+1。 如下图，p1、p2以及p3都有自己的初始的逻辑时钟0；进程的全局（当前）逻辑时钟即为当某一事件发生之后的逻辑时钟值，如事件a与b的逻辑时钟值分别为0+1=1和1+1=2。而发p1发送消息m1给p2后，c的逻辑时钟值为max(0, 2)+1=3。 在lamport clock表示法中，对于事件e1与e2，e1-&gt;e2能推断出L(e1)&lt;L(e2)，但反之不成立，即L(e1)&lt;L(e2)不能推断出e1-&gt;e2，如在图(2)中，L(b)&gt;L(e)，但实际上有b||e。另外，并发事件也是类似的，即若L(e1)=L(e2)可以推断出e1||e2，但反之不成立。对于lamport clock，并发事件没有可比性，正如上文所述，并发事件发生的先后顺序并不影响系统逻辑正确性。 在lamport clock表示法中，无法确定没有因果关系的事件的先后顺序，而大多数分布式系统确实需要对所有的事件进行全局排序(total order)，而不仅仅得到影响系统正确性的事件之间的偏序关系(partial order)。换言之，为了得到一个全局的事件发生顺序，必须对并发事件进行先后发生顺序的判定。因为并发事件真正发生的先后顺序不影响系统的准确性，因此可以为它们统一制定一个任意顺序规则（事实上，lamport clock就是这么考虑的）。比如同其它因果关系事件类似，以逻辑时钟(L(e))的大小来判定，逻辑时钟小的发生在前，反之则发生在后。而对于逻辑时钟相同的并发事件，在lamport clock算法当中，给出的解释是根据进程号(PID)的大小来确定，进程编号更小的发生在前。其实，Lamport 在论文中提到过，也可以采用其它方式来确定并发事件的先后顺序，这似乎没有理论依据，但是正如前面所述，通过引入lamport clock，可以在逻辑上保证系统的正确性，我们不关心那些不影响系统正确运行的事件之间的顺序。但以进程编号作为依据，似乎影响到了系统的公平性，比如当两个进程竞争同一物理资源，物理时间上先发出请求的进程不一定能先锁定资源，但这并不会造成系统逻辑错误。在lamport clock原论文中，给出的实例便是分布式系统资源竞争或者互斥占用，大家可以参考原论文。 Vector Clock前文提到lamport clock存在一个缺点，即对于事件e1与e2，L(e1)&lt;L(e2)并不能推导出e1 happened before e2，换言之，其只能确定单方的因果关系关联。vector clock是在lamport clock上演进的一种逻辑时钟表示法，它完善了lamport clock这一缺陷，能提供完整的因果关系关联。在vector clock表示法中，每个进程维护的不仅仅是本进程的时间戳，而是通过一个向量(vector)来记录所有进程的lamport clock以此作为进程的逻辑时钟，即进程事件的逻辑时钟被表示为：v(e)[c1, c2..., cn]，其中ci为进程i中先于事件e发生的事件。vector clock的逻辑时钟标记原理同lamport clock原理类似。 如下图，在进程p1中，事件a的逻辑时钟为(1,0,0)，发送消息m的事件b的逻辑时钟为(2,0,0)。在进程p2中，其接收消息m1的事件c的逻辑时钟为max((0,0,0),(2,0,0))+1=(2,1,0)。此时，对于事件e1与e2，由e1 happened before e2推断出v(e1)&lt;v(e2)，反之亦然。在vector clock表示法中，事件c与e是并行事件，记作c&lt;-&gt;e，因为我们不能推导出v(c)&lt;=v(e)，也不能推导出V(e)&lt;=v(c)。注意，此时逻辑时钟值的比较(&lt;|&gt;|&lt;=|&gt;=)是对向量的分量逐一比较。 参考资料：（插图出自 CMU Lecture）[1] https://en.wikipedia.org/wiki/Cristian%27s_algorithm[2] https://en.wikipedia.org/wiki/Berkeley_algorithm[3] Lamport L. Time, clocks, and the ordering of events in a distributed system[J]. Communications of the ACM, 1978, 21(7): 558-565.[4].CMU 15-440 Distributed System Lecutre 9]]></content>
      <categories>
        <category>分布式系统</category>
        <category>逻辑时钟</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>lamport clock</tag>
        <tag>逻辑时钟</tag>
        <tag>时钟同步</tag>
        <tag>物理时钟</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[groupcache 设计原理剖析]]></title>
    <url>%2F2018%2F10%2F29%2Fgroupcache-%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86%E5%89%96%E6%9E%90%2F</url>
    <content type="text"><![CDATA[groupcache是一个用go实现的分布式k/v缓存及缓存填充库，它的作者也是memcached的作者，它已在Google多个生产环境中使用。它非常小巧精致，比较适用于分布式缓存的学习。它本身只是一个代码包（大约2000行代码，不需要配置服务器，在不同的请求处理场合，它可以充当客户端或者服务器的角色。它支持一致性哈希，即通过一致性哈希来对查询请求进行路由。对于缓存的具体策略，groupcache采用的是LRU，使用了一个List和一个Map来实现，非常简单。下面先简述本地缓存的基本模型和常见问题，然后剖析groupcache的设计原理。 单机缓存或者本地缓存是简单的，通过在内存中维护一个cache，当收到查询时，先查询cache是否已缓存查询结果，如果命中则直接返回，否则必须到存储系统执行查询，然后将结果先缓存到cache，然后返回结果。当然，这是本地缓存的基本模型，一般而言，缓存系统都面临着诸如缓存穿透、缓存雪崩及缓存击穿等问题。 缓存穿透指的是查询一定不存在的数据，此时从数据源查询不到结果，因此也无法对结果进行缓存，这直接导致此类型的查询请求每次都会落到数据源层，不仅使得缓存失效，当请求数量过多时也会浪费资源。 缓存雪崩指的是大量的缓存的过期时间被设置为相同或近似，使得缓存失效时，所有的查询请求全部落地到数据源层，同样，此时数据源层存在服务不可用的可能性。 缓存击穿则指的是对于那些热点数据，在缓存失效时，高并发的查询请求也会导致后端数据源层崩溃。 对于groupcache的设计，文章从一致性哈希、缓存命名空间、热数据扩散以及缓存过滤几个方面进行阐述。 一致性哈希一致性哈希最初是在论文《Consistent Hashing and Random Trees: Distributed Caching Protocols for Relieving Hot Spots on the World Wide Web》中提出，目标是致力于解决因特网中的热点(Hot spot)问题，并真正应用于p2p环境，它弥补简单的哈希算法的不足。一般可以从四个方面来衡量哈希算法的适用性。 平衡性。平衡性即哈希的结果能够尽可能的分散到所有节点或缓冲，以保证缓冲空间被最大程度使用。 单调性。单调性即如果当前缓存系统已经存在被映射的缓冲内容，当有新的节点加入到系统时，哈希算法应该能够尽可能保证原有已分配的的缓冲内容只能被映射到原有的对应节点或者新的节点，而不能被映射到旧的节点集合的其它节点。 分散性。分布式环境中，不同终端所见的节点范围有可能不同（因为可能只能看见部分节点），这会导致不同终端的哈希结果不一致，最终，相同的内容被映射到了不同的节点。而分散性则专门用于描述此种情况发生的严重程度。好的哈希算法应该尽量避免发生这种情况，即降低分散性。 负载。本质上与分散性阐述的是同一问题。但它从节点出发，即某一特定的节点应该尽可能被相同的缓冲内容所映射到，换言之，避免（不同终端）将相同的内容映射到不同的节点。 所谓一致性哈希，简而言之，即将节点与缓冲内容分别映射到一个巨大的环形空间中，最终内容的缓存节点为在顺时针方向上最靠近它的节点。可以发现，系统中节点的添加与删除，一致性哈希算法仍能基本满足以上四个特性。另外一个关键问题是，当集群中节点数量较少时，节点分布不均匀（即节点所负责的内容范围相差较大）会直接导致内容（数据）倾斜，因此一般会引入虚拟节点，即将节点映射为虚拟节点。如此，整个缓存映射过程便拆分为两个阶段：对于特定缓冲内容，先找到其映射的虚拟节点，然后再由虚拟节点映射到物理节点。 一致性哈希在分布式缓存中充当查询路由角色，因为不同节点负责特定的key集合。因此，如果此时当查询没能在本节点缓存中命中时，则需通过一致性哈希路由特定节点(peer)，然后借助http发送数据查询请求，请求的协议格式为: GET http://peer/key。因此，所有节点必须监听其它节点的数据查询请求，同时具备相应的请求处理模块。 缓存命名空间即便是在单个节点上，也可以创建若干个不同名称的缓存命名空间，以使得不同命名空间的缓存相互独立。如此，可以在原本针对key进行分片的基础上，丰富缓存功能。因此，节点间的数据查询请求协议格式变更为：GET http://peer/groupname/key。 热点数据扩散分布式缓存系统，不同的节点会负责特定的key集合的查询请求。但因为并非所有的key的访问量是均匀的，因此，存在这种情况：某些key属于热点数据而被大量访问，这可能导致包含该key的节点无法及时处理甚至瘫痪。考虑到这一点，groupcache增加了热点数据自动扩展的功能。即针对每一个节点，除了会缓存本节点存在且大量被访问的key之外（缓存这些key的对象被称之为maincache），也会缓存那些不属于本节点，但同样被大量访问（发生大量地miss cache）的key，而缓存这些key的对象被称这为hotcache，如此便能缓解热点数据的查询请求集中某一个节点的问题。 缓存过滤机制groupcache的singleflight模块实现了缓存过滤机制。即在大量相同的请求并发访问时，若缓存未能命中，则会触发大量的Load过程。即所有的查询请求全部会落到数据源（如DB）或从其它节点加载数据，因此考虑到节点可靠性，此时DB存在因压力过大而导致服务不可用的情况，同时也浪费资源。groupcache设计所提供的解决方案是：尽管存在并发的查询，但能保证只有一个请求能够真正的转发到DB执行查询，而其余的请求都会阻塞等待，直至第一个请求的查询结果返回，同时，其它请求会使用第一个请求的查询结果，最后再返回给客户端。singleflight通过go的sync.WaitGroup实现同一时间相同查询请求的合并。 最后，虽然官方声称groupcache在很多场景下已经成为memcached的替代版，但其本身存在固有的”局限性”。 groupcache采用的是LRU缓存机制，使用List和Map实现，不支持过期机制（不支持设置过期时间），也没有明确的回收机制（只是简单地将队尾的数据移除），但能够控制缓存总大小在用户设置的阈值之下。 groupcache不支持set、update以及delete，即对于客户端而言，只能执行get操作。 groupcache针对key不支持多个版本的值。 总而言之，groupcache是一个值得学习的开源分布式缓存系统，通过阅读源码，一方面可以了解分布式缓存相关的设计原则，也能学习编程相关的设计经验。]]></content>
      <categories>
        <category>分布式系统</category>
        <category>分布式缓存</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>分布式缓存</tag>
        <tag>LRU缓存</tag>
        <tag>一致性哈希</tag>
        <tag>缓存过滤机制</tag>
        <tag>缓存击穿</tag>
        <tag>热点数据扩散</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Live Sequence Protocol 实现]]></title>
    <url>%2F2018%2F10%2F25%2FLive-Sequence-Protocol-%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[分布式环境中，网络不稳定导致消息（数据包）的传输存在乱序、重复和丢失的情况，同时，节点宕机也不可避免。如何优雅地处理这些问题，是构建一个健壮的分布式系统的关键。网络的复杂性使得数据包传输协议至关重要。低级别的IP协议提供不可靠的数据报服务，即消息可能延时、重复或丢失，另外，它也限制了在网络节点中传输的消息的最大字节数，因此很少直接利用IP协议来构建分布式应用。在传输层，UDP也不提供可靠的数据报服务，但它可以通过端口定向传输报文。而TCP则会保证消息传输的可靠性、有序性，并允许任意字节大小的消息传递，还提供额外的功能，如流量控制、拥塞控制。 我们的目的是实现一个基于UDP、具备TCP几个关键特性的消息传输协议 (Live Sequence Protocol），同时它还具备如下功能： 不同于UDP或TCP，它支持 client-server通信模型 。 server会维护若干个client的连接。 server与client的通信是通过向对方发送消息来实现，消息大小限制与UDP相同。 消息传输是可靠的：消息一旦发送，就会被顺序接收，且每个消息只会被接收一次。 server与client可以检测连接的状态。 协议具体的工作原理、关键特性、运行流程及开放使用的接口可以参考p1.pdf。下面我会讨论协议实现过程中的几个关键点，以及个人在实现过程中遇到的棘手的问题。 系统逻辑框架构建清晰且优雅地构建整个系统的逻辑框架至关重要，代码框架设计关系到后期功能模块调试与扩展，不合理的系统逻辑框架设计会使得后期的扩展寸步难行，也会导致代码的可调试性、可读性变差。因此，在编写出你的第一个可用的版本之前，尽可能合理地安排系统框架，这需要理解并梳理系统的主干及各分支（异常）运行流程，为了更简单、高效且合理地实现模块功能，必须尽可能熟悉(go)语言的特性(channel、gorountine及interface)。 协议实现文档清晰地描述了协议的完整工作流程，按照此流程，其核心是epoch event触发后，协议的应对逻辑，可以实现出一个可运行的版本。合理安排程序框架关键在于处理好以下三个方面的问题： 哪些功能逻辑应该被顺序执行，如何保证同步顺序执行。比如，当创建client后，只有当其与server建立连接connection（抽象连接，并非消息传输所使用的连接）后才能返回，同时启动后台服务。注意client创建UDP连接到server可能会尝试多次，因为server可能存在慢启动问题，而且Connect消息也可能丢失。 系统需要哪些后台服务(background goroutine)， 后台服务如何可靠地同主线程协调交互。比如，对于client而言，至少需要三个goroutine来处理消息。 read goroutine持续从连接中读取消息，直到连接关闭。 write goroutine，因为写操作的调用是非阻塞的，但由于滑动窗口大小限制，并非所有消息都能立刻cache到滑动窗口并立即发送出去，因此，可以将用户wirte的消息放入到消息的write channel中，然后由专门的后台服务从channel中取消息，并在恰当的时候发送消息。 epoch event trigger goroutine，即处理与epoch相关的逻辑，超时如何处理？接收到Ack消息或Data消息如何处理？达到max epoch时如何处理？ 确保开放接口的实现符合协议规范中预定义的准则要求。比如，server的Read接口的调用会阻塞直到其从任一client收到消息，然后返回消息的payload及对应的connection ID。如果连接丢失，关闭或者Server主动关闭终止，都应该返回错误提示。这个方法不应该被简单地设计成从连接中持续读取数据，因为Server可能连接多个client，针对每一个client 连接的读取，必须启用单独的goroutine。所以，一种简单的设计是server并发地从各连接读取数据，若通过了校验（如保证用户调用Read所返回的数据正是用户所期望的），则将数据放入到channel，让Read持续从channel中取数据，注意数据一旦添加到channel中，则会以放入的顺序被Read取出，并返回给用户。 理解UDP通信本质大家可能对TCP原理及编程更为熟悉，UDP相对简单，但因为lsp(Live Sequence Protocol)基于UDP，并在更高的协议抽象层面具备TCP的特性，所以，不要混淆了二者的通信原理。UDP是无连接的！它会完全按照程序员的意愿发送消息，它不考虑对方主机是否存在或正常工作，也不会主动重发消息，因此，也就无法保证消息的可靠接收与发送。 所以，server不需要也不能维护其与client的连接！但应当在sever端创建并维护与其通信的client关联的信息实体（需包含哪些数据？），那何时创建？答案是当server读取到数据时，因为此时可以获取读取所返回的client地址，server可以通过cache已经连接的信息来判断此次读取对应的连接是否是新的连接。若不是，则直接进入消息读取处理逻辑，否则需要先初始化server维护的client相关联的信息实体。 最后，注意server与client使用的是不同的UDP读写通信接口。（client直接持有与server通信的连接，而server是通过指定地址（IP+port）发送与接收消息）。 如何实现滑动窗口滑动窗口sliding window是协议实现流量控制的关键，是整个协议的功能核心，并且其与TCP的滑动窗口机制类似。关于滑动窗口，在理解它的工作原理后，重点考虑以下三个方面： 设计滑动窗口的数据结构。 消息应该被有序添加到滑动窗口。 发送消息窗口需要标识每一条消息是否已经被ack。 发送消息所关联的滑动窗口latestSentDataMsg。以client作为示例，维持其发送消息的窗口，以便对未按时返回Ack的消息进行重发（已发送的data消息可能会丢失，或者接收主机响应的Ack消息丢失）。 因为窗口内的消息所返回的Ack是无序的（消息异步发送，网络传输也不能保证消息按序到达），所以，需要维护一个指针，表示当前返回的Ack消息的最小的序号receivedAckSeqNum，以作为窗口向前推进的依据。 当client发送data消息时，需同时将其cache到latestSentDataMsg。而当其接收到Ack消息时，需要执行更新此指针receivedAckSeqNum的逻辑。而server则需要对其所维护的每一个连接构建对应的发送消息窗口，但处理逻辑类似。 接收消息所关联的滑动窗口latestReceivedDataMsg。同样以client作为示例，维持其接收消息的窗口，以便在计时器超时后，对最近收到的若干个data消息，重发Ack消息。 同样，接收消息窗口也是无序的，因此，为了保证返回给用户的消息有序，需要维护一个指针，表示下一个期望接收到的data消息序号nextReceiveDataSeqNum（或者是当前已经接收到的最大的data消息的消息序号），它是依次递增的。对于接收到的任何data消息，若其SeqNum在此指针之后，都应该直接添加（暂时缓存）到latestReceivedDataMsg中，而不应该作为Read调用的返回结果。 当client收到server的data消息时，也需要将其cache到latestReceivedDataMsg，并判断是否需要更新nextReceiveDataSeqNum，若需要更新，则应当将更新过程中所涉及到的cache在接收消息窗口中的data消息按序添加到供Read接口所读取的channel。server同样是一个连接对应一个接收消息窗口。 如何实现流量控制流量控制表示若当前主机有过多的消息未被ack（网络拥塞），因此发送主机需要对用户调用Write接口的data消息进行阻塞以延缓发送。其实现关键是滑动窗口机制。具体实现原理为： 当用户调用Write接口以发送消息时，将消息添加到消息发送队列channel，然后返回，不能阻塞。 后台服务write goroutine从消息发送队列中不断的取消息，但在消息正式发送前，需要检测消息发送滑动窗口是否空闲idle，并且包含多少空闲的slot。 空闲的slot数目可以根据以下表达式计算：idleSlotNum := cli.params.WindowSize-(lastMsg.SeqNum-cli.receivedAckSeqNum)，其中，lastMsg为消息发送窗口中最后一个消息，即SeqNum最大的消息。 如果idleSlotNum大于0，则可以发送对应数目的消息，并将已经发送的消息记录到消息发送窗口，同时递增nextSendDataSeqNum指针。否则，write goroutine应该被阻塞住。那如何解除阻塞？每当client在接收到Ack消息时都要去尝试解除阻塞。 如图所示，当滑动窗口处于(a)的情况下，当用户调用Write以发送消息时，消息会被阻塞在write channel中，因为此时receivedAckSeqNum为9，消息发送窗口的idle的slot数目为：5-(14-9)=0。而当client接收若干Ack消息后，滑动窗口转移到(b)状态时，注意到receivedAckSeqNum从9逐一递增到11，消息发送窗口idleSlotNum为：5-(14-11)=2，因此窗口前移，并可以从write channel中顺序取出两个消息，进行发送。 如何检测消息重复消息重复主要包括data和Ack消息的重复接收。以client作为示例。 data消息的重复接收。 当client读取到data消息后，需要判断消息是否已经接收过。若消息重复，则直接返回Ack消息，否则应该先将消息cache到latestReceivedDataMsg。 可以通过消息的SeqNum来去重。这涉及两种情况：其一，消息已经被Ack，并且已经从latestReceivedDataMsg中移除，我们称之为消息被丢弃(discarded)。其二，消息被Ack，但仍然cache在latestReceivedDataMsg中。 Ack消息的重复接收。Ack消息的去重逻辑同data消息类似。 如何保证消息顺序发送主机异步发送消息，且消息在网络中传输也有不同程度的延迟，因此接收主机接收的消息序列的顺序很可能与发送主机发送的消息顺序不同。如何保证消息顺序？准确而言，如何以发送主机发送消息的顺序来返回给用户。 针对具备滑动窗口机制的消息传输，可以保证滑动窗口前所接收的消息，即已经被discarded的消息肯定是有序返回给用户的。而滑动窗口内的消息，因为无法规避从网络中读取乱序消息的问题，但在读取到消息后可以控制以何种顺序将消息返回给用户。简单而言，将收到的data消息先cache在latestReceivedDataMsg中，然后通过指针nextReceiveDataSeqNum来判断是否应该将窗口中cache的消息返回给用户。 如何优雅地关闭连接保证连接优雅地关闭是一个非常棘手的问题。其中，相比于client端的连接关闭，server的关闭又更为复杂。协议规范清晰地描述了client及server在关闭连接时需要注意的问题。其核心是： 当存在pending消息时，需要将其处理完成（即需保证接收到Ack消息）。 同时，一旦data消息被加入到write channel，它必须保证最后能够被发送出去。client的关闭相对简单，具体处理逻辑为：当用户调用Close接口时，需要判断是否存在pending消息，如何检测？两个条件： 保证消息发送窗口的最后一个消息的SeqNum恰好为其持有的receivedAckSeqNum的值。 保证write channel中没有任何未被处理的消息。因此如果此时存在pending消息，Close会被阻塞。那如何解除阻塞？每当client在接收到Ack消息时都要去尝试解除阻塞。此外，值得注意的是，在阻塞的过程中，如果触发了max epoch event，则client应该立刻返回，因为这表明连接已经discarded，此时要么所有pending消息已被处理，要么server主动关闭了连接。server的CloseConn接口可以看作是client的Close接口的非阻塞版本。而Close接口需要协调所有的connection的关闭。同样，server的某个连接也可能到达max epoch，此时其对应的连接应该被关闭。当所有连接都关闭时，Close才能返回。在连接关闭时，需要及时退出对应的background goroutine。 需注意的细节问题往往一些编程方面的细节，包括逻辑漏洞或者被忽视的语法问题会造成很长时间的调试。而且，当通信过程中，数据交换复杂变得越发复杂时，很难从庞大的日志文件中找出错误的根源。个人在实现的过程中，遇到两个问题： dead lock。死锁很容易产生，一般有两个原因，其一，资源的相互持有，造成两个线程都无法向前推进。其二，没有正确嵌套使用锁，你需要清楚锁是否可重入。 buffered channel。其导致的问题比较隐蔽，你首先要明确是使用带缓冲的channel或者不带缓冲的channel，如果是buffered channel，你需要确定它的大小，如果你不确定缓冲区数量是否足够，建议设置的稍大一些，但这个前提是，必须在合适的时机清空buffered channel，避免在复用buffered channel之后导致逻辑受到影响。 最后，需要提醒的是，分布式程序异步、并发，且网络复杂的特性导致其很难debug。所以，尽可能设计完善的日志流程，以帮助跟踪未符合期望的执行逻辑，并定位问题。 另外，cmu提供较为完善的测试程序，如果程序出现问题，可以对某一个或几个子测试用例进行单独测试，熟悉测试用例代码，了解测试用例流程是有必要的。 参考代码在这里]]></content>
      <categories>
        <category>分布式系统</category>
        <category>传输协议</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>网络编程</tag>
        <tag>传输协议</tag>
        <tag>可靠服务</tag>
        <tag>流量控制</tag>
      </tags>
  </entry>
</search>
